{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "     # Arguments for training\n",
    "    PARSER.add_argument('--name', type=str, default=\"\", \n",
    "                        help='Name of the folder where the output should be saved.')\n",
    "    \n",
    "    PARSER.add_argument('--pretrained', type=str, default=None, \n",
    "                        help='Folder name of pretrained model that should be loaded.')\n",
    "    \n",
    "    PARSER.add_argument('--pretrained_best', type=str, default=\"train\", \n",
    "                        help='Pretrained model with lowest [train, val] loss.')\n",
    "    \n",
    "    # data\n",
    "    PARSER.add_argument('--dataset', type=str, default=\"small\", \n",
    "                        help='The dataset which we train on.')\n",
    "    \n",
    "    PARSER.add_argument('--norm_min_max', type=list, default=[0, 1], \n",
    "                        help='List with min and max for normalizing input.')\n",
    "    \n",
    "    PARSER.add_argument('--seed', type=int, default=34, \n",
    "                        help='List with min and max for normalizing input.')\n",
    "    \n",
    "    # train variables\n",
    "    PARSER.add_argument('--epochs', type=int, default=500, \n",
    "                        help='Number of epochs.')\n",
    "    \n",
    "    PARSER.add_argument('--acc_steps', type=int, default=10, \n",
    "                        help='Number of subjects that the gradient is \\\n",
    "                        accumulated over before taking an optim step.')\n",
    "    \n",
    "    PARSER.add_argument('--eval_every', type=int, default=10, \n",
    "                        help='Set the # epochs after which evaluation should be done.')\n",
    "    \n",
    "    PARSER.add_argument('--shuffle', type=bool, default=True, \n",
    "                        help='Shuffle the train dataloader?')\n",
    "    \n",
    "    PARSER.add_argument('--n_coords_sample', type=int, default=5000, \n",
    "                        help='Number of coordinates that should be sampled for each subject.')\n",
    "    \n",
    "    \n",
    "    # CNN\n",
    "    PARSER.add_argument('--cnn_setup', type=int, default=1, \n",
    "                        help='Setup of the CNN.')\n",
    "    \n",
    "    # SIREN\n",
    "    PARSER.add_argument('--dim_hidden', type=int, default=256, \n",
    "                        help='Dimension of hidden SIREN layers.')\n",
    "    \n",
    "    PARSER.add_argument('--siren_hidden_layers', type=int, default=3, \n",
    "                        help='Number of hidden SIREN layers.')\n",
    "    \n",
    "    PARSER.add_argument('--first_omega_0', type=float, default=30., \n",
    "                        help='Omega_0 of first layer.')\n",
    "    \n",
    "    PARSER.add_argument('--hidden_omega_0', type=float, default=30., \n",
    "                        help='Omega_0 of hidden layer.')\n",
    "    \n",
    "    \n",
    "    # optimizers\n",
    "    PARSER.add_argument('--cnn_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of cnn optim.')\n",
    "\n",
    "    PARSER.add_argument('--siren_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of siren optim.')\n",
    "\n",
    "    PARSER.add_argument('--mapping_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of mapping optim.')\n",
    "\n",
    "    PARSER.add_argument('--cnn_wd', type=float, default=0, \n",
    "                        help='Weight decay of cnn optim.')\n",
    "\n",
    "    PARSER.add_argument('--siren_wd', type=float, default=0, \n",
    "                        help='Weight decay of siren optim.')\n",
    "    \n",
    "    PARSER.add_argument('--mapping_wd', type=float, default=0, \n",
    "                        help='Weight decay of mapping optim.')\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.name = \"\"\n",
      "self.pretrained = None\n",
      "self.pretrained_best = \"train\"\n",
      "self.dataset = \"small\"\n",
      "self.norm_min_max = [0, 1]\n",
      "self.seed = 34\n",
      "self.epochs = 500\n",
      "self.acc_steps = 10\n",
      "self.eval_every = 10\n",
      "self.shuffle = True\n",
      "self.n_coords_sample = 5000\n",
      "self.cnn_setup = 1\n",
      "self.dim_hidden = 256\n",
      "self.siren_hidden_layers = 3\n",
      "self.first_omega_0 = 30.\n",
      "self.hidden_omega_0 = 30.\n",
      "self.cnn_lr = 1e-4\n",
      "self.siren_lr = 1e-4\n",
      "self.mapping_lr = 1e-4\n",
      "self.cnn_wd = 0\n",
      "self.siren_wd = 0\n",
      "self.mapping_wd = 0\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(parser.split(\"--\")):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    var = row.split(\"\\'\")[0]\n",
    "    default = row.split(\"\\'\")[1].split(\"default=\")[1].split(\"help=\")[0][:-27]\n",
    "    \n",
    "    print(f\"self.{var} = {default}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
