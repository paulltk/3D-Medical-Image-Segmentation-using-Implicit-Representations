{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YuCJt8PbQVS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import torch \n",
    "import glob\n",
    "import sys\n",
    "import time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mplPath\n",
    "\n",
    "import pylab as pl\n",
    "\n",
    "from threading import Timer\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "from kornia.augmentation.augmentation3d import *\n",
    "from kornia.geometry.transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbjkxsU8bQVc"
   },
   "outputs": [],
   "source": [
    "class SirenDataset(Dataset): \n",
    "    def __init__(self, root, subjects, DEVICE): \n",
    "        self.root = root\n",
    "        self.DEVICE = DEVICE\n",
    "                \n",
    "        self.all_images = [image.split(\"__\")[:3] for image in os.listdir(root) \n",
    "                           if list(image.split(\"__\")[:2]) in subjects.tolist() \n",
    "                           and image.split(\"__\")[3] == \"pcmra.npy\"]\n",
    "            \n",
    "        self.pcmras = torch.tensor([np.load(os.path.join(self.root, f\"{subj}__{proj}__{size}__pcmra.npy\")) \n",
    "                           for subj, proj, size in self.all_images]).float().to(DEVICE)\n",
    "\n",
    "        self.masks = torch.tensor([np.load(os.path.join(self.root, f\"{subj}__{proj}__{size}__mask.npy\")) \n",
    "                           for subj, proj, size in self.all_images]).float().to(DEVICE)\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        subj, proj, size = self.all_images[idx]\n",
    "        pcmra = self.pcmras[idx]\n",
    "        mask = self.masks[idx]\n",
    "        \n",
    "        pcmra = pcmra.permute(2, 0, 1).unsqueeze(0)\n",
    "        mask = mask.permute(2, 0, 1).unsqueeze(0)\n",
    "        loss_cover = torch.ones(mask.shape).to(self.DEVICE)\n",
    "\n",
    "        return idx, subj, proj, pcmra, mask, loss_cover"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "new_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
