{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Project and Show_images classes.\n"
     ]
    }
   ],
   "source": [
    "from py_files.data_classes import *\n",
    "# from data_classes.py_files.data_classes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "class PrepareData2D(object):\n",
    "    \"\"\"\n",
    "    Loads the data in project classes, combines data from all subjects, \n",
    "    shuffles slices, and returns train, validation, and test split.\n",
    "    Each split is a tuple with (project names (list), subject names (list),\n",
    "    pcmra slices (list), masks slices (list)).\n",
    "    length of project names and subject names: # slices\n",
    "    shape of pcmra and masks slices: height x width x # slices\n",
    "    \"\"\"\n",
    "    def __init__(self, project_names, seed=34): \n",
    "        self.project_names = project_names  # list with project names\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.project = self.load_project(self.project_names) # returns Project class\n",
    "        \n",
    "        #filter shape of the images, temporarily until further preprocessing\n",
    "        self.project.filter_dimension_shape(0, 128, print_dropped=False)\n",
    "        self.project.filter_dimension_shape(2, 24, print_dropped=False)\n",
    "        \n",
    "        # normalize masks and pcmra between 0 and 1\n",
    "        self.project.normalize()\n",
    "        \n",
    "        # creates list with project name and subject name for each slice\n",
    "        self.proj_list = np.array(self.projects_list())\n",
    "        self.subj_list = np.array(self.subjects_list())\n",
    "        \n",
    "        # stack masks and pcmras of all subjects onto 1 3d array\n",
    "        self.masks = np.dstack(self.project.masks)        \n",
    "        self.pcmras = np.dstack(self.project.pcmras)\n",
    "        \n",
    "        # returns 3 tuples with (project names (1d array), subject names (1d array), \n",
    "        #                        pcmra slices (3d array), masks slices (3d array))\n",
    "        self.train, self.val, self.test = self.create_train_val_test_split()\n",
    "\n",
    "\n",
    "    def load_project(self, project_names): \n",
    "        \"\"\"\n",
    "        Returns project as Project class.\n",
    "        \"\"\"\n",
    "        # load only one folder if single folder is given\n",
    "        if type(project_names) == str: \n",
    "            project = Project(project_names)\n",
    "        \n",
    "        # load and append multiple folder as one project\n",
    "        if type(project_names) == list: \n",
    "            if len(project_names) == 1: \n",
    "                project = Project(project_names[0])\n",
    "            else:\n",
    "                project = Project(project_names[0])\n",
    "                for i in range(1, len(project_names)):\n",
    "                    project.append_project(project_names[i])\n",
    "        \n",
    "        return project \n",
    "    \n",
    "    \n",
    "    def subjects_list(self):\n",
    "        \"\"\"\n",
    "        Returns a list with subject name for each slice in self.masks.\n",
    "        \"\"\"\n",
    "        subj_list = []\n",
    "        \n",
    "        for i in range(len(self.project.subjects)):\n",
    "            subject = self.project.subjects[i]\n",
    "            for j in range(self.project.masks_shape[i][2]): \n",
    "                subj_list.append(subject)\n",
    "        \n",
    "        return subj_list\n",
    "\n",
    "    \n",
    "    def projects_list(self): \n",
    "        \"\"\"\n",
    "        Returns a list with project name for each slice in self.masks.\n",
    "        \"\"\"\n",
    "        proj_list = []\n",
    "        \n",
    "        for i in range(len(self.project.subprojects)):\n",
    "            subproject = self.project.subprojects[i]\n",
    "            for j in range(self.project.masks_shape[i][2]): \n",
    "                proj_list.append(subproject)\n",
    "        \n",
    "        return proj_list\n",
    "\n",
    "    def create_train_val_test_split(self):\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        \n",
    "        # list with all slice indices (form 0 to # slices)\n",
    "        idx = list(range(self.subj_list.shape[0]))\n",
    "        \n",
    "        # set two split points\n",
    "        split1 = int(len(idx) * 0.6)\n",
    "        split2 = int(len(idx) * 0.8)\n",
    "\n",
    "        random.shuffle(idx) # shuffles indices\n",
    "\n",
    "        # incides per data subset\n",
    "        train_idx = idx[:split1]\n",
    "        val_idx = idx[split1:split2]\n",
    "        test_idx = idx[split2:]\n",
    "\n",
    "        #create tuples with data\n",
    "        train_data = (self.proj_list[train_idx], \n",
    "                      self.subj_list[train_idx], \n",
    "                      self.pcmras[:,:,train_idx], \n",
    "                      self.masks[:,:,train_idx])\n",
    "\n",
    "        val_data = (self.proj_list[val_idx], \n",
    "                      self.subj_list[val_idx], \n",
    "                      self.pcmras[:,:,val_idx], \n",
    "                      self.masks[:,:,val_idx])\n",
    "\n",
    "        test_data = (self.proj_list[test_idx], \n",
    "                      self.subj_list[test_idx], \n",
    "                      self.pcmras[:,:,test_idx], \n",
    "                      self.masks[:,:,test_idx])\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "    \n",
    "    \n",
    "    \n",
    "class Dataset2D(Dataset):  \n",
    "    \"\"\" \n",
    "    Returns tuple with (project name (str), subject name (str), \n",
    "    pcmra (np array shape: 1xHxW), mask (np array shape: 1xHxW))\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[0].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns: <project>, <subject>, <pcmra>, <mask>\n",
    "        return (self.data[0][idx], \n",
    "                self.data[1][idx], \n",
    "                np.array([self.data[2][:, :, idx]]), \n",
    "                np.array([self.data[3][:,:,idx]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = PrepareData2D([\"Aorta Volunteers\", \"Aorta BaV\", \"Aorta Resvcue\", \"Aorta CoA\"])\n",
    "# train_ds = Dataset2D(data.train)\n",
    "# train_dl = DataLoader(train_ds, batch_size=32)\n",
    "\n",
    "# batch = next(iter(train_dl))\n",
    "\n",
    "# print(\"Projects:\", batch[0])\n",
    "# print(\"\\n Subjects:\", batch[1])\n",
    "# print(\"\\n PCMRAs:\", batch[2].shape)\n",
    "# print(\"\\n Masks:\", batch[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_2d_batch(batch):\n",
    "#     title = [proj + \": \" + subj for proj, subj in zip(batch[0], batch[1])]\n",
    "    \n",
    "#     pcmra = batch[2].clone()\n",
    "#     pcmra = pcmra.reshape(pcmra.shape[0], pcmra.shape[2], pcmra.shape[3])\n",
    "#     pcmra = pcmra.permute(2, 1, 0).detach().numpy()\n",
    "    \n",
    "#     mask = batch[3].clone()\n",
    "#     mask = mask.reshape(mask.shape[0], mask.shape[2], mask.shape[3])\n",
    "#     mask = mask.permute(2, 1, 0).detach().numpy()\n",
    "\n",
    "\n",
    "#     show = Show_images(title, (pcmra, \"pcmra\"), (mask, \"mask\"), (pcmra + mask, \"pcmra + mask\"))\n",
    "    \n",
    "#     return show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# show = show_2d_batch(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "class PrepareData3D(object):\n",
    "    \"\"\"\n",
    "    Loads the data in project classes, combines data from all subjects, \n",
    "    shuffles slices, and returns train, validation, and test split.\n",
    "    Each split is a tuple with ((project names (1d array), subject names (1d array), \n",
    "    pcmra slices (4d array), masks slices (4d array)).\n",
    "    length of project names and subject names: # subjects\n",
    "    shape of pcmra and masks slices: # subjects x height x width x # slices\n",
    "    \"\"\"\n",
    "    def __init__(self, project_names, seed=34, image_size=\"full\", norm_min_max=[0,1], add_transformations=True): \n",
    "        self.project_names = project_names  # list with project names\n",
    "        self.seed = seed\n",
    "        \n",
    "        if image_size == \"full\": \n",
    "            self.root = \"/scratch/ptenkaate/Data\"\n",
    "            self.size_filters = [(0, 128), (2, 24)]\n",
    "        elif image_size == \"small\":\n",
    "            self.root = \"/scratch/ptenkaate/Data/Scaled Data\"\n",
    "            self.size_filters = [(0, 64), (2, 24)]\n",
    "            \n",
    "        else: \n",
    "            raise(Exception(\"please choose an image_size from ['full', 'small']\"))\n",
    "            \n",
    "        self.project = self.load_project(self.project_names) # returns Project class\n",
    "        \n",
    "        #filter shape of the images, temporarily until further preprocessing\n",
    "        for layer, size in self.size_filters:\n",
    "            self.project.filter_dimension_shape(layer, size, print_dropped=False)\n",
    "        \n",
    "        # normalize masks and pcmra between 0 and 1\n",
    "        self.project.normalize(norm_min_max[0], norm_min_max[1])\n",
    "        \n",
    "        self.proj_list = np.array(self.project.subprojects)\n",
    "        self.subj_list = np.array(self.project.subjects)\n",
    "        \n",
    "        self.masks = np.array(self.project.masks)        \n",
    "        self.pcmras = np.array(self.project.pcmras)\n",
    "        \n",
    "        # returns 3 tuples with (project names (1d array), subject names (1d array), \n",
    "        #                        pcmra slices (4d array), masks slices (4d array))\n",
    "        self.train, self.val, self.test = self.create_train_val_test_split()\n",
    "        \n",
    "        if add_transformations: \n",
    "            self.add_transformations()\n",
    "\n",
    "\n",
    "    def load_project(self, project_names): \n",
    "        \"\"\"\n",
    "        Returns project as Project class.\n",
    "        \"\"\"\n",
    "        # load only one folder if single folder is given\n",
    "        if type(project_names) == str: \n",
    "            project = Project(project_names, self.root)\n",
    "        \n",
    "        # load and append multiple folder as one project\n",
    "        if type(project_names) == list: \n",
    "            if len(project_names) == 1: \n",
    "                project = Project(project_names[0], self.root)\n",
    "            else:\n",
    "                project = Project(project_names[0], self.root)\n",
    "                for i in range(1, len(project_names)):\n",
    "                    project.append_project(project_names[i])\n",
    "        \n",
    "        return project \n",
    "    \n",
    "    def create_train_val_test_split(self):\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        \n",
    "        # list with all slice indices (form 0 to # slices)\n",
    "        idx = list(range(self.subj_list.shape[0]))\n",
    "        \n",
    "        # set two split points\n",
    "        split1 = int(len(idx) * 0.6)\n",
    "        split2 = int(len(idx) * 0.8)\n",
    "\n",
    "        random.shuffle(idx) # shuffles indices\n",
    "\n",
    "        # incides per data subset\n",
    "        train_idx = idx[:split1]\n",
    "        val_idx = idx[split1:split2]\n",
    "        test_idx = idx[split2:]\n",
    "\n",
    "        #create tuples with data\n",
    "        train_data = (self.subj_list[train_idx], \n",
    "                      self.proj_list[train_idx], \n",
    "                      self.pcmras[train_idx,:,:,:], \n",
    "                      self.masks[train_idx,:,:,:])\n",
    "\n",
    "        val_data = (self.subj_list[val_idx], \n",
    "                      self.proj_list[val_idx], \n",
    "                      self.pcmras[val_idx,:,:,:], \n",
    "                      self.masks[val_idx,:,:,:])\n",
    "\n",
    "        test_data = (self.subj_list[test_idx], \n",
    "                      self.proj_list[test_idx], \n",
    "                      self.pcmras[test_idx,:,:,:], \n",
    "                      self.masks[test_idx,:,:,:])\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "    \n",
    "    def add_transformations(self):\n",
    "        new_data =[[],[],[],[]]\n",
    "        \n",
    "        path = self.root + \"/Transformations/\"\n",
    "\n",
    "        files = os.listdir(path)\n",
    "        files = [file for file in files if \"_pcmra\" in file]\n",
    "\n",
    "        for file in files:\n",
    "            subj, proj, transform, img_type = file.split(\"__\")\n",
    "            if subj in self.train[0] and proj in self.train[1]:\n",
    "                new_subj = subj + \" \" + transform\n",
    "#                 print(new_subj)\n",
    "                new_data[0].append(new_subj)\n",
    "                new_data[1].append(proj)\n",
    "                \n",
    "                new_data[2].append(np.load(path + subj + \"__\" + proj  + \"__\" + transform  + \"__pcmra.npy\"))\n",
    "                new_data[3].append(np.load(path + subj + \"__\" + proj  + \"__\" + transform  + \"__mask.npy\"))\n",
    "        \n",
    "        old_data = list(self.train)\n",
    "        \n",
    "        combined_data = [np.append(old, np.array(new) , axis=0) for old, new in zip(old_data, new_data)]\n",
    "        \n",
    "        self.train = combined_data\n",
    "#         print(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset3D(Dataset):  \n",
    "    \"\"\" \n",
    "    Returns tuple with (project name (str), subject name (str), \n",
    "    pcmra (np array shape: 1 x # slices x H x W), mask (np array shape: 1 x # slics x H x W))\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[0].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns: <project>, <subject>, <pcmra>, <mask>\n",
    "        \n",
    "        return (self.data[0][idx], \n",
    "                self.data[1][idx], \n",
    "                np.array([self.data[2][idx, :, :, :]]).transpose(0, 3, 1, 2), \n",
    "                np.array([self.data[3][idx, :, :, :]]).transpose(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = PrepareData3D([\"Aorta Volunteers\", \"Aorta BaV\", \"Aorta Resvcue\", \"Aorta CoA\"], image_size=\"small\")\n",
    "# train_ds = Dataset3D(data.train)\n",
    "\n",
    "# print(train_ds.__getitem__(0)[0])\n",
    "# train_dl = DataLoader(train_ds, batch_size=32)\n",
    "\n",
    "# batch = next(iter(train_dl))\n",
    "\n",
    "# print(\"Projects:\", batch[0])\n",
    "# print(\"\\n Subjects:\", batch[1])\n",
    "# print(\"\\n PCMRAs:\", batch[2].shape)\n",
    "# print(\"\\n Masks:\", batch[3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siren Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(*sidelengths):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    \n",
    "    tensors = []\n",
    "    \n",
    "    for sidelen in sidelengths:\n",
    "        tensors.append(torch.linspace(-1, 1, steps=sidelen))\n",
    "    \n",
    "    tensors = tuple(tensors)\n",
    "    coords = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    return coords.reshape(-1, len(sidelengths))\n",
    "\n",
    "\n",
    "def get_sorted_ind(tensor, axis):\n",
    "    values, ind = torch.sort(tensor[:, axis])\n",
    "    \n",
    "    sorted_ind = []\n",
    "    print(sorted(set(values.tolist())))\n",
    "    for v in sorted(set(values.tolist())): \n",
    "        subset = ((values == v).nonzero(as_tuple=True)[0])\n",
    "        sorted_ind += ind[subset].sort()[0].tolist()\n",
    "    \n",
    "    return sorted_ind\n",
    "\n",
    "\n",
    "def sort_coords_and_pixels(coords, pixels):\n",
    "    for axis in reversed(range(coords.shape[1])):\n",
    "        ind = get_sorted_ind(coords, axis)\n",
    "        coords = coords[ind]\n",
    "        pixels = pixels[ind]\n",
    "        print(axis)\n",
    "        print(coords)\n",
    "        print(pixels)\n",
    "    \n",
    "    return coords, pixels\n",
    "\n",
    "\n",
    "def prod(val) :  \n",
    "    res = 1 \n",
    "    for ele in val:  \n",
    "        res *= ele  \n",
    "    return res   \n",
    "\n",
    "\n",
    "def image_to_array(image): \n",
    "    length = prod(image.shape)\n",
    "\n",
    "    coords = get_coords(*image.shape)\n",
    "    image = image.view(length, 1)\n",
    "    \n",
    "    return coords, image\n",
    "\n",
    "      \n",
    "def array_to_image(coords, pixels, sort=True): \n",
    "    if sort: \n",
    "        coords, pixels = sort_coords_and_pixels(coords, pixels)\n",
    "        \n",
    "    size = list()\n",
    "    for dim in range(coords.shape[1]): \n",
    "        i = len(set(coords[:, dim].tolist()))\n",
    "        size.append(i)\n",
    "    image = pixels.view(*size)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SirenDataset(Dataset): \n",
    "    \n",
    "    def __init__(self, data, DEVICE):\n",
    "        \"\"\"\n",
    "        Returns a list with tuples, each tuple is a subject. \n",
    "        Tuple consists of: (\n",
    "        idx: added in __getitem__, \n",
    "        subject name, \n",
    "        project_name, \n",
    "        pcmra: width x height x slices, \n",
    "        coords: n_pixels x 3, \n",
    "        pcmra: n_pixels x 1, \n",
    "        mask:n_pixels x 1\n",
    "        )\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(data[0].shape[0]): \n",
    "#         for i in range(1): \n",
    "            sample = []\n",
    "            sample.append(data[0][i])\n",
    "            sample.append(data[1][i])\n",
    "            sample.append(torch.Tensor(data[2][i]).permute(2, 0, 1).unsqueeze(0).to(DEVICE))\n",
    "            coords, pcmra = image_to_array(torch.Tensor(data[2][i]))\n",
    "            _, mask = image_to_array(torch.Tensor(data[3][i]))\n",
    "            sample.append(coords.to(DEVICE))\n",
    "            sample.append(pcmra.to(DEVICE))\n",
    "            sample.append(mask.to(DEVICE))\n",
    "            \n",
    "            self.data.append(tuple(sample))\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):    \n",
    "#         if idx > 0: raise IndexError\n",
    "            \n",
    "        return (idx, *self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported data preparation and custom Dataset classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Imported data preparation and custom Dataset classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = PrepareData3D([\"Aorta Volunteers\", \"Aorta BaV\", \"Aorta Resvcue\", \"Aorta CoA\"], image_size=\"small\")\n",
    "\n",
    "# train_ds = SirenDataset(data.train, \"cpu\")\n",
    "# # print(train_ds.proj_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.009506225585938e-05\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "sample = train_ds.__getitem__(1)\n",
    "\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit0627eb39d7a6497d88458471ef8e42e3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
