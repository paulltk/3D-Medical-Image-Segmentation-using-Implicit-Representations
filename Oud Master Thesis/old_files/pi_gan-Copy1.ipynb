{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Project and Show_images classes.\n",
      "Imported data preparation and custom Dataset classes.\n",
      "Imported CNN model.\n",
      "Imported PI-Gan model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import math \n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# from data_classes.py_files.data_classes import *\n",
    "from data_classes.py_files.custom_datasets import *\n",
    "\n",
    "from model_classes.py_files.cnn_model import *\n",
    "from model_classes.py_files.pigan_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Using device for training: cuda\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "def set_device():\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return DEVICE \n",
    "\n",
    "DEVICE = set_device()\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Using device for training:', DEVICE)\n",
    "print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Random coords subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_coords(*arrays, n=1000): \n",
    "    \n",
    "    mx = arrays[0].shape[1]\n",
    "    rand_idx = random.sample(range(mx), n)\n",
    "\n",
    "    arrays = [array[:, rand_idx, :] for array in arrays]\n",
    "    \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image generation and model saving functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_image(cnn, siren, pcmra, coords, val_n = 10000): \n",
    "    \n",
    "    cnn.eval(); siren.eval() #evaluation mode    \n",
    "    image = torch.Tensor([]).cuda() # initialize results tensor\n",
    "    cnn_out = cnn(pcmra) # get representation\n",
    "    \n",
    "    n_slices = math.ceil(coords.shape[1] / val_n) # number of batches\n",
    "    for i in range(n_slices):\n",
    "        coords_in = coords[:, (i*val_n) : ((i+1)*val_n), :]\n",
    "        siren_out = siren(cnn_out, coords_in)\n",
    "        image = torch.cat((image, siren_out.detach()), 1)\n",
    "    \n",
    "    cnn.train(); cnn.train()\n",
    "    \n",
    "    return image \n",
    "\n",
    "\n",
    "def save_info(path, losses, cnn, siren, cnn_optim, siren_optim): \n",
    "    \n",
    "    np.save(f\"{path}/losses.npy\", losses)\n",
    "    \n",
    "    eps = losses[:, 0]\n",
    "    train_losses = losses[:, 1]\n",
    "    val_losses = losses[:, 3]\n",
    "\n",
    "    if train_losses[-1] == train_losses.min(): \n",
    "        print(f\"New best train loss: {round(train_losses[-1], 5)}, saving model.\")\n",
    "\n",
    "        torch.save(cnn.state_dict(), f\"{path}/cnn_train.pt\")\n",
    "        torch.save(cnn_optim.state_dict(), f\"{path}/cnn_optim_train.pt\")\n",
    "        \n",
    "        torch.save(siren.state_dict(), f\"{path}/siren_train.pt\")\n",
    "        torch.save(siren_optim.state_dict(), f\"{path}/siren_optim_train.pt\")\n",
    "    \n",
    "    if train_losses[-1] == train_losses.min(): \n",
    "        print(f\"New best val loss: {round(val_losses[-1], 5)}, saving model.\")\n",
    "\n",
    "        torch.save(cnn.state_dict(), f\"{path}/cnn_val.pt\")\n",
    "        torch.save(cnn_optim.state_dict(), f\"{path}/cnn_optim_val.pt\")\n",
    "        \n",
    "        torch.save(siren.state_dict(), f\"{path}/siren_val.pt\")\n",
    "        torch.save(siren_optim.state_dict(), f\"{path}/siren_optim_val.pt\")\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.plot(eps[1:], train_losses[1:], label='Train loss')\n",
    "    ax.plot(eps[1:], val_losses[1:], label='Eval loss')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('BCELoss')\n",
    "    legend = ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.savefig(f\"{path}/loss_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder(ARGS): \n",
    "    now = datetime.now()\n",
    "    dt = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    path = f\"saved_runs/pi-gan {dt} {ARGS.name}\"\n",
    "    \n",
    "    Path(f\"{path}\").mkdir(parents=True, exist_ok=True)   \n",
    "\n",
    "    return path\n",
    "    \n",
    "\n",
    "def initialize_dataloaders(projects, ARGS):\n",
    "    assert(ARGS.dataset in [\"full\", \"small\"])\n",
    "\n",
    "    data = PrepareData3D(projects, image_size=ARGS.dataset, norm_min_max=ARGS.norm_min_max)\n",
    "\n",
    "    train_ds = SirenDataset(data.train, DEVICE) \n",
    "    train_dl = DataLoader(train_ds, batch_size=1, num_workers=0, shuffle=ARGS.shuffle)\n",
    "    print(\"Train subjects:\", train_ds.__len__())\n",
    "\n",
    "    val_ds = SirenDataset(data.val, DEVICE) \n",
    "    val_dl = DataLoader(val_ds, batch_size=1, num_workers=0, shuffle=False)\n",
    "    print(\"Validation subjects:\", val_ds.__len__())\n",
    "    \n",
    "    return train_dl, val_dl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(cnn, siren, dataloader, cnn_optim, siren_optim, criterion, batch_count, ARGS):\n",
    "    losses = []\n",
    "    \n",
    "    for _, _, _, pcmra, coords, _, mask_array in dataloader:\n",
    "        siren_in, siren_labels = choose_random_coords(coords, mask_array)\n",
    "\n",
    "        cnn_out = cnn(pcmra)\n",
    "        siren_out = siren(cnn_out, siren_in)\n",
    "\n",
    "        loss = criterion(siren_out, siren_labels) \n",
    "        losses.append(loss.item())\n",
    "        loss = loss / dataloader.__len__()\n",
    "        loss.backward()\n",
    "\n",
    "        batch_count += 1\n",
    "        if batch_count % ARGS.acc_steps == 0: \n",
    "            siren_optim.step()\n",
    "            cnn_optim.step()   \n",
    "\n",
    "            siren_optim.zero_grad()\n",
    "            cnn_optim.zero_grad()\n",
    "    \n",
    "    mean, std = round(np.mean(losses), 6), round(np.std(losses), 6)\n",
    "    \n",
    "    return mean, std, batch_count\n",
    "\n",
    "\n",
    "def val_epoch(cnn, siren, dataloader, cnn_optim, siren_optim, criterion):\n",
    "    losses = []\n",
    "\n",
    "    for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in dataloader:    \n",
    "        siren_out = get_complete_image(cnn, siren, pcmra, coords)\n",
    "        loss = criterion(siren_out, mask_array)            \n",
    "\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    mean, std = round(np.mean(losses), 6), round(np.std(losses), 6)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():  \n",
    "    \n",
    "    ##### path to wich the model should be saved #####\n",
    "    path = get_folder(ARGS)\n",
    "    \n",
    "    ##### save ARGS #####\n",
    "    with open(f'{path}/ARGS.txt', 'w') as f:\n",
    "        print(vars(ARGS), file=f)\n",
    "        \n",
    "    ##### data preparation #####\n",
    "    train_dl, val_dl = initialize_dataloaders([\"Aorta Volunteers\", \"Aorta BaV\",\n",
    "                                               \"Aorta Resvcue\", \"Aorta CoA\"], ARGS)\n",
    "\n",
    "    \n",
    "    ##### initialize models #####\n",
    "    cnn = CNN((1, 16), (16, 32), (32, 64), (64, 128),\n",
    "              (ARGS.flattened_size, ARGS.z_dim)).cuda()\n",
    "    \n",
    "    siren = SirenGenerator(dim=ARGS.z_dim, dim_hidden=256).cuda()\n",
    "    \n",
    "    ##### initialize optimizers #####\n",
    "    cnn_optim = torch.optim.Adam(lr=ARGS.cnn_lr, params=cnn.parameters(), \n",
    "                                 weight_decay=ARGS.cnn_wd)\n",
    "    \n",
    "    siren_optim = torch.optim.Adam(lr=ARGS.siren_lr, params=siren.parameters(), \n",
    "                                   weight_decay=ARGS.siren_wd)\n",
    "    \n",
    "    ##### loss function #####\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    \n",
    "    ##### epoch, train loss mean, train loss std, #####\n",
    "    ##### val loss mean, val loss std #####\n",
    "    losses = np.empty((0, 5))\n",
    "\n",
    "    batch_count = 0     \n",
    "    \n",
    "    for ep in range(ARGS.epochs):\n",
    "    \n",
    "        t = time.time() \n",
    "\n",
    "        cnn.train(); siren.train()\n",
    "\n",
    "        t_loss_mean, t_loss_std, batch_count = train_epoch(cnn, siren, train_dl, \n",
    "                                                           cnn_optim, siren_optim, \n",
    "                                                           criterion, batch_count, ARGS)\n",
    "        \n",
    "        if ep % ARGS.eval_every == 0: \n",
    "\n",
    "            print(f\"Epoch {ep} took {round(time.time() - t)} seconds.\")\n",
    "\n",
    "            v_loss_mean, v_loss_std = val_epoch(cnn, siren, val_dl, \n",
    "                                                cnn_optim, siren_optim, criterion)\n",
    "            \n",
    "            losses = np.append(losses, [[ep ,t_loss_mean, t_loss_std, \n",
    "                                         v_loss_mean, v_loss_std]], axis=0)\n",
    "            \n",
    "            save_info(path, losses, cnn, siren, cnn_optim, siren_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: ARGS class initialized.\n",
      "Train subjects: 54\n",
      "Validation subjects: 18\n",
      "Epoch 0 took 4 seconds.\n",
      "New best train loss: 0.67144, saving model.\n",
      "New best val loss: 0.63832, saving model.\n",
      "Epoch 2 took 4 seconds.\n",
      "New best train loss: 0.27788, saving model.\n",
      "New best val loss: 0.14501, saving model.\n",
      "Epoch 4 took 4 seconds.\n",
      "New best train loss: 0.13694, saving model.\n",
      "New best val loss: 0.12213, saving model.\n",
      "Epoch 6 took 4 seconds.\n",
      "New best train loss: 0.13041, saving model.\n",
      "New best val loss: 0.12257, saving model.\n",
      "Epoch 8 took 4 seconds.\n",
      "New best train loss: 0.12776, saving model.\n",
      "New best val loss: 0.12128, saving model.\n",
      "Epoch 10 took 4 seconds.\n",
      "New best train loss: 0.12454, saving model.\n",
      "New best val loss: 0.11824, saving model.\n"
     ]
    }
   ],
   "source": [
    "class init_ARGS(object): \n",
    "    def __init__(self): \n",
    "        self.name = \"\"\n",
    "        self.dataset = \"small\"\n",
    "        self.epochs = 500\n",
    "        self.acc_steps = 10\n",
    "        self.shuffle = True\n",
    "        self.norm_min_max = [0, 1]\n",
    "        self.shuffle = True\n",
    "        self.flattened_size = 4096\n",
    "        self.z_dim = 128\n",
    "        self.shuffle = True\n",
    "        self.cnn_lr = 1e-4\n",
    "        self.siren_lr = 1e-4\n",
    "        self.cnn_wd = 0\n",
    "        self.siren_wd = 0\n",
    "        self.eval_every = 2\n",
    "\n",
    "        \n",
    "        print(\"WARNING: ARGS class initialized.\")\n",
    "        \n",
    "ARGS = init_ARGS()\n",
    "        \n",
    "train()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size = \"small\"\n",
    "\n",
    "data = PrepareData3D([\"Aorta Volunteers\", \"Aorta BaV\", \"Aorta Resvcue\", \"Aorta CoA\"], \n",
    "                     image_size=image_size, norm_min_max=[0,1])\n",
    "\n",
    "train_ds = SirenDataset(data.train, DEVICE) \n",
    "train_dataloader = DataLoader(train_ds, batch_size=1, num_workers=0, shuffle=True)\n",
    "print(train_ds.__len__())\n",
    "print(next(iter(train_dataloader))[1])\n",
    "\n",
    "val_ds = SirenDataset(data.val, DEVICE) \n",
    "val_dataloader = DataLoader(val_ds, batch_size=1, num_workers=0, shuffle=True)\n",
    "\n",
    "print(val_ds.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_dim = 128\n",
    "\n",
    "flattened_size = [16384 if image_size==\"full\" else 4096][0]\n",
    "\n",
    "cnn = CNN((1, 16), \n",
    "          (16, 32), \n",
    "          (32, 64), \n",
    "          (64, 128), \n",
    "          (flattened_size, z_dim)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"Model Classes/cnn_model.ipynb\"\n",
    "\n",
    "\n",
    "# pcmra = next(iter(train_dataloader))[3]\n",
    "# print(\"pcmra:\", pcmra.shape)\n",
    "\n",
    "# out = cnn(pcmra)\n",
    "# print(\"out:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "siren = SirenGenerator(dim=z_dim, dim_hidden=256).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wd = 0\n",
    "\n",
    "siren_optim = torch.optim.Adam(params=siren.parameters(), weight_decay=wd)\n",
    "cnn_optim = torch.optim.Adam(params=cnn.parameters(), weight_decay=wd)\n",
    "\n",
    "# def l2_loss(out, ground_truth): \n",
    "#     return ((out - ground_truth)**2).mean()\n",
    "\n",
    "# criterion = l2_loss\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_optim.param_groups[0]['lr'] = 5e-5\n",
    "siren_optim.param_groups[0]['lr'] = 5e-5\n",
    "print(siren_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = \"Models/PI-Gan 02-04-2021 16:20:46 mask_complete dataset_n 30000/\"\n",
    "\n",
    "# best_loss = \"train\"\n",
    "\n",
    "# cnn.load_state_dict(torch.load(f\"{folder}/cnn_{best_loss}.pt\"))\n",
    "# cnn_optim.load_state_dict(torch.load(f\"{folder}/cnn_optim_{best_loss}.pt\"))\n",
    "\n",
    "# siren.load_state_dict(torch.load(f\"{folder}/siren_{best_loss}.pt\"))\n",
    "# siren_optim.load_state_dict(torch.load(f\"{folder}/siren_optim_{best_loss}.pt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Train model\n",
    "for pcmra array with linear output, 0.000500 is good.\n",
    "\n",
    "\n",
    "for mask with sigmoid output and BCE, 0.02 is good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "print_every = 5\n",
    "\n",
    "aggregate_gradient = 10\n",
    "batches = 0\n",
    "\n",
    "# n = 393216\n",
    "n = 30000\n",
    "\n",
    "output_type = \"mask\"\n",
    "dataset = \"complete\"\n",
    "\n",
    "\n",
    "folder = f\"PI-Gan {dt} {output_type}_{dataset} dataset_n {n}\"\n",
    "\n",
    "Path(f\"Models/{folder}\").mkdir(parents=True, exist_ok=True)   \n",
    "print(f\"Creating path \\\\Models\\\\{folder}\")\n",
    "    \n",
    "\n",
    "\n",
    "for ep in range(epochs):\n",
    "    \n",
    "    t = time.time() \n",
    "    \n",
    "    cnn.train()\n",
    "    siren.train()\n",
    "\n",
    "    losses = []\n",
    "        \n",
    "    for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in train_dataloader:\n",
    "        siren_in, _, siren_labels = choose_random_coords(coords, pcmra_array, mask_array, n=n)\n",
    "\n",
    "        cnn_out = cnn(pcmra)\n",
    "        siren_out = siren(cnn_out, siren_in)\n",
    "        \n",
    "        loss = criterion(siren_out, siren_labels) \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss = loss / train_ds.__len__()\n",
    "        loss.backward()\n",
    "        \n",
    "        batches += 1\n",
    "\n",
    "        if batches % aggregate_gradient == 0: \n",
    "            siren_optim.step()\n",
    "            cnn_optim.step()   \n",
    "            \n",
    "            siren_optim.zero_grad()\n",
    "            cnn_optim.zero_grad()\n",
    "    \n",
    "\n",
    "    if ep % print_every == 0: \n",
    "        \n",
    "        print(f\"Epoch {ep} took {round(time.time() - t)} seconds.\")\n",
    "        \n",
    "        best_train_loss = save_model(best_train_loss, losses, dataset=\"train\")\n",
    "        \n",
    "        val_losses = []\n",
    "        \n",
    "        for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in val_dataloader:    \n",
    "            siren_out = get_complete_image(pcmra, coords)\n",
    "            loss = criterion(siren_out, mask_array)            \n",
    "        \n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "        best_val_loss = save_model(best_val_loss, val_losses, dataset=\"val\")\n",
    "                \n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx, subj, proj, pcmra, coords, pcmra_array, mask_array = next(iter(val_dataloader))\n",
    "# # pcmra, coords = pcmra.unsqueeze(0), coords.unsqueeze(0)\n",
    "# # pcmra_array, mask_array =  pcmra_array.unsqueeze(0), mask_array.unsqueeze(0)\n",
    "\n",
    "# siren_out = get_complete_image(pcmra, coords)\n",
    "# loss = criterion(siren_out, mask_array)            \n",
    "\n",
    "# print(f\"{subj}, loss: {loss}\")\n",
    "\n",
    "# def arrays_to_numpy(*arrays): \n",
    "#     print(arrays)\n",
    "    \n",
    "    \n",
    "# slic = 8\n",
    "\n",
    "# # shape = (128, 128, 24)\n",
    "# shape = (64, 64, 24)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(12,12))\n",
    "# axes[0].imshow(pcmra_array.cpu().view(shape).detach().numpy()[:, :, slic])\n",
    "# axes[1].imshow(mask_array.cpu().view(shape).detach().numpy()[:, :, slic])\n",
    "# # axes[2].imshow(siren_out.cpu().view(shape).detach().numpy()[:, :, slic])\n",
    "# axes[2].imshow(siren_out.cpu().view(shape).detach().numpy().round()[:, :, slic])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in val_dataloader: \n",
    "    \n",
    "    \n",
    "#     siren_out = get_complete_image(pcmra, coords)\n",
    "#     loss = criterion(siren_out, mask_array)            \n",
    "\n",
    "#     print(subj, loss.item()) \n",
    "\n",
    "#     slic = 12\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(12,12))\n",
    "#     axes[0].imshow(pcmra_array.cpu().view(128, 128, 24).detach().numpy()[:, :, slic])\n",
    "#     axes[1].imshow(mask_array.cpu().view(128, 128, 24).detach().numpy()[:, :, slic])\n",
    "#     axes[2].imshow(siren_out.cpu().view(128, 128, 24).detach().numpy().round()[:, :, slic])\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_through_output(shape=(64, 64, 24)):\n",
    "    pcmras = masks = outs = torch.Tensor([])\n",
    "    titles = []\n",
    "\n",
    "    for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in val_dataloader: \n",
    "\n",
    "        siren_out = get_complete_image(pcmra, coords)\n",
    "        loss = criterion(siren_out, mask_array) \n",
    "\n",
    "        pcmras = torch.cat((pcmras, pcmra_array.cpu().view(shape).detach()), 2)\n",
    "        masks = torch.cat((masks, mask_array.cpu().view(shape).detach()), 2)\n",
    "        outs = torch.cat((outs, siren_out.cpu().view(shape).detach()), 2)\n",
    "\n",
    "        titles += [subj[0] + \" \" + proj[0] for i in range(shape[2])]\n",
    "\n",
    "    return Show_images(titles, (pcmras.numpy(), \"pcmras\"), (masks.numpy(), \"masks\"), (outs.numpy(), \"outs\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = scroll_through_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    PARSER = argparse.ArgumentParser()\n",
    "\n",
    "    # Arguments for training\n",
    "    PARSER.add_argument('--name', type=str, default=\"\", \n",
    "                        help='Name of the folder where the output should be saved.')\n",
    "    \n",
    "    PARSER.add_argument('--dataset', type=str, default=\"small\", \n",
    "                        help='The dataset which we train on.')\n",
    "    \n",
    "    PARSER.add_argument('--epochs', type=int, default=500, \n",
    "                        help='Number of epochs.')\n",
    "    \n",
    "    PARSER.add_argument('--acc_steps', type=int, default=10, \n",
    "                        help='Number of subjects that the gradient is \\\n",
    "                        accumulated over before taking an optim step.')\n",
    "    \n",
    "    PARSER.add_argument('--shuffle', type=bool, default=True, \n",
    "                        help='Shuffle the train dataloader?')\n",
    "    \n",
    "    PARSER.add_argument('--norm_min_max', type=list, default=[0, 1], \n",
    "                        help='List with min and max for normalizing input.')\n",
    "    \n",
    "    PARSER.add_argument('--flattened_size', type=int, default=16384, \n",
    "                        help='Size of cnn conv output.')\n",
    "    \n",
    "    PARSER.add_argument('--z_dim', type=int, default=128, \n",
    "                        help='Size of the latent pcmra representation.')\n",
    "    \n",
    "    PARSER.add_argument('--cnn_lr', type=float, default=0, \n",
    "                        help='Learning rate of cnn optim.')\n",
    "\n",
    "    PARSER.add_argument('--siren_lr', type=float, default=0, \n",
    "                        help='Learning rate of siren optim.')\n",
    "\n",
    "    PARSER.add_argument('--cnn_wd', type=float, default=0, \n",
    "                        help='Weight decay of cnn optim.')\n",
    "\n",
    "    PARSER.add_argument('--siren_wd', type=float, default=0, \n",
    "                        help='Weight decay of siren optim.')\n",
    "    \n",
    "    PARSER.add_argument('--eval_every', type=int, default=10, \n",
    "                        help='Set the # epochs after which evaluation should be done.')\n",
    "    \n",
    "    ARGS = PARSER.parse_args()\n",
    "    \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS(object): \n",
    "    def __init__(self): \n",
    "        self.dataset = \"small\"\n",
    "        self.epochs = 500\n",
    "        self.acc_steps = 10\n",
    "        self.shuffle = True\n",
    "        self.norm_min_max = [0, 1]\n",
    "        self.shuffle = True\n",
    "        self.flattened_size = 16384\n",
    "        self.z_dim = 128\n",
    "        self.shuffle = True\n",
    "        self.cnn_lr = 0\n",
    "        self.siren_lr = 0\n",
    "        self.cnn_wd = 0\n",
    "        self.siren_wd = 0\n",
    "        self.eval_every = 10\n",
    "        \n",
    "train()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
