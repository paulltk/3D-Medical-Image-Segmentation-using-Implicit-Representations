{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Kopie van seq_pi_gan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9yeZRQtBNXlg"},"source":["#### Colab run"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkezriwYKMI1","executionInfo":{"status":"ok","timestamp":1624616182535,"user_tz":-120,"elapsed":19822,"user":{"displayName":"Paul ten Kaate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihEcWnD7dnWVuLjWRFp5A0AGfS2b-MdUZ0Bmclse4=s64","userId":"16522113836666229259"}},"outputId":"b18b0cd4-3dca-4cc0-b79f-81b6434b6034"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxfXBh-4Mq7g","executionInfo":{"status":"ok","timestamp":1624616182976,"user_tz":-120,"elapsed":449,"user":{"displayName":"Paul ten Kaate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihEcWnD7dnWVuLjWRFp5A0AGfS2b-MdUZ0Bmclse4=s64","userId":"16522113836666229259"}},"outputId":"8621aec9-ec1e-430c-b5e0-3f5da5d9088a"},"source":["cd drive/MyDrive/master_thesis/pi-gan_sequential"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/16udig9ZMaNcASs5Maj6kv7tg-TL3PnSE/Master Thesis/pi-gan_sequential\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"diXDczG5Y-79","executionInfo":{"status":"ok","timestamp":1624616191126,"user_tz":-120,"elapsed":8155,"user":{"displayName":"Paul ten Kaate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihEcWnD7dnWVuLjWRFp5A0AGfS2b-MdUZ0Bmclse4=s64","userId":"16522113836666229259"}},"outputId":"41e64f39-6cf0-43f9-b6c9-7f0b74e52f5a"},"source":["!pip install kornia\n","!pip install torchinfo"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting kornia\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/74/5473a402191071754abf32b69efdefc48194210d14f6d4904bcb3547d9ad/kornia-0.5.4-py2.py3-none-any.whl (285kB)\n","\r\u001b[K     |█▏                              | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 11.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 92kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kornia) (1.19.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->kornia) (3.7.4.3)\n","Installing collected packages: kornia\n","Successfully installed kornia-0.5.4\n","Collecting torchinfo\n","  Downloading https://files.pythonhosted.org/packages/e7/d3/11f9901d75f4d105b2b1700c81f83579fd33c4cf0ec88bb7a165d96c7bb4/torchinfo-0.1.5-py3-none-any.whl\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-0.1.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oLM-4phiTeNM"},"source":["#### End Colab run"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdmZCajHJ73l","tags":[],"executionInfo":{"status":"ok","timestamp":1624616209712,"user_tz":-120,"elapsed":18592,"user":{"displayName":"Paul ten Kaate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihEcWnD7dnWVuLjWRFp5A0AGfS2b-MdUZ0Bmclse4=s64","userId":"16522113836666229259"}},"outputId":"a881c5bc-ec19-4564-b739-06e27fc0b3cf"},"source":["import warnings\n","import time\n","\n","from py_files.args import *\n","\n","from py_files.functions import *\n","\n","from py_files.dataset import *\n","\n","from py_files.cnn_model import *\n","from py_files.pigan_model import *\n","\n","from py_files.load_utils import *\n","from py_files.data_utils import *\n","from py_files.plot_utils import *\n","from py_files.train_utils import *\n","from py_files.save_utils import *"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Imported CNN and Mapping functions.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/kornia/augmentation/augmentation.py:1833: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n","  category=DeprecationWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RXGVJS5sJ73n"},"source":["#### Train the model"]},{"cell_type":"code","metadata":{"id":"FW0Qoi6lJ73n","executionInfo":{"status":"ok","timestamp":1624616209717,"user_tz":-120,"elapsed":10,"user":{"displayName":"Paul ten Kaate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihEcWnD7dnWVuLjWRFp5A0AGfS2b-MdUZ0Bmclse4=s64","userId":"16522113836666229259"}}},"source":["def train():  \n","    \n","    warnings.filterwarnings(\"ignore\")\n","    \n","    ##### path to wich the model should be saved #####\n","    path = get_folder(ARGS)\n","    DEVICE = set_device(ARGS)\n","    \n","    with open(os.path.join(path, \"ARGS.txt\"), \"w\") as f:\n","        print(vars(ARGS), file=f)\n","        \n","    ##### data preparation #####\n","    train_dl, val_dl, test_dl = initialize_dataloaders(ARGS, DEVICE)\n","    print(\"train batch:\", next(iter(train_dl))[1][:5])\n","    print(\"eval batch:\", next(iter(val_dl))[1][:5])\n","    print(\"test batch:\", next(iter(test_dl))[1][:5])\n","            \n","    ##### initialize models and optimizers #####\n","    models, optims, schedulers = initialize_models_and_optims(ARGS, DEVICE)\n","    \n","    blur_layer = initialize_blurring_layer(1.0, DEVICE)\n","    \n","    ##### load pretrained model #####\n","    load_from_saved_run(models, optims, DEVICE, ARGS)\n","\n","    ##### loss function #####\n","    criterions = [nn.BCELoss(), nn.MSELoss()]\n","        \n","    ##### epoch, train loss mean, train loss std, val loss mean, val loss std #####\n","    mask_losses, pcmra_losses, dice_losses = np.empty((0, 5)), np.empty((0, 5)), np.empty((0, 5))\n","    \n","    for ep in range(ARGS.pcmra_epochs):\n","    \n","        t = time.time() \n","\n","        for model in models.values():\n","            model.train()\n","\n","        loss, _ = train_model(train_dl, models, optims, schedulers, criterions[1], blur_layer, ARGS, output=\"pcmra\")\n","        \n","        if ep % ARGS.eval_every == 0: \n","\n","            print(f\"Epoch {ep} took {round(time.time() - t, 2)} seconds.\")\n","            \n","            t_pcmra_mean, t_pcmra_std, _, _ = \\\n","                val_model(train_dl, models, criterions[1], blur_layer, ARGS, output=\"pcmra\")\n","            v_pcmra_mean, v_pcmra_std, _, _ = \\\n","                val_model(val_dl, models, criterions[1], ARGS, output=\"pcmra\")\n","\n","            pcmra_losses = np.append(pcmra_losses, [[ep ,t_pcmra_mean, t_pcmra_std, \n","                                         v_pcmra_mean, v_pcmra_std]], axis=0)\n","            \n","            save_loss(path, pcmra_losses, models, optims, name=\"pcmra_loss\", \n","                      save_models=True)\n","        \n","    \n","    for ep in range(ARGS.mask_epochs):\n","    \n","        t = time.time() \n","\n","        for model in models.values():\n","            model.train()\n","\n","        loss, _ = train_model(train_dl, models, optims, schedulers, criterions[0], blur_layer, ARGS, output=\"mask\")\n","        \n","        if ep % ARGS.eval_every == 0: \n","\n","            print(f\"Epoch {ep} took {round(time.time() - t, 2)} seconds.\")\n","            \n","            t_mask_mean, t_mask_std, t_dice_mean, t_dice_std = \\\n","                val_model(train_dl, models, criterions[0], blur_layer, ARGS, output=\"mask\")\n","            v_mask_mean, v_mask_std, v_dice_mean, v_dice_std = \\\n","                val_model(val_dl, models, criterions[0], blur_layer, ARGS, output=\"mask\")\n","\n","            mask_losses = np.append(mask_losses, [[ep ,t_mask_mean, t_mask_std, \n","                                         v_mask_mean, v_mask_std]], axis=0)\n","            dice_losses = np.append(dice_losses, [[ep ,t_dice_mean, t_dice_std, \n","                                         v_dice_mean, v_dice_std]], axis=0)\n","            \n","            save_loss(path, mask_losses, models, optims, name=\"mask_loss\", \n","                      save_models=True)\n","            save_loss(path, dice_losses, models, optims, name=\"dice_loss\", \n","                      save_models=False)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TCWHjP8GJ73q"},"source":["## Run as .ipynb"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSjdoRDcJ73r","scrolled":true,"outputId":"0db1f9cc-6217-46ab-9bb1-ad558f80a9e1"},"source":["for cnn_setup, mapping_setup in [(-1, -1)]:\n","\n","    ARGS = init_ARGS()\n","        \n","    ARGS.pcmra_epochs = 0\n","    \n","    ARGS.patience = 100 \n","    \n","    ARGS.flip = True \n","    ARGS.crop = True \n","    ARGS.rotate = True \n","    ARGS.translate = True\n","\n","    ARGS.sdf = False \n","    ARGS.sdf_split = None\n","    \n","    print(vars(ARGS))\n","\n","    train()  \n","\n","    torch.cuda.empty_cache()    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING: ARGS class initialized.\n","{'device': 'GPU', 'print_models': False, 'name': '', 'pretrained': None, 'pretrained_best_dataset': 'train', 'pretrained_best_loss': 'mask', 'pretrained_models': None, 'pretrained_lr_reset': None, 'dataset': 'new', 'seed': 34, 'rotate': True, 'translate': True, 'translate_max_pixels': 20, 'flip': True, 'crop': True, 'stretch': True, 'stretch_factor': 1.2, 'norm_min_max': [0, 1], 'pcmra_epochs': 0, 'mask_epochs': 5000, 'batch_size': 24, 'eval_every': 50, 'shuffle': True, 'n_coords_sample': 5000, 'min_lr': 1e-05, 'cnn_setup': -1, 'pcmra_train_cnn': True, 'mask_train_cnn': True, 'mapping_setup': -1, 'dim_hidden': 256, 'siren_hidden_layers': 3, 'first_omega_0': 30.0, 'hidden_omega_0': 30.0, 'pcmra_first_omega_0': 30.0, 'pcmra_hidden_omega_0': 30.0, 'cnn_lr': 0.0001, 'cnn_wd': 0, 'mapping_lr': 0.0001, 'pcmra_mapping_lr': 0.0001, 'siren_lr': 0.0001, 'siren_wd': 0, 'pcmra_siren_lr': 0.0001, 'pcmra_siren_wd': 0, 'patience': 100, 'sdf': False, 'sdf_split': None}\n","saved_runs/pi_gan_2021_06_25_10_16_49\n","----------------------------------\n","Using device for training: cuda\n","----------------------------------\n","Train subjects: 86\n","Val subjects: 29\n","Test subjects: 29\n","train batch: ('82', '64', '71', '110', '10')\n","eval batch: ('119', '111', '118', '132', '127')\n","test batch: ('105', '113', '109', '120', '116')\n","CNN\n","MAPPING\n","SIREN\n","PCMRA_MAPPING\n","PCMRA_SIREN\n","Epoch 0 took 4.16 seconds.\n","mask_loss       Train: 0.581151, \t Eval: 0.580735\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 1.000000, \t Eval: 1.000000\n","Epoch 50 took 4.51 seconds.\n","mask_loss       Train: 0.122330, \t Eval: 0.126908\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 1.000000, \t Eval: 1.000000\n","Epoch 100 took 4.47 seconds.\n","mask_loss       Train: 0.088010, \t Eval: 0.091197\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.808804, \t Eval: 0.813709\n","Epoch 150 took 4.48 seconds.\n","mask_loss       Train: 0.075374, \t Eval: 0.080391\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.601191, \t Eval: 0.598875\n","Epoch 200 took 4.49 seconds.\n","mask_loss       Train: 0.068911, \t Eval: 0.070870\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.658369, \t Eval: 0.620102\n","Epoch 250 took 4.49 seconds.\n","mask_loss       Train: 0.062418, \t Eval: 0.064408\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.467308, \t Eval: 0.467930\n","Epoch 300 took 4.46 seconds.\n","mask_loss       Train: 0.052057, \t Eval: 0.054202\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.376506, \t Eval: 0.379175\n","Epoch 350 took 4.48 seconds.\n","mask_loss       Train: 0.047419, \t Eval: 0.050098\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.367824, \t Eval: 0.363705\n","Epoch 400 took 4.45 seconds.\n","mask_loss       Train: 0.046511, \t Eval: 0.051254\n","New best train loss, saving model.\n","dice_loss       Train: 0.377418, \t Eval: 0.379591\n","Epoch 450 took 4.46 seconds.\n","mask_loss       Train: 0.043497, \t Eval: 0.046493\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.329103, \t Eval: 0.330057\n","Epoch 500 took 4.49 seconds.\n","mask_loss       Train: 0.041357, \t Eval: 0.043618\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.319853, \t Eval: 0.303356\n","Epoch 550 took 4.48 seconds.\n","mask_loss       Train: 0.040613, \t Eval: 0.043565\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.331435, \t Eval: 0.311922\n","Epoch 600 took 4.44 seconds.\n","mask_loss       Train: 0.042118, \t Eval: 0.045001\n","dice_loss       Train: 0.353212, \t Eval: 0.351115\n","Epoch 650 took 4.45 seconds.\n","mask_loss       Train: 0.040312, \t Eval: 0.043214\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.342000, \t Eval: 0.318232\n","Epoch 700 took 4.48 seconds.\n","mask_loss       Train: 0.038431, \t Eval: 0.042185\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.297160, \t Eval: 0.292760\n","Epoch 750 took 4.48 seconds.\n","mask_loss       Train: 0.040696, \t Eval: 0.045544\n","dice_loss       Train: 0.328787, \t Eval: 0.328090\n","Epoch   761: reducing learning rate of group 0 to 5.0000e-05.\n","Epoch   761: reducing learning rate of group 0 to 5.0000e-05.\n","Epoch   761: reducing learning rate of group 0 to 5.0000e-05.\n","Epoch 800 took 4.47 seconds.\n","mask_loss       Train: 0.033606, \t Eval: 0.037620\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.253008, \t Eval: 0.250139\n","Epoch 850 took 4.46 seconds.\n","mask_loss       Train: 0.033924, \t Eval: 0.038034\n","dice_loss       Train: 0.276160, \t Eval: 0.278384\n","Epoch 900 took 4.46 seconds.\n","mask_loss       Train: 0.030907, \t Eval: 0.036260\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.249968, \t Eval: 0.262683\n","Epoch 950 took 4.48 seconds.\n","mask_loss       Train: 0.030425, \t Eval: 0.035659\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.233307, \t Eval: 0.254004\n","Epoch 1000 took 4.48 seconds.\n","mask_loss       Train: 0.031134, \t Eval: 0.035690\n","dice_loss       Train: 0.236968, \t Eval: 0.247512\n","Epoch 1050 took 4.48 seconds.\n","mask_loss       Train: 0.031053, \t Eval: 0.036548\n","dice_loss       Train: 0.230331, \t Eval: 0.259861\n","Epoch 1100 took 4.49 seconds.\n","mask_loss       Train: 0.029364, \t Eval: 0.034305\n","New best train loss, saving model.\n","New best eval  loss, saving model.\n","dice_loss       Train: 0.231571, \t Eval: 0.238974\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QaZkO5-eTeNV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fHqsyQs5J73t"},"source":["## Run as .py"]},{"cell_type":"code","metadata":{"id":"e4YS9Jm4J73u"},"source":["def str2bool(v):\n","    if isinstance(v, bool):\n","        return v\n","    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n","        return True\n","    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n","        return False\n","    else:\n","        raise argparse.ArgumentTypeError('Boolean value expected.')\n","\n","if __name__ == \"__main__\":\n","\n","    PARSER = argparse.ArgumentParser()\n","\n","    \n","    # Arguments for training\n","    PARSER.add_argument('--device', type=str, default=\"GPU\", \n","                        help='Device that should be used.')\n","\n","    PARSER.add_argument('--print_models', type=str2bool, nargs=\"?\", const=True, default=False, \n","                        help='Print the models after initialization or not.')\n","\n","    PARSER.add_argument('--name', type=str, default=\"\", \n","                        help='Name of the folder where the output should be saved.')\n","    \n","    \n","\n","    # pretrained params \n","    \n","    PARSER.add_argument('--pretrained', type=str, default=None, \n","                        help='Folder name of pretrained model that should be loaded.')\n","    \n","    PARSER.add_argument('--pretrained_best_dataset', type=str, default=\"train\", \n","                        help='Pretrained model with lowest [train, val] loss.')\n","    \n","    PARSER.add_argument('--pretrained_best_loss', type=str, default=\"mask\", \n","                        help='Pretrained model with lowest [train, val] loss.')\n","    \n","    PARSER.add_argument('--pretrained_models', type=str, default=None, \n","                        help='Choose which pretrained models to load. None = all models')\n","    \n","    PARSER.add_argument('--pretrained_lr_reset', type=str, default=None, \n","                        help='Reset the lr to a value.')\n","    \n","    \n","    \n","    # data\n","    PARSER.add_argument('--dataset', type=str, default=\"new\", \n","                        help='The dataset which we train on.')\n","    \n","    PARSER.add_argument('--seed', type=int, default=34, \n","                        help='Seed for initializig dataloader')\n","    \n","    PARSER.add_argument('--rotate', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Rotations of the same image')\n","    \n","    PARSER.add_argument('--translate', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Translations of the same image')\n","    \n","    PARSER.add_argument('--translate_max_pixels', type=int, default=20, \n","                        help='Translation max in height and width.')\n","    \n","    PARSER.add_argument('--flip', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Flips the train image')\n","    \n","    PARSER.add_argument('--crop', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Crops the train image')\n","\n","    PARSER.add_argument('--stretch', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Stretches the train image')\n","\n","    PARSER.add_argument('--stretch_factor', type=float, default=1.2, \n","                        help='Stretch maximum of the train image')\n","\n","    PARSER.add_argument('--norm_min_max', type=list, default=[0, 1], \n","                        help='List with min and max for normalizing input.')\n","    \n","    \n","    \n","    # train variables\n","    PARSER.add_argument('--pcmra_epochs', type=int, default=5000, \n","                        help='Number of epochs for pcmra training.')\n","\n","    PARSER.add_argument('--mask_epochs', type=int, default=5000, \n","                        help='Number of epochs for mask training.')\n","    \n","    PARSER.add_argument('--batch_size', type=int, default=24, \n","                        help='Number of epochs.')\n","        \n","    PARSER.add_argument('--eval_every', type=int, default=50, \n","                        help='Set the # epochs after which evaluation should be done.')\n","    \n","    PARSER.add_argument('--shuffle', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Shuffle the train dataloader?')\n","    \n","    PARSER.add_argument('--n_coords_sample', type=int, default=5000, \n","                        help='Number of coordinates that should be sampled for each subject.')\n","    \n","    PARSER.add_argument('--min_lr', type=float, default=1e-5, \n","                        help='Minimum lr, input for lr scheduler.')\n","    \n","    \n","    \n","    # CNN\n","    PARSER.add_argument('--cnn_setup', type=int, default=-1, \n","                        help='Setup of the CNN.')\n","    \n","    PARSER.add_argument('--pcmra_train_cnn', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Whether to also train the cnn during pcmra reconstruction.')\n","\n","    PARSER.add_argument('--mask_train_cnn', type=str2bool, nargs=\"?\", const=True, default=True, \n","                        help='Whether to also train the cnn during mask segmentation.')\n","\n","\n","    \n","    # Mapping\n","    PARSER.add_argument('--mapping_setup', type=int, default=-1, \n","                        help='Setup of the Mapping network.')\n","\n","    \n","    \n","    # SIREN\n","    PARSER.add_argument('--dim_hidden', type=int, default=256, \n","                        help='Dimension of hidden SIREN layers.')\n","    \n","    PARSER.add_argument('--siren_hidden_layers', type=int, default=3, \n","                        help='Number of hidden SIREN layers.')\n","    \n","    \n","    PARSER.add_argument('--first_omega_0', type=float, default=30., \n","                        help='Omega_0 of first layer.')\n","    \n","    PARSER.add_argument('--hidden_omega_0', type=float, default=30., \n","                        help='Omega_0 of hidden layer.')\n","    \n","    \n","    PARSER.add_argument('--pcmra_first_omega_0', type=float, default=30., \n","                        help='Omega_0 of first layer of PCMRA siren.')\n","    \n","    PARSER.add_argument('--pcmra_hidden_omega_0', type=float, default=30., \n","                        help='Omega_0 of hidden layer of PCMRA siren.')\n","    \n","    \n","    \n","    # optimizers\n","    PARSER.add_argument('--cnn_lr', type=float, default=1e-4, \n","                        help='Learning rate of cnn optim.')\n","\n","    PARSER.add_argument('--cnn_wd', type=float, default=0, \n","                        help='Weight decay of cnn optim.')\n","\n","    \n","    PARSER.add_argument('--mapping_lr', type=float, default=1e-4, \n","                        help='Learning rate of siren optim.')\n","    \n","    PARSER.add_argument('--pcmra_mapping_lr', type=float, default=1e-4, \n","                        help='Learning rate of siren optim.')\n","    \n","\n","    PARSER.add_argument('--siren_lr', type=float, default=1e-4, \n","                        help='Learning rate of siren optim.')\n","\n","    PARSER.add_argument('--siren_wd', type=float, default=0, \n","                        help='Weight decay of siren optim.')\n","    \n","    \n","    PARSER.add_argument('--pcmra_siren_lr', type=float, default=1e-4, \n","                        help='Learning rate of PCMRA siren optim.')    \n","    \n","    PARSER.add_argument('--pcmra_siren_wd', type=float, default=0, \n","                        help='Weight decay of PCMRA siren optim.')\n","    \n","    PARSER.add_argument('--patience', type=int, default=200, \n","                        help='Patience of the LR scheduler.')\n","    \n","    \n","    ARGS = PARSER.parse_args()\n","    \n","    train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N78yDqQtTeNb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNdqEEccTeNc"},"source":[""],"execution_count":null,"outputs":[]}]}