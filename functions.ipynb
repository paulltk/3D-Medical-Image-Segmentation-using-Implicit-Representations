{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported CNN model.\n",
      "Imported PI-Gan model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import math \n",
    "import skimage\n",
    "import pickle\n",
    "import ast\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mplPath\n",
    "import pylab as pl\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from threading import Timer\n",
    "from PIL import Image\n",
    "\n",
    "# from data_classes.py_files.custom_datasets import *\n",
    "from data_classes.py_files.new_dataset import *\n",
    "\n",
    "from model_classes.py_files.cnn_model import *\n",
    "from model_classes.py_files.pigan_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARGS class for .ipynb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class init_ARGS(object): \n",
    "    def __init__(self): \n",
    "        self.device = \"GPU\"\n",
    "        self.print_models = \"GPU\"\n",
    "        self.name = \"\"\n",
    "        self.pretrained = None\n",
    "        self.pretrained_best = \"train\"\n",
    "        self.reconstruction = \"pcmra\"\n",
    "        self.share_mapping = True\n",
    "        self.pcmra_lambda = 1.\n",
    "        self.mask_lambda = 1.\n",
    "        self.dataset = \"small\"\n",
    "        self.rotate = True\n",
    "        self.translate = True\n",
    "        self.flip = True\n",
    "        self.norm_min_max = [0, 1]\n",
    "        self.seed = 34\n",
    "        self.epochs = 51\n",
    "        self.batch_size = 24\n",
    "        self.eval_every = 5\n",
    "        self.shuffle = True\n",
    "        self.n_coords_sample = 5000\n",
    "        self.cnn_setup = 1\n",
    "        self.mapping_setup = 1\n",
    "        self.dim_hidden = 256\n",
    "        self.siren_hidden_layers = 3\n",
    "        self.first_omega_0 = 30.\n",
    "        self.hidden_omega_0 = 30.\n",
    "        self.pcmra_first_omega_0 = 30.\n",
    "        self.pcmra_hidden_omega_0 = 30.\n",
    "        self.cnn_lr = 1e-4\n",
    "        self.cnn_wd = 0\n",
    "        self.mapping_lr = 1e-4\n",
    "        self.pcmra_mapping_lr = 1e-4\n",
    "        self.siren_lr = 1e-4\n",
    "        self.siren_wd = 0\n",
    "        self.pcmra_siren_lr = 1e-4\n",
    "        self.pcmra_siren_wd = 0\n",
    "        self.scheduler_on = \"combined\"\n",
    "\n",
    "        print(\"WARNING: ARGS class initialized.\")\n",
    "\n",
    "    def set_args(self, dictionary):\n",
    "        for k, v in dictionary.items():\n",
    "            setattr(self, k, v)\n",
    "          \n",
    "        \n",
    "def load_args(run, print_changed=True):\n",
    "    run_path = os.path.join(\"saved_runs\", run, \"ARGS.txt\")\n",
    "\n",
    "    with  open(run_path, \"r\") as f:\n",
    "        contents = f.read()\n",
    "        args_dict = ast.literal_eval(contents)\n",
    "    \n",
    "    ARGS = init_ARGS()\n",
    "    \n",
    "    old_args = vars(ARGS)\n",
    "    \n",
    "    if print_changed:\n",
    "        for k, v in args_dict.items(): \n",
    "            if k in old_args.keys(): \n",
    "                if old_args[k] != v: \n",
    "                    print(f\"Changed param \\t{k}: {v}.\") \n",
    "            else:\n",
    "                print(f\"New param \\t{k}: {v}.\")\n",
    "            \n",
    "    ARGS.set_args(args_dict)\n",
    "    \n",
    "    return ARGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Using device for training: cuda\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "def set_device():\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    print('Using device for training:', DEVICE)\n",
    "    print('----------------------------------')\n",
    "\n",
    "    return DEVICE \n",
    "\n",
    "# DEVICE = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model saving functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder(ARGS): \n",
    "    now = datetime.now()\n",
    "    dt = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    path = f\"saved_runs/pi-gan {dt} {ARGS.name}\"\n",
    "    \n",
    "    Path(f\"{path}\").mkdir(parents=True, exist_ok=True)   \n",
    "\n",
    "    return path\n",
    "    \n",
    "\n",
    "def plot_graph(path, x, ys_and_labels, axes=(\"Epochs\", \"BCELoss\"), fig_name=\"loss_plot\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    for y, label in ys_and_labels: \n",
    "        ax.plot(x[1:], y[1:], label=label)\n",
    "\n",
    "    plt.xlabel(axes[0])\n",
    "    plt.ylabel(axes[1])\n",
    "    legend = ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.savefig(f\"{path}/{fig_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def save_info(path, mask_losses, pcmra_losses, dice_losses, models, optims, save_last=False): \n",
    "    \n",
    "    np.save(f\"{path}/losses.npy\", mask_losses)\n",
    "    np.save(f\"{path}/pcmra_losses.npy\", pcmra_losses)\n",
    "    np.save(f\"{path}/dice_losses.npy\", dice_losses)\n",
    "    \n",
    "    eps = mask_losses[:, 0]\n",
    "    \n",
    "    train_m_losses = mask_losses[:, 1]\n",
    "    val_m_losses = mask_losses[:, 3]\n",
    "    \n",
    "    train_p_losses = pcmra_losses[:, 1]\n",
    "    val_p_losses = pcmra_losses[:, 3]\n",
    "    \n",
    "    train_d_losses = dice_losses[:, 1]\n",
    "    val_d_losses = dice_losses[:, 3]\n",
    "    \n",
    "    print(f\"Train mask loss: \\t {round(train_m_losses[-1], 5)}, \\\n",
    "    pcmra loss: \\t {round(train_p_losses[-1], 5)}, \\\n",
    "    \\tdice loss: \\t {round(train_d_losses[-1], 5)}.\")\n",
    "    \n",
    "    print(f\"Eval  mask loss: \\t {round(val_m_losses[-1], 5)}, \\\n",
    "    pcmra loss: \\t {round(val_p_losses[-1], 5)}, \\\n",
    "    \\tdice loss: \\t {round(val_d_losses[-1], 5)}.\")\n",
    "\n",
    "    if train_m_losses[-1] == train_m_losses.min() or save_last: \n",
    "        print(f\"New best train loss, saving model.\")\n",
    "\n",
    "        for model in models.keys():\n",
    "            torch.save(models[model].state_dict(), f\"{path}/{model}_train.pt\")\n",
    "            torch.save(optims[model].state_dict(), f\"{path}/{model}_optim_train.pt\")\n",
    "        \n",
    "    \n",
    "    if val_m_losses[-1] == val_m_losses.min(): \n",
    "        print(f\"New best val loss, saving model.\")\n",
    "\n",
    "        for model in models.keys():\n",
    "            torch.save(models[model].state_dict(), f\"{path}/{model}_val.pt\")\n",
    "            torch.save(optims[model].state_dict(), f\"{path}/{model}_optim_val.pt\")\n",
    "\n",
    "    plot_graph(path, eps, [(train_m_losses, \"Train loss\"), (val_m_losses, \"Eval loss\")], \n",
    "               axes=(\"Epochs\", \"BCELoss\"), fig_name=\"loss_plot\")\n",
    "    \n",
    "    plot_graph(path, eps, [(train_p_losses, \"Train loss\"), (val_p_losses, \"Eval loss\")], \n",
    "               axes=(\"Epochs\", \"MSELoss\"), fig_name=\"pcmra_loss_plot\")\n",
    "    \n",
    "    plot_graph(path, eps, [(train_d_losses, \"Train dice loss\"), (val_d_losses, \"Eval dice loss\")], \n",
    "               axes=(\"Epochs\", \"Dice Loss\"), fig_name=\"dice_loss_plot\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_dataloaders(projects, ARGS):\n",
    "#     assert(ARGS.dataset in [\"full\", \"small\"])\n",
    "\n",
    "#     data = PrepareData3D(projects, seed=ARGS.seed, image_size=ARGS.dataset, norm_min_max=ARGS.norm_min_max)\n",
    "\n",
    "#     train_ds = SirenDataset(data.train, DEVICE) \n",
    "#     train_dl = DataLoader(train_ds, batch_size=1, num_workers=0, shuffle=ARGS.shuffle)\n",
    "#     print(\"Train subjects:\", train_ds.__len__())\n",
    "\n",
    "#     val_ds = SirenDataset(data.val, DEVICE) \n",
    "#     val_dl = DataLoader(val_ds, batch_size=1, num_workers=0, shuffle=False)\n",
    "#     print(\"Validation subjects:\", val_ds.__len__())\n",
    "    \n",
    "#     test_ds = SirenDataset(data.test, DEVICE) \n",
    "#     test_dl = DataLoader(test_ds, batch_size=1, num_workers=0, shuffle=False)\n",
    "#     print(\"Test subjects:\", test_ds.__len__())\n",
    "    \n",
    "#     return train_dl, val_dl, test_dl\n",
    "    \n",
    "def initialize_dataloaders(ARGS):\n",
    "    \n",
    "    if ARGS.device.lower() == \"cpu\": \n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Using device for training:', DEVICE)\n",
    "        print('----------------------------------')\n",
    "    \n",
    "    else: \n",
    "        DEVICE = set_device()\n",
    "    \n",
    "    \n",
    "    assert(ARGS.dataset in [\"full\", \"small\"])\n",
    "    \n",
    "    root = \"/home/ptenkaate/scratch/Master-Thesis/Dataset/\"\n",
    "    if ARGS.dataset == \"small\":\n",
    "        root += \"scaled_normalized\"\n",
    "    else: \n",
    "        root += \"original_normalized\"\n",
    "    \n",
    "    if ARGS.rotate: \n",
    "        root += \"_rotated\"\n",
    "        \n",
    "    subjects = [file.split(\"__\")[:2] for file in  sorted(os.listdir(root))]\n",
    "    subjects = np.array(sorted([list(subj) for subj in list(set(map(tuple, subjects)))]))\n",
    "    \n",
    "    idx = list(range(subjects.shape[0]))\n",
    "    split1, split2 = int(len(idx) * 0.6), int(len(idx) * 0.8)\n",
    "    \n",
    "    random.seed(ARGS.seed)\n",
    "\n",
    "    random.shuffle(idx) # shuffles indices\n",
    "    train_idx, val_idx, test_idx = idx[:split1], idx[split1:split2], idx[split2:] # incides per data subset\n",
    "\n",
    "    train_subjects, val_subjects, test_subjects =  subjects[train_idx], subjects[val_idx], subjects[test_idx]\n",
    "\n",
    "    train_ds = SirenDataset(root, train_subjects, DEVICE, dataset=\"train\", \n",
    "                            translate=ARGS.translate, flip=ARGS.flip)\n",
    "    train_dl = DataLoader(train_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=ARGS.shuffle)\n",
    "    print(\"Train subjects:\", train_ds.__len__())\n",
    "    print(train_ds.all_images[:10])\n",
    "    \n",
    "    val_ds =  SirenDataset(root, val_subjects, DEVICE, dataset=\"val\")\n",
    "    val_dl = DataLoader(val_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=False)\n",
    "    print(\"Val subjects:\", val_ds.__len__())\n",
    "    \n",
    "    test_ds =  SirenDataset(root, val_subjects, DEVICE, dataset=\"test\")\n",
    "    test_dl = DataLoader(test_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=False)\n",
    "    print(\"Test subjects:\", test_ds.__len__())\n",
    "\n",
    "    return train_dl, val_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_and_optims(ARGS):\n",
    "    \n",
    "    if ARGS.device.lower() == \"cpu\": \n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Using device for training:', DEVICE)\n",
    "        print('----------------------------------')\n",
    "\n",
    "    else: \n",
    "        DEVICE = set_device()\n",
    "        \n",
    "\n",
    "    models = {}\n",
    "    optims = {}\n",
    "    schedulers = {}\n",
    "\n",
    "    models[\"cnn\"] = load_cnn(ARGS).to(DEVICE)\n",
    "    optims[\"cnn\"] = torch.optim.Adam(lr=ARGS.cnn_lr, params=models[\"cnn\"].parameters(), \n",
    "                                     weight_decay=ARGS.cnn_wd)\n",
    "    schedulers[\"cnn\"] = torch.optim.lr_scheduler.ReduceLROnPlateau(optims[\"cnn\"], patience=5, verbose=True)\n",
    "    \n",
    "    models[\"mapping\"] = load_mapping(ARGS).to(DEVICE)\n",
    "    optims[\"mapping\"] = torch.optim.Adam(lr=ARGS.mapping_lr, params=models[\"mapping\"].parameters())\n",
    "    schedulers[\"mapping\"] = torch.optim.lr_scheduler.ReduceLROnPlateau(optims[\"mapping\"], patience=5, verbose=True)\n",
    "\n",
    "    models[\"siren\"] = Siren(ARGS, in_features=3, out_features=1,first_omega_0=ARGS.first_omega_0, \n",
    "                            hidden_omega_0=ARGS.hidden_omega_0).to(DEVICE)\n",
    "    optims[\"siren\"] = torch.optim.Adam(lr=ARGS.siren_lr, params=models[\"siren\"].parameters(),\n",
    "                                       weight_decay=ARGS.siren_wd)           \n",
    "    schedulers[\"siren\"] = torch.optim.lr_scheduler.ReduceLROnPlateau(optims[\"siren\"], patience=5, verbose=True)\n",
    "    \n",
    "    if not ARGS.share_mapping: \n",
    "        models[\"pcmra_mapping\"] = load_mapping(ARGS).to(DEVICE)\n",
    "        optims[\"pcmra_mapping\"] = torch.optim.Adam(lr=ARGS.pcmra_mapping_lr, params=models[\"pcmra_mapping\"].parameters())\n",
    "        schedulers[\"pcmra_mapping\"] = torch.optim.lr_scheduler.ReduceLROnPlateau(optims[\"pcmra_mapping\"], patience=5, verbose=True)\n",
    "    \n",
    "    if ARGS.reconstruction == \"pcmra\" or ARGS.reconstruction == \"both\":\n",
    "        models[\"pcmra_siren\"] = Siren(ARGS, in_features=3, out_features=1, \n",
    "                                      first_omega_0=ARGS.pcmra_first_omega_0, \n",
    "                                      hidden_omega_0=ARGS.pcmra_hidden_omega_0,\n",
    "                                      final_activation=None).to(DEVICE)\n",
    "        optims[\"pcmra_siren\"] = torch.optim.Adam(lr=ARGS.pcmra_siren_lr, params=models[\"pcmra_siren\"].parameters(),\n",
    "                                                 weight_decay=ARGS.pcmra_siren_wd)\n",
    "        schedulers[\"pcmra_siren\"] = torch.optim.lr_scheduler.ReduceLROnPlateau(optims[\"pcmra_siren\"], patience=5, verbose=True)\n",
    "    \n",
    "\n",
    "    for model, struct in models.items(): \n",
    "        print(model.upper())\n",
    "        if ARGS.print_models:\n",
    "            print(struct)\n",
    "\n",
    "    return models, optims, schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Random coords subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_coords(*arrays, n=1000): \n",
    "    \n",
    "    if not n == -1:\n",
    "        mx = arrays[0].shape[1]\n",
    "        rand_idx = random.sample(range(mx), n)\n",
    "    \n",
    "        arrays = [array.detach().clone()[:, rand_idx, :] for array in arrays]\n",
    "    \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice_loss(pred, target):\n",
    "    \n",
    "    smooth = 0.\n",
    "\n",
    "    pred = torch.round(pred)\n",
    "\n",
    "    pflat = pred.flatten()\n",
    "    tflat = target.flatten()\n",
    "    intersection = (pflat * tflat).sum()\n",
    "\n",
    "    A_sum = torch.sum(pflat * pflat)\n",
    "    B_sum = torch.sum(tflat * tflat)\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and validation epoch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, models, optims, schedulers, criterions, batch_count, ARGS):\n",
    "    mask_losses = []\n",
    "    pcmra_losses = []\n",
    "    combined_losses = []\n",
    "    \n",
    "    for _, _, _, pcmra, coords, pcmra_array, mask_array in dataloader:\n",
    "        #choose random coords\n",
    "        siren_in, pcmra_labels, mask_labels = choose_random_coords(coords, pcmra_array, \n",
    "                                                                   mask_array, n=ARGS.n_coords_sample)\n",
    "\n",
    "        # get latent representations\n",
    "        latent_rep = models[\"cnn\"](pcmra)   \n",
    "        \n",
    "        # get reconstructions \n",
    "        if ARGS.reconstruction == \"pcmra\":\n",
    "            if ARGS.share_mapping: \n",
    "                gamma, beta = models[\"mapping\"](latent_rep)\n",
    "                \n",
    "                mask_out = models[\"siren\"](siren_in, gamma.detach(), beta.detach())\n",
    "                pcmra_out = models[\"pcmra_siren\"](siren_in, gamma, beta)\n",
    "            \n",
    "            if not ARGS.share_mapping: \n",
    "                gamma, beta = models[\"mapping\"](latent_rep.detach())\n",
    "                mask_out = models[\"siren\"](siren_in, gamma, beta)\n",
    "\n",
    "                pcmra_gamma, pcmra_beta = models[\"pcmra_mapping\"](latent_rep)\n",
    "                pcmra_out = models[\"pcmra_siren\"](siren_in, pcmra_gamma, pcmra_beta)\n",
    "        \n",
    "        if ARGS.reconstruction == \"both\":\n",
    "            if ARGS.share_mapping: \n",
    "                gamma, beta = models[\"mapping\"](latent_rep)\n",
    "                \n",
    "                mask_out = models[\"siren\"](siren_in, gamma, beta)\n",
    "                pcmra_out = models[\"pcmra_siren\"](siren_in, gamma, beta)\n",
    "            \n",
    "            if not ARGS.share_mapping: \n",
    "                gamma, beta = models[\"mapping\"](latent_rep)\n",
    "                mask_out = models[\"siren\"](siren_in, gamma, beta)\n",
    "\n",
    "                pcmra_gamma, pcmra_beta = models[\"pcmra_mapping\"](latent_rep)\n",
    "                pcmra_out = models[\"pcmra_siren\"](siren_in, pcmra_gamma, pcmra_beta)\n",
    "                \n",
    "        if ARGS.reconstruction == \"mask\":\n",
    "            gamma, beta = models[\"mapping\"](latent_rep)\n",
    "                \n",
    "            mask_out = models[\"siren\"](siren_in, gamma, beta)\n",
    "\n",
    "        #calculate losses\n",
    "        mask_loss = criterions[0](mask_out, mask_labels) \n",
    "        \n",
    "        if ARGS.reconstruction == \"pcmra\" or ARGS.reconstruction == \"both\":\n",
    "            pcmra_loss = criterions[1](pcmra_out, pcmra_labels)\n",
    "            loss = ARGS.mask_lambda * mask_loss + ARGS.pcmra_lambda * pcmra_loss\n",
    "            \n",
    "        else: \n",
    "            pcmra_loss = torch.Tensor([0])\n",
    "            loss = ARGS.mask_lambda * mask_loss\n",
    "        \n",
    "        mask_losses.append(mask_loss.item())\n",
    "        pcmra_losses.append(pcmra_loss.item())\n",
    "        combined_losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        for _, optim in optims.items():\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "    \n",
    "    for _, scheduler in schedulers.items():\n",
    "        if ARGS.scheduler_on == \"pcmra\":\n",
    "            scheduler.step(np.mean(pcmra_losses))\n",
    "        elif ARGS.scheduler_on == \"combined\":\n",
    "            scheduler.step(np.mean(combined_losses))\n",
    "        elif ARGS.scheduler_on == \"mask\":\n",
    "            scheduler.step(np.mean(mask_losses))  \n",
    "        else: \n",
    "            raise(Exception(\"Choose valid scheduler_on for ARGS.\"))\n",
    "    \n",
    "    mean, std = round(np.mean(mask_losses), 6), round(np.std(mask_losses), 6)\n",
    "    p_mean, p_std = round(np.mean(pcmra_losses), 6), round(np.std(pcmra_losses), 6)\n",
    "    \n",
    "    return mean, std, p_mean, p_std, batch_count\n",
    "\n",
    "\n",
    "def val_epoch(dataloader, models, criterions, ARGS, n_eval=100):\n",
    "    with torch.no_grad():\n",
    "        mask_losses = []\n",
    "        pcmra_losses = []\n",
    "        d_losses = []\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in dataloader:    \n",
    "            mask_out = get_complete_image(models, pcmra, coords, ARGS)\n",
    "            \n",
    "            mask_loss = criterions[0](mask_out, mask_array)  \n",
    "            mask_losses.append(mask_loss.item())\n",
    "\n",
    "            d_loss = calc_dice_loss(mask_out, mask_array) \n",
    "            d_losses.append(d_loss.item())\n",
    "            \n",
    "            if ARGS.reconstruction != \"mask\": \n",
    "                pcmra_out = get_complete_image(models, pcmra, coords, ARGS, output=\"pcmra\")\n",
    "                \n",
    "                pcmra_loss = criterions[1](pcmra_out, pcmra_array)                  \n",
    "                pcmra_losses.append(pcmra_loss.item())\n",
    "            \n",
    "            else: \n",
    "                pcmra_losses.append(0)\n",
    "                \n",
    "\n",
    "            i += ARGS.batch_size\n",
    "            if i > n_eval:\n",
    "                break    \n",
    "\n",
    "        m_loss_mean, m_loss_std = round(np.mean(mask_losses), 6), round(np.std(mask_losses), 6)\n",
    "        p_loss_mean, p_loss_std = round(np.mean(pcmra_losses), 6), round(np.std(pcmra_losses), 6)\n",
    "        d_loss_mean, d_loss_std = round(np.mean(d_losses), 6), round(np.std(d_losses), 6)\n",
    "    \n",
    "    return m_loss_mean, m_loss_std, p_loss_mean, p_loss_std, d_loss_mean, d_loss_std\n",
    "\n",
    "\n",
    "def get_complete_image(models, pcmra, coords, ARGS, val_n=10000, output=\"mask\"): \n",
    "    for model in models.values(): \n",
    "        model.eval() #evaluation mode    \n",
    "        \n",
    "    latent_rep = models[\"cnn\"](pcmra)\n",
    "                \n",
    "    n_slices = math.ceil(coords.shape[1] / val_n) # number of batches\n",
    "    for i in range(n_slices):\n",
    "        coords_in = coords[:, (i*val_n) : ((i+1)*val_n), :]\n",
    "        \n",
    "        if output == \"mask\":\n",
    "            gamma, beta = models[\"mapping\"](latent_rep)\n",
    "            siren_out = models[\"siren\"](coords_in, gamma, beta)\n",
    "        \n",
    "        elif output == \"pcmra\": \n",
    "            if ARGS.share_mapping: \n",
    "                gamma, beta = models[\"mapping\"](latent_rep)\n",
    "            if not ARGS.share_mapping:\n",
    "                gamma, beta = models[\"pcmra_mapping\"](latent_rep)\n",
    "                \n",
    "            siren_out = models[\"pcmra_siren\"](coords_in, gamma, beta)\n",
    "            \n",
    "        if i == 0: \n",
    "            image = siren_out.detach()\n",
    "        else:\n",
    "            image = torch.cat((image, siren_out.detach()), 1)\n",
    "    \n",
    "    for model in models.values(): \n",
    "        model.train() #train mode\n",
    "    \n",
    "    return image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(folder, best, models, optims): \n",
    "    path = f\"saved_runs/{folder}/\"\n",
    "\n",
    "    for key in models.keys(): \n",
    "        models[key].load_state_dict(torch.load(f\"{path}/{key}_{best}.pt\"))\n",
    "        optims[key].load_state_dict(torch.load(f\"{path}/{key}_optim_{best}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CNN and Mapping setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cnn(ARGS): \n",
    "    \n",
    "    if ARGS.cnn_setup == 1: \n",
    "        cnn = CNN1()\n",
    "    elif ARGS.cnn_setup == 2: \n",
    "        cnn = CNN2()\n",
    "    else: \n",
    "        raise(Exception(\"Choose existing CNN setup\"))\n",
    "        \n",
    "    return cnn\n",
    "\n",
    "def load_mapping(ARGS): \n",
    "    \n",
    "    if ARGS.mapping_setup == 1: \n",
    "        mapping = Mapping1()\n",
    "    elif ARGS.mapping_setup == 2: \n",
    "        mapping = Mapping2()\n",
    "    elif ARGS.mapping_setup == 3: \n",
    "        mapping = Mapping3()\n",
    "    elif ARGS.mapping_setup == 4: \n",
    "        mapping = Mapping4()\n",
    "    else: \n",
    "        raise(Exception(\"Choose existing mapping setup\"))\n",
    "        \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to scroll through output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Show_images(object):\n",
    "    \"\"\"\n",
    "    Scroll through slices. Takes an unspecified number of subfigures per figure.\n",
    "    suptitles: either a str or a list. Represents the \n",
    "    main title of a figure. \n",
    "    images_titles: a list with tuples, each tuple an np.array and a \n",
    "    title for the array subfigure. \n",
    "    \"\"\"\n",
    "    def __init__(self, suptitles, *images_titles):\n",
    "        # if string if given, make list with that title for \n",
    "        # each slice.\n",
    "        if type(suptitles) == str: \n",
    "            self.suptitles = []\n",
    "            for i in range(images_titles[0][0].shape[2]): \n",
    "                self.suptitles.append(suptitles)\n",
    "        else: \n",
    "            self.suptitles = suptitles\n",
    "                    \n",
    "        self.fig, self.ax = plt.subplots(1,len(images_titles))\n",
    "\n",
    "        # split tuples with (image, title) into lists\n",
    "        self.images = [x[0] for x in images_titles]\n",
    "        self.titles = [x[1] for x in images_titles]\n",
    "\n",
    "        # get the number of slices that are to be shown\n",
    "        rows, cols, self.slices = self.images[0].shape        \n",
    "        self.ind = 0\n",
    "\n",
    "        self.fig.suptitle(self.suptitles[self.ind]) # set title \n",
    "\n",
    "        self.plots = []\n",
    "        \n",
    "        # start at slice 10 if more than 20 slices, \n",
    "        # otherwise start at middle slice.\n",
    "        if self.images[0].shape[2] > 20: \n",
    "            self.ind = 10\n",
    "        else:\n",
    "            self.ind = self.images[0].shape[2] // 2\n",
    "        \n",
    "        # make sure ax is an np array\n",
    "        if type(self.ax) == np.ndarray:\n",
    "            pass\n",
    "        else: \n",
    "            self.ax = np.array([self.ax])\n",
    "        \n",
    "        # create title for each subfigure in slice\n",
    "        for (sub_ax, image, title) in zip(self.ax, self.images, self.titles): \n",
    "            sub_ax.set_title(title)\n",
    "            plot = sub_ax.imshow(image[:, :, self.ind], vmin=0, vmax=1)\n",
    "            self.plots.append(plot)\n",
    "\n",
    "            \n",
    "        # link figure to mouse scroll movement\n",
    "        self.plot_show = self.fig.canvas.mpl_connect('scroll_event', self.onscroll)\n",
    "        \n",
    "\n",
    "    def onscroll(self, event):\n",
    "        \"\"\"\n",
    "        Shows next or previous slice with mouse scroll.\n",
    "        \"\"\"\n",
    "        if event.button == 'up':\n",
    "            self.ind = (self.ind - 1) % self.slices\n",
    "        else:\n",
    "            self.ind = (self.ind + 1) % self.slices\n",
    "        \n",
    "        self.update()\n",
    "        \n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates the figure.\n",
    "        \"\"\"\n",
    "        self.fig.suptitle(self.suptitles[self.ind])\n",
    "        \n",
    "        for plot, image in zip(self.plots, self.images):\n",
    "            plot.set_data(image[:, :, self.ind])\n",
    "        \n",
    "        self.ax[0].set_ylabel('Slice Number: %s' % self.ind)\n",
    "        self.plots[0].axes.figure.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all helper functions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded all helper functions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
