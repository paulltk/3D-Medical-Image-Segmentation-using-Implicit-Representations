{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported classes.\n",
      "Imported CNN model.\n",
      "Imported PI-Gan model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptenkaate/.local/lib/python3.6/site-packages/matplotlib/backends/qt_editor/figureoptions.py:11: MatplotlibDeprecationWarning: \n",
      "The support for Qt4  was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "  from matplotlib.backends.qt_compat import QtGui\n"
     ]
    }
   ],
   "source": [
    "%run \"custom_datasets.ipynb\"\n",
    "%run \"Model Classes/cnn_model.ipynb\"\n",
    "%run \"Model Classes/pigan_model.ipynb\"\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Using device for training: cuda\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "def set_device():\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    return DEVICE \n",
    "\n",
    "DEVICE = set_device()\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Using device for training:', DEVICE)\n",
    "print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "('RESV_016.npy',)\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "image_size = \"small\"\n",
    "\n",
    "data = PrepareData3D([\"Aorta Volunteers\", \"Aorta BaV\", \"Aorta Resvcue\", \"Aorta CoA\"], \n",
    "                     image_size=image_size, norm_min_max=[0,1])\n",
    "\n",
    "train_ds = SirenDataset(data.train, DEVICE) \n",
    "train_dataloader = DataLoader(train_ds, batch_size=1, num_workers=0, shuffle=True)\n",
    "print(train_ds.__len__())\n",
    "print(next(iter(train_dataloader))[1])\n",
    "\n",
    "val_ds = SirenDataset(data.val, DEVICE) \n",
    "val_dataloader = DataLoader(val_ds, batch_size=1, num_workers=0, shuffle=True)\n",
    "\n",
    "print(val_ds.__len__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_dim = 128\n",
    "\n",
    "flattened_size = [16384 if image_size==\"full\" else 4096][0]\n",
    "\n",
    "cnn = CNN((1, 16), \n",
    "          (16, 32), \n",
    "          (32, 64), \n",
    "          (64, 128), \n",
    "          (flattened_size, z_dim)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"Model Classes/cnn_model.ipynb\"\n",
    "\n",
    "\n",
    "# pcmra = next(iter(train_dataloader))[3]\n",
    "# print(\"pcmra:\", pcmra.shape)\n",
    "\n",
    "# out = cnn(pcmra)\n",
    "# print(\"out:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "siren = SirenGenerator(dim=z_dim, dim_hidden=256).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wd = 0\n",
    "\n",
    "siren_optim = torch.optim.Adam(params=siren.parameters(), weight_decay=wd)\n",
    "cnn_optim = torch.optim.Adam(params=cnn.parameters(), weight_decay=wd)\n",
    "\n",
    "# def l2_loss(out, ground_truth): \n",
    "#     return ((out - ground_truth)**2).mean()\n",
    "\n",
    "# criterion = l2_loss\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_optim.param_groups[0]['lr'] = 5e-5\n",
    "siren_optim.param_groups[0]['lr'] = 5e-5\n",
    "print(siren_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Random coords subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_coords(coords, pcmra_array, mask_array, n=1000): \n",
    "    mx = coords.shape[1]\n",
    "    rand_idx = random.sample(range(mx), n)\n",
    "\n",
    "    coords = coords[:, rand_idx, :]\n",
    "    pcmra_array = pcmra_array[:, rand_idx, :]\n",
    "    mask_array = mask_array[:, rand_idx, :]\n",
    "\n",
    "    return coords, pcmra_array, mask_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image generation and model saving functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_image(pcmra, coords, val_n = 10000): \n",
    "    \n",
    "    cnn.eval()\n",
    "    siren.eval()\n",
    "    \n",
    "    image = torch.Tensor([]).cuda()\n",
    "    \n",
    "    cnn_out = cnn(pcmra)\n",
    "    \n",
    "    n_slices = math.ceil(coords.shape[1] / val_n)    \n",
    "    for i in range(n_slices):\n",
    "        s_e = (i * val_n, (i+1) * val_n)\n",
    "        coords_in = coords[:, s_e[0] : s_e[1], :]\n",
    "\n",
    "        siren_out = siren(cnn_out, coords_in)\n",
    "        image = torch.cat((image, siren_out.detach()), 1)\n",
    "    \n",
    "    cnn.train()\n",
    "    cnn.train()\n",
    "    \n",
    "    return image \n",
    "\n",
    "\n",
    "def save_model(best_loss, losses, dataset=\"train\"):\n",
    "    mean, std = round(np.mean(losses), 6), round(np.std(losses), 6)\n",
    "\n",
    "    print(f\"{dataset} \\t mean loss: {mean} \\t std: {std}\")\n",
    "\n",
    "    if mean < best_loss: \n",
    "        best_loss = mean\n",
    "        print(f\"New best {dataset} loss, saving model.\")\n",
    "\n",
    "        torch.save(cnn.state_dict(), f\"Models/{folder}/cnn_{dataset}.pt\")\n",
    "        torch.save(cnn_optim.state_dict(), f\"Models/{folder}/cnn_optim_{dataset}.pt\")\n",
    "        \n",
    "        torch.save(siren.state_dict(), f\"Models/{folder}/siren_{dataset}.pt\")\n",
    "        torch.save(siren_optim.state_dict(), f\"Models/{folder}/siren_optim_{dataset}.pt\")\n",
    "\n",
    "    return best_loss     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = \"Models/PI-Gan 02-04-2021 16:20:46 mask_complete dataset_n 30000/\"\n",
    "\n",
    "# best_loss = \"train\"\n",
    "\n",
    "# cnn.load_state_dict(torch.load(f\"{folder}/cnn_{best_loss}.pt\"))\n",
    "# cnn_optim.load_state_dict(torch.load(f\"{folder}/cnn_optim_{best_loss}.pt\"))\n",
    "\n",
    "# siren.load_state_dict(torch.load(f\"{folder}/siren_{best_loss}.pt\"))\n",
    "# siren_optim.load_state_dict(torch.load(f\"{folder}/siren_optim_{best_loss}.pt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Train model\n",
    "for pcmra array with linear output, 0.000500 is good.\n",
    "\n",
    "\n",
    "for mask with sigmoid output and BCE, 0.02 is good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating path \\Models\\PI-Gan 02-04-2021 17:56:41 mask_complete dataset_n 30000\n",
      "Epoch 0 took 7 seconds.\n",
      "train \t mean loss: 0.587906 \t std: 0.099548\n",
      "New best train loss, saving model.\n",
      "val \t mean loss: 0.573797 \t std: 0.018322\n",
      "New best val loss, saving model.\n",
      "\n",
      "Epoch 5 took 5 seconds.\n",
      "train \t mean loss: 0.135945 \t std: 0.023211\n",
      "New best train loss, saving model.\n",
      "val \t mean loss: 0.155971 \t std: 0.086799\n",
      "New best val loss, saving model.\n",
      "\n",
      "Epoch 10 took 5 seconds.\n",
      "train \t mean loss: 0.126712 \t std: 0.029006\n",
      "New best train loss, saving model.\n",
      "val \t mean loss: 0.144014 \t std: 0.080867\n",
      "New best val loss, saving model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "print_every = 5\n",
    "\n",
    "aggregate_gradient = 10\n",
    "batches = 0\n",
    "\n",
    "# n = 393216\n",
    "n = 30000\n",
    "\n",
    "output_type = \"mask\"\n",
    "dataset = \"complete\"\n",
    "\n",
    "now = datetime.now()\n",
    "dt = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "\n",
    "folder = f\"PI-Gan {dt} {output_type}_{dataset} dataset_n {n}\"\n",
    "\n",
    "Path(f\"Models/{folder}\").mkdir(parents=True, exist_ok=True)   \n",
    "print(f\"Creating path \\\\Models\\\\{folder}\")\n",
    "    \n",
    "\n",
    "best_train_loss, best_val_loss = 100000, 100000\n",
    "\n",
    "for ep in range(epochs):\n",
    "    \n",
    "    t = time.time() \n",
    "    \n",
    "    cnn.train()\n",
    "    siren.train()\n",
    "\n",
    "    losses = []\n",
    "        \n",
    "    for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in train_dataloader:\n",
    "        siren_in, _, siren_labels = choose_random_coords(coords, pcmra_array, mask_array, n=n)\n",
    "\n",
    "        cnn_out = cnn(pcmra)\n",
    "        siren_out = siren(cnn_out, siren_in)\n",
    "        \n",
    "        loss = criterion(siren_out, siren_labels) \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss = loss / train_ds.__len__()\n",
    "        loss.backward()\n",
    "        \n",
    "        batches += 1\n",
    "\n",
    "        if batches % aggregate_gradient == 0: \n",
    "            siren_optim.step()\n",
    "            cnn_optim.step()   \n",
    "            \n",
    "            siren_optim.zero_grad()\n",
    "            cnn_optim.zero_grad()\n",
    "    \n",
    "\n",
    "    if ep % print_every == 0: \n",
    "        \n",
    "        print(f\"Epoch {ep} took {round(time.time() - t)} seconds.\")\n",
    "        \n",
    "        best_train_loss = save_model(best_train_loss, losses, dataset=\"train\")\n",
    "        \n",
    "        val_losses = []\n",
    "        \n",
    "        for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in val_dataloader:    \n",
    "            siren_out = get_complete_image(pcmra, coords)\n",
    "            loss = criterion(siren_out, mask_array)            \n",
    "        \n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "        best_val_loss = save_model(best_val_loss, val_losses, dataset=\"val\")\n",
    "                \n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx, subj, proj, pcmra, coords, pcmra_array, mask_array = next(iter(val_dataloader))\n",
    "# # pcmra, coords = pcmra.unsqueeze(0), coords.unsqueeze(0)\n",
    "# # pcmra_array, mask_array =  pcmra_array.unsqueeze(0), mask_array.unsqueeze(0)\n",
    "\n",
    "# siren_out = get_complete_image(pcmra, coords)\n",
    "# loss = criterion(siren_out, mask_array)            \n",
    "\n",
    "# print(f\"{subj}, loss: {loss}\")\n",
    "\n",
    "# def arrays_to_numpy(*arrays): \n",
    "#     print(arrays)\n",
    "    \n",
    "    \n",
    "# slic = 8\n",
    "\n",
    "# # shape = (128, 128, 24)\n",
    "# shape = (64, 64, 24)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(12,12))\n",
    "# axes[0].imshow(pcmra_array.cpu().view(shape).detach().numpy()[:, :, slic])\n",
    "# axes[1].imshow(mask_array.cpu().view(shape).detach().numpy()[:, :, slic])\n",
    "# # axes[2].imshow(siren_out.cpu().view(shape).detach().numpy()[:, :, slic])\n",
    "# axes[2].imshow(siren_out.cpu().view(shape).detach().numpy().round()[:, :, slic])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in val_dataloader: \n",
    "    \n",
    "    \n",
    "#     siren_out = get_complete_image(pcmra, coords)\n",
    "#     loss = criterion(siren_out, mask_array)            \n",
    "\n",
    "#     print(subj, loss.item()) \n",
    "\n",
    "#     slic = 12\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(12,12))\n",
    "#     axes[0].imshow(pcmra_array.cpu().view(128, 128, 24).detach().numpy()[:, :, slic])\n",
    "#     axes[1].imshow(mask_array.cpu().view(128, 128, 24).detach().numpy()[:, :, slic])\n",
    "#     axes[2].imshow(siren_out.cpu().view(128, 128, 24).detach().numpy().round()[:, :, slic])\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_through_output(shape=(64, 64, 24)):\n",
    "    pcmras = masks = outs = torch.Tensor([])\n",
    "    titles = []\n",
    "\n",
    "    shape = (64, 64, 24)\n",
    "    for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in val_dataloader: \n",
    "\n",
    "        siren_out = get_complete_image(pcmra, coords)\n",
    "        loss = criterion(siren_out, mask_array) \n",
    "\n",
    "        pcmras = torch.cat((pcmras, pcmra_array.cpu().view(shape).detach()), 2)\n",
    "        masks = torch.cat((masks, mask_array.cpu().view(shape).detach()), 2)\n",
    "        outs = torch.cat((outs, siren_out.cpu().view(shape).detach()), 2)\n",
    "\n",
    "        titles += [subj[0] + \" \" + proj[0] for i in range(shape[2])]\n",
    "\n",
    "    return Show_images(titles, (pcmras.numpy(), \"pcmras\"), (masks.numpy(), \"masks\"), (outs.numpy(), \"outs\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = scroll_through_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
