{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run convert_ipynb_to_py_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Project and Show_images classes.\n",
      "Imported CNN model.\n",
      "Imported PI-Gan model.\n",
      "----------------------------------\n",
      "Using device for training: cuda\n",
      "----------------------------------\n",
      "Loaded all helper functions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptenkaate/.local/lib/python3.6/site-packages/matplotlib/backends/qt_editor/figureoptions.py:11: MatplotlibDeprecationWarning: \n",
      "The support for Qt4  was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "  from matplotlib.backends.qt_compat import QtGui\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import math \n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# from data_classes.py_files.custom_datasets import *\n",
    "from data_classes.py_files.data_classes import *\n",
    "from data_classes.py_files.new_dataset import *\n",
    "# \n",
    "from model_classes.py_files.cnn_model import *\n",
    "from model_classes.py_files.pigan_model import *\n",
    "\n",
    "from functions import *\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Using device for training: cuda\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "DEVICE = set_device()\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Using device for training:', DEVICE)\n",
    "print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the run you want to evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: ARGS class initialized.\n",
      "Changed param \tepochs: 100.\n",
      "Changed param \tacc_steps: 64.\n",
      "Changed param \teval_every: 5.\n",
      "Changed param \tcnn_setup: 17.\n",
      "pi-gan 23-04-2021 08:16:09 \n",
      "{'name': '', 'pretrained': None, 'pretrained_best': 'train', 'dataset': 'small', 'norm_min_max': [0, 1], 'seed': 34, 'epochs': 100, 'acc_steps': 64, 'eval_every': 5, 'shuffle': True, 'n_coords_sample': 5000, 'cnn_setup': 17, 'dim_hidden': 256, 'siren_hidden_layers': 3, 'first_omega_0': 30.0, 'hidden_omega_0': 30.0, 'cnn_lr': 0.0001, 'siren_lr': 0.0001, 'mapping_lr': 0.0001, 'cnn_wd': 0, 'siren_wd': 0, 'mapping_wd': 0}\n"
     ]
    }
   ],
   "source": [
    "run = sorted(os.listdir(path='saved_runs'))[-1]\n",
    "# run = \"pi-gan 21-04-2021 06:39:36 \"\n",
    "\n",
    "ARGS = load_args(run)\n",
    "# ARGS.dataset = \"full\"\n",
    "# ARGS.shuffle = False\n",
    "\n",
    "print(run)\n",
    "print(vars(ARGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subjects: 1026\n",
      "Val subjects: 18\n",
      "Test subjects: 18\n"
     ]
    }
   ],
   "source": [
    "##### data preparation #####\n",
    "train_dl, val_dl, test_dl = initialize_dataloaders(ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (model): Sequential(\n",
      "    (0): Conv3d(1, 16, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): LayerNorm((24, 64, 64), eps=1e-05, elementwise_affine=True)\n",
      "    (3): Conv3d(16, 16, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): LayerNorm((12, 32, 32), eps=1e-05, elementwise_affine=True)\n",
      "    (6): Conv3d(16, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "    (7): ReLU()\n",
      "    (8): LayerNorm((12, 32, 32), eps=1e-05, elementwise_affine=True)\n",
      "    (9): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (10): ReLU()\n",
      "    (11): LayerNorm((6, 16, 16), eps=1e-05, elementwise_affine=True)\n",
      "    (12): Conv3d(32, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "    (13): ReLU()\n",
      "    (14): LayerNorm((6, 16, 16), eps=1e-05, elementwise_affine=True)\n",
      "    (15): Conv3d(64, 64, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (16): ReLU()\n",
      "    (17): LayerNorm((3, 8, 8), eps=1e-05, elementwise_affine=True)\n",
      "    (18): Conv3d(64, 128, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "    (19): ReLU()\n",
      "    (20): LayerNorm((3, 8, 8), eps=1e-05, elementwise_affine=True)\n",
      "    (21): Conv3d(128, 128, kernel_size=(5, 5, 5), stride=(2, 2, 2), padding=(2, 2, 2))\n",
      "    (22): ReLU()\n",
      "    (23): LayerNorm((2, 4, 4), eps=1e-05, elementwise_affine=True)\n",
      "    (24): Flatten()\n",
      "    (25): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (26): LeakyReLU(negative_slope=0.2)\n",
      "    (27): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (28): LeakyReLU(negative_slope=0.2)\n",
      "    (29): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      ")\n",
      "Siren(\n",
      "  (net): ModuleList(\n",
      "    (0): SineLayer(\n",
      "      (linear): Linear(in_features=3, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): SineLayer(\n",
      "      (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (2): SineLayer(\n",
      "      (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (3): SineLayer(\n",
      "      (linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models, optims = load_models_and_optims(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = \"val\"\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].load_state_dict(torch.load(f\"saved_runs/{run}/{model}_{best_loss}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### loss function #####\n",
    "criterion = nn.BCELoss()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_through_output(dataloader, shape=(64, 64, 24), first=100):\n",
    "    pcmras = masks = outs = torch.Tensor([])\n",
    "    titles = []\n",
    "\n",
    "    for idx, subj, proj, pcmra, coords, pcmra_array, mask_array in dataloader: \n",
    "#         print(pcmra.shape)\n",
    "\n",
    "        siren_out = get_complete_image(models, pcmra, coords)\n",
    "        loss = criterion(siren_out, mask_array) \n",
    "\n",
    "        pcmras = torch.cat((pcmras, pcmra_array.cpu().view(shape).detach()), 2)\n",
    "        masks = torch.cat((masks, mask_array.cpu().view(shape).detach()), 2)\n",
    "        outs = torch.cat((outs, siren_out.cpu().view(shape).detach()), 2)\n",
    "\n",
    "        titles += [f\"{idx.item()} {subj[0]} {proj[0]}, loss:, {round(loss.item(), 4)}\" for i in range(shape[2])]\n",
    "        \n",
    "        if idx >= first: \n",
    "            break\n",
    "\n",
    "    return Show_images(titles, (pcmras.numpy(), \"pcmras\"), (masks.numpy(), \"masks\"), (outs.numpy(), \"outs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = scroll_through_output(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
