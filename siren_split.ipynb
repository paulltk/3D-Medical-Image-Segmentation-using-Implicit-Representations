{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported classes.\n"
     ]
    }
   ],
   "source": [
    "%run custom_datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30, add_dropout=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        self.in_features = in_features\n",
    "        self.add_dropout = add_dropout\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.dropout = nn.Dropout(.2)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = torch.sin(self.omega_0 * self.linear(input))\n",
    "        if self.add_dropout and not self.is_first: \n",
    "            out = self.dropout(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, \n",
    "                 first_different_init=True, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        \n",
    "        \n",
    "        # first layer \n",
    "        if first_different_init:\n",
    "            self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "        else: \n",
    "            self.net.append(SineLayer(in_features, hidden_features, omega_0=hidden_omega_0))\n",
    "\n",
    "            \n",
    "        # hidden layers\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, omega_0=hidden_omega_0))\n",
    "\n",
    "            \n",
    "        # last layer\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)    \n",
    "            \n",
    "            self.net.append(final_linear)\n",
    "        \n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, omega_0=hidden_omega_0))\n",
    "        \n",
    "        \n",
    "        # add all to network\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        output = self.net(coords)\n",
    "        return output\n",
    "\n",
    "\n",
    "def set_device():\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('----------------------------------')\n",
    "    print('Using device for training:', DEVICE)\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    return DEVICE \n",
    "\n",
    "def mem(step):\n",
    "    div = 1024*1024*1024\n",
    "    \n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    c = torch.cuda.memory_cached(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "\n",
    "    print(step)\n",
    "    print(\"Memory cached:\", round(c/div, 3))\n",
    "    print(\"Memory allocated:\", round(c/div, 3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Using device for training: cuda\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "DEVICE = set_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PrepareData3D([\"Aorta Volunteers\", \"Aorta BaV\", \"Aorta Resvcue\", \"Aorta CoA\"])\n",
    "\n",
    "train_ds = SirenDataset(data.train, DEVICE) \n",
    "train_dataloader = DataLoader(train_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = SirenDataset(data.val, DEVICE) \n",
    "val_dataloader = DataLoader(val_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'RESV_109.npy',\n",
       " 'Aorta Resvcue',\n",
       " tensor([[-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -0.9130],\n",
       "         [-1.0000, -1.0000, -0.8261],\n",
       "         ...,\n",
       "         [ 1.0000,  1.0000,  0.8261],\n",
       "         [ 1.0000,  1.0000,  0.9130],\n",
       "         [ 1.0000,  1.0000,  1.0000]], device='cuda:0'),\n",
       " tensor([[-1.],\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         ...,\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         [-1.]], device='cuda:0'),\n",
       " tensor([[-1.],\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         ...,\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         [-1.]], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "\n",
    "def create_model_per_image(dataset): \n",
    "    models = {}\n",
    "    \n",
    "    for i in range(dataset.__len__()):\n",
    "        subj = dataset[i][1].item()\n",
    "        \n",
    "        models[subj] = []\n",
    "\n",
    "        model = Siren(in_features=3, out_features=size, hidden_features=size, \n",
    "                      hidden_layers=1, first_different_init=True, outermost_linear=False).cuda()\n",
    "\n",
    "        models[subj].append(model)\n",
    "        models[subj].append(torch.optim.Adam(lr=1e-4, params=model.parameters()))\n",
    "    \n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Siren(\n",
       "   (net): Sequential(\n",
       "     (0): SineLayer(\n",
       "       (linear): Linear(in_features=3, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.2, inplace=False)\n",
       "     )\n",
       "     (1): SineLayer(\n",
       "       (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.2, inplace=False)\n",
       "     )\n",
       "     (2): SineLayer(\n",
       "       (linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.2, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     eps: 1e-08\n",
       "     lr: 0.0001\n",
       "     weight_decay: 0\n",
       " )]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcmra_siren = Siren(in_features=size, out_features=1, hidden_features=size, \n",
    "                  hidden_layers=1, first_different_init=False, outermost_linear=True).cuda()\n",
    "pcmra_optim = torch.optim.Adam(lr=1e-4, params=pcmra_siren.parameters())\n",
    "\n",
    "mask_siren = Siren(in_features=size, out_features=1, hidden_features=size, \n",
    "                  hidden_layers=1, first_different_init=False, outermost_linear=True).cuda()\n",
    "mask_optim = torch.optim.Adam(lr=1e-4, params=mask_siren.parameters())\n",
    "\n",
    "train_models = create_model_per_image(train_ds)\n",
    "\n",
    "val_models = create_model_per_image(val_ds)\n",
    "\n",
    "train_models[\"RESV_109.npy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(out, ground_truth): \n",
    "    return ((out - ground_truth)**2).mean()\n",
    "\n",
    "def train_model(coords, ground_truth, h_model, h_optim, \n",
    "                t_model, t_optim, criterion, train_head=True, train_tail=True): \n",
    "\n",
    "    out = h_model(coords)\n",
    "    out = t_model(out)\n",
    "\n",
    "    loss = criterion(out, ground_truth)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    if train_head: \n",
    "        h_optim.step()\n",
    "    \n",
    "    if train_tail: \n",
    "        t_optim.step()\n",
    "    \n",
    "    h_optim.zero_grad()\n",
    "    t_optim.zero_grad()\n",
    "    \n",
    "    return out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models/train_models_05_03_2021_20_15_03..pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-be8c7e4d5711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models/train_models_05_03_2021_20_15_03..pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpcmra_siren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models/pcmra_siren_05_03_2021_20_15_03..pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmask_siren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models/mask_siren_05_03_2021_20_15_03..pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Models/train_models_05_03_2021_20_15_03..pkl'"
     ]
    }
   ],
   "source": [
    "train_models = pickle.load(open(\"Models/train_models_05_03_2021_20_15_03..pkl\", \"rb\"))\n",
    "pcmra_siren = pickle.load(open(\"Models/pcmra_siren_05_03_2021_20_15_03..pkl\", \"rb\"))\n",
    "mask_siren = pickle.load(open(\"Models/mask_siren_05_03_2021_20_15_03..pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = 1000\n",
    "steps_til_summary = 10\n",
    "\n",
    "now = datetime.now()\n",
    "dt = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "print(dt)\n",
    "\n",
    "lowest_losses = 1000\n",
    "for batch in range(batches):\n",
    "    \n",
    "    pcmra_losses = []\n",
    "    mask_losses = []\n",
    "        \n",
    "    for idx, subj, proj, coords, pcmra, mask in train_dataloader:\n",
    "        subj = subj[0].item()\n",
    "        img_siren, img_optim = train_models[subj]\n",
    "        \n",
    "        pcmra_out, pcmra_loss = train_model(coords, pcmra, img_siren, img_optim, \n",
    "                                 pcmra_siren, pcmra_optim, l2_loss)\n",
    "        \n",
    "        mask_out, mask_loss = train_model(coords, mask, img_siren, img_optim,\n",
    "                                mask_siren, mask_optim, l2_loss)\n",
    "        \n",
    "        \n",
    "        pcmra_losses.append(pcmra_loss.item())\n",
    "        mask_losses.append(mask_loss.item())\n",
    "    \n",
    "    if not batch % steps_til_summary:\n",
    "        p_mean, p_std = round(np.mean(pcmra_losses), 6), round(np.std(pcmra_losses), 6)\n",
    "        m_mean, m_std = round(np.mean(mask_losses), 6), round(np.std(mask_losses), 6)\n",
    "        \n",
    "        print(f\"Batch {batch} \\n Pcmra loss: \\t mean {p_mean} \\t std {p_std} \\n Mask loss: \\t mean {m_mean} \\t std {m_std}\")\n",
    "        \n",
    "        if (p_mean + m_mean) < lowest_losses: \n",
    "            print(\"Saving models...\")\n",
    "            lowest_losses = (p_mean + m_mean)\n",
    "            pickle.dump(train_models, open(f\"train_models_{dt}.pkl\", \"wb\"))\n",
    "            pickle.dump(pcmra_siren, open(f\"pcmra_siren_{dt}.pkl\", \"wb\"))\n",
    "            pickle.dump(mask_siren, open(f\"mask_siren_{dt}.pkl\", \"wb\"))\n",
    "#             print(\"Models saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single Image Siren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "batches = 500\n",
    "steps_til_summary = 10\n",
    "\n",
    "lowest_losses = 1000\n",
    "\n",
    "for batch in range(batches):\n",
    "    \n",
    "#     idx, subj, proj, coords, pcmra, mask = train_ds[3]\n",
    "    idx, subj, proj, coords, pcmra, mask = val_ds[1]\n",
    "    subj = subj.item()\n",
    "    \n",
    "#     img_siren, img_optim = train_models[subj]\n",
    "    img_siren, img_optim = val_models[subj]\n",
    "    \n",
    "    pcmra_out, pcmra_loss = train_model(coords, pcmra, img_siren, img_optim, \n",
    "                                        pcmra_siren, pcmra_optim, l2_loss, \n",
    "                                        train_tail=False)\n",
    "\n",
    "    mask_out, mask_loss = train_model(coords, mask, img_siren, img_optim,\n",
    "                                    mask_siren, mask_optim, l2_loss, \n",
    "                                    train_head=True, train_tail=False)\n",
    "    \n",
    "    if not batch % steps_til_summary:\n",
    "        print(f\"Batch {batch} \\t pcmra loss: {round(pcmra_loss.item(), 6)} \\t mask loss: {round(mask_loss.item(), 6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slic = 10\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,12))\n",
    "axes[0, 0].imshow(pcmra_out.cpu().view(128, 128, 24).detach().numpy()[:, :, slic])\n",
    "axes[0, 1].imshow(pcmra.cpu().view(128, 128, 24).detach().numpy()[:, :, slic])\n",
    "axes[1, 0].imshow(mask_out.cpu().view(128, 128, 24).detach().numpy().round()[:, :, slic])\n",
    "axes[1, 1].imshow(mask.cpu().view(128, 128, 24).detach().numpy()[:, :, slic])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_siren = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints currently alive Tensors and Variables\n",
    "import torch\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models = 0\n",
    "val_models=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
