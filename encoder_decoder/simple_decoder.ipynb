{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/ptenkaate/scratch/Master-Thesis/convert_ipynb_to_py_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import math \n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from py_files.new_dataset import *\n",
    "\n",
    "from py_files.cnn_model import *\n",
    "from py_files.pigan_model import *\n",
    "\n",
    "from py_files.seq_pi_gan_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (32, 1, 24, 64, 64)\n",
    "encoder = Encoder()\n",
    "summary(encoder, input_size=input_size, depth=2)\n",
    "\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "#             nn.ConvTranspose3d(512, 128, (3, 4, 4), stride=2, padding=0, output_padding=0),            \n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose3d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose3d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose3d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose3d(16, 1, 3, stride=(1, 2, 2), padding=1, output_padding=(0, 1, 1)),\n",
    "            \n",
    "            \n",
    "            nn.ConvTranspose3d(512, 128, (3, 4, 4), stride=2, padding=0, output_padding=0),            \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='trilinear'),\n",
    "            nn.Conv3d(32, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(16, 1, 3, stride=(1, 2, 2), padding=1, output_padding=(0, 1, 1)),\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "output_size = encoder(torch.randn(input_size).cuda()).shape\n",
    "print(tuple(output_size))\n",
    "decoder = Decoder()\n",
    "summary(decoder, input_size=output_size, depth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder_1().cuda()\n",
    "decoder = Decoder().cuda()\n",
    "\n",
    "e_optim = torch.optim.Adam(lr=1e-4, params=encoder.parameters())\n",
    "d_optim = torch.optim.Adam(lr=1e-4, params=decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_run  = \"pi-gan 18-05-2021 20:47:06 trained quite well\"\n",
    "\n",
    "encoder.load_state_dict(torch.load(f\"saved_runs/{saved_run}/encoder_train.pt\"))\n",
    "decoder.load_state_dict(torch.load(f\"saved_runs/{saved_run}/decoder_train.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for g in e_optim.param_groups:\n",
    "#     g['lr'] = 1e-5\n",
    "\n",
    "# for g in d_optim.param_groups:\n",
    "#     g['lr'] = 1e-5\n",
    "\n",
    "ARGS = init_ARGS()\n",
    "print(vars(ARGS))\n",
    "\n",
    "##### path to wich the model should be saved #####\n",
    "path = get_folder(ARGS)\n",
    "\n",
    "##### save ARGS #####\n",
    "with open(f\"{path}/ARGS.txt\", \"w\") as f:\n",
    "    print(vars(ARGS), file=f)\n",
    "\n",
    "##### data preparation #####\n",
    "train_dl, val_dl, test_dl = initialize_dataloaders(ARGS)\n",
    "print(next(iter(test_dl))[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ARGS.epochs = 10000\n",
    "\n",
    "##### loss function #####\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "losses = np.empty((0, 5))\n",
    "\n",
    "for ep in range(ARGS.epochs):\n",
    "#     print(\"Epoch\", ep)\n",
    "\n",
    "    ep_loss = []\n",
    "\n",
    "    t = time.time() \n",
    "    \n",
    "    for batch in train_dl:\n",
    "                    \n",
    "        batch = transform_batch(batch, ARGS)            \n",
    "        _, _, _, pcmra, coords, pcmra_array, mask_array = get_siren_batch(batch)\n",
    "        \n",
    "        \n",
    "        out = decoder(encoder(pcmra))\n",
    "#         out = decoder(encoder(pcmra).detach())\n",
    "\n",
    "        loss = criterion(out, pcmra)\n",
    "        loss.backward()\n",
    "\n",
    "        ep_loss.append(loss.item())\n",
    "\n",
    "        e_optim.step()\n",
    "        d_optim.step()  \n",
    "\n",
    "        e_optim.zero_grad(); \n",
    "        d_optim.zero_grad()  \n",
    "        \n",
    "        \n",
    "    if (ep + 1) % 20 == 0: \n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder.eval()\n",
    "            decoder.eval()\n",
    "\n",
    "            print(f\"Epoch {ep} took {round(time.time() - t, 2)} seconds.\")\n",
    "\n",
    "            train_loss = []\n",
    "\n",
    "            b = 0\n",
    "            for batch in train_dl:\n",
    "\n",
    "                batch = transform_batch(batch, ARGS)\n",
    "\n",
    "                _, _, _, pcmra, coords, pcmra_array, mask_array = get_siren_batch(batch)\n",
    "\n",
    "                out = encoder(pcmra)\n",
    "                out = decoder(out)\n",
    "\n",
    "                loss = criterion(out, pcmra)\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                b += 1\n",
    "\n",
    "                if b == 10: \n",
    "                    break\n",
    "\n",
    "            print(\"train loss\", np.array(train_loss).mean())\n",
    "\n",
    "            val_loss = []\n",
    "\n",
    "            for batch in val_dl:\n",
    "\n",
    "                _, _, _, pcmra, coords, pcmra_array, mask_array = get_siren_batch(batch)\n",
    "\n",
    "                out = encoder(pcmra)\n",
    "                out = decoder(out)\n",
    "\n",
    "                loss = criterion(out, pcmra)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "            print(\"val loss\", np.array(val_loss).mean())\n",
    "\n",
    "            encoder.train()\n",
    "            decoder.train()\n",
    "            \n",
    "            losses = np.append(losses, [[ep, np.array(train_loss).mean(), np.array(train_loss).std(), \n",
    "                                         np.array(val_loss).mean(), np.array(val_loss).std()]], axis=0)\n",
    "            \n",
    "            \n",
    "            np.save(f\"{path}/losses.npy\", losses)\n",
    "            \n",
    "           \n",
    "        models = {\"encoder\": encoder, \"decoder\": decoder}    \n",
    "        optims = {\"encoder\": e_optim, \"decoder\": d_optim}    \n",
    "\n",
    "        save_loss(path, losses, models, optims, name=\"loss\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_through_output(dataloader, shape=(64, 64, 24), transform=True):\n",
    "    pcmras = outs = torch.Tensor([])\n",
    "    \n",
    "    titles = []\n",
    "\n",
    "    ep_loss = []\n",
    "\n",
    "    for batch in dataloader: \n",
    "\n",
    "        if transform:\n",
    "            batch = transform_batch(batch, ARGS)\n",
    "\n",
    "        _, _, _, pcmra, coords, pcmra_array, mask_array = get_siren_batch(batch)\n",
    "        \n",
    "        out = encoder(pcmra)\n",
    "        out = decoder(out)\n",
    "\n",
    "        loss = criterion(pcmra, out) \n",
    "        ep_loss.append(loss.item())\n",
    "\n",
    "\n",
    "        pcmras = torch.cat((pcmras, pcmra.contiguous().view(-1, 64, 64).cpu().detach().permute(1, 2, 0)), 2)\n",
    "        outs = torch.cat((outs, out.contiguous().view(-1, 64, 64).cpu().detach().permute(1, 2, 0)), 2)\n",
    "        \n",
    "    \n",
    "    print(np.array(ep_loss).mean())\n",
    "    window = Show_images(\"Comparison\", (pcmras.numpy(), \"pcmras\"), \n",
    "                                 (outs.numpy(), \"output\"))\n",
    "\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "\n",
    "scroll_through_output(test_dl, shape=(64, 64, 24), transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(encoder.state_dict(), f\"{path}/cnn_train.pt\")\n",
    "# torch.save(e_optim.state_dict(), f\"{path}/cnn_optim_train.pt\")\n",
    "\n",
    "# torch.save(decoder.state_dict(), f\"{path}/decoder_train.pt\")\n",
    "# torch.save(e_optim.state_dict(), f\"{path}/decoder_optim_train.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
