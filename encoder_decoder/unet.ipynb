{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run /home/ptenkaate/scratch/Master-Thesis/convert_ipynb_to_py_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import math \n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from py_files.new_dataset import *\n",
    "\n",
    "from py_files.cnn_model import *\n",
    "from py_files.pigan_model import *\n",
    "\n",
    "from py_files.seq_pi_gan_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv3d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(1, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(512, 256)\n",
    "        self.dconv_up2 = double_conv(256, 128)\n",
    "        self.dconv_up1 = double_conv(128, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv3d(64, 1, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGS = init_ARGS()\n",
    "\n",
    "# ARGS.rotate, ARGS.translate, ARGS.flip = False, True, True\n",
    "# ARGS.epochs = 50\n",
    "\n",
    "# ARGS.batch_size = 24\n",
    "\n",
    "\n",
    "# ##### path to wich the model should be saved #####\n",
    "# path = get_folder(ARGS)\n",
    "\n",
    "# ##### save ARGS #####\n",
    "# with open(f\"{path}/ARGS.txt\", \"w\") as f:\n",
    "#     print(vars(ARGS), file=f)\n",
    "\n",
    "# ##### data preparation #####\n",
    "# train_dl, val_dl, test_dl = initialize_dataloaders(ARGS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet().cuda()\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=unet.parameters())\n",
    "\n",
    "\n",
    "##### loss function #####\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "losses = np.empty((0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ep in range(ARGS.epochs):\n",
    "\n",
    "    t = time.time() \n",
    "\n",
    "    ep_loss = []\n",
    "\n",
    "    for _, _, _, pcmra, coords, pcmra_array, mask_array in train_dl:\n",
    "\n",
    "        out = unet(pcmra)\n",
    "\n",
    "        loss = criterion(out, pcmra)\n",
    "        loss.backward()\n",
    "\n",
    "        ep_loss.append(loss.item())\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "    print(np.array(ep_loss).mean())\n",
    "    \n",
    "    if ep % 5 == 0: \n",
    "        \n",
    "        print(f\"Epoch {ep} took {round(time.time() - t, 2)} seconds.\")\n",
    "\n",
    "        ep_loss = []\n",
    "        \n",
    "        for _, _, _, pcmra, coords, pcmra_array, mask_array in val_dl:\n",
    "\n",
    "            out = unet(pcmra)\n",
    "\n",
    "            loss = criterion(out, pcmra)\n",
    "\n",
    "            ep_loss.append(loss.item())\n",
    "\n",
    "        print(\"val loss\", np.array(ep_loss).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx, subj, proj, pcmra, coords, pcmra_array, mask_array = next(iter(val_dl))\n",
    "            \n",
    "out = encoder(pcmra)\n",
    "out = decoder(out)\n",
    "\n",
    "# print(subj)\n",
    "\n",
    "# print(out.shape)\n",
    "# print(out.shape)\n",
    "\n",
    "print(criterion(pcmra, out).item())\n",
    "\n",
    "i = 6\n",
    "slce = 8\n",
    "in_i = pcmra[i, 0, slce, :, :]\n",
    "out_i = out[i, 0, slce, :, :]\n",
    "\n",
    "plt.imshow(in_i.cpu())\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(out_i.cpu().detach())\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(unet, input_size=(32, 1, 24, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
