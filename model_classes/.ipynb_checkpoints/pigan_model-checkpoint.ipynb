{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import math\n",
    "from einops import repeat, rearrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Siren from Sitzmann paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input, gamma, beta):\n",
    "        out = self.linear(input)\n",
    "        \n",
    "        out = self.omega_0 * out        \n",
    "        \n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = gamma * out + beta\n",
    "        out = out.permute(1, 0, 2)\n",
    "        \n",
    "        return torch.sin(out)\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, ARGS, in_features=3, out_features=1, \n",
    "                 first_omega_0=30., hidden_omega_0=30., \n",
    "                 final_activation=\"sigmoid\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.ModuleList([])\n",
    "\n",
    "        self.net.append(SineLayer(in_features, ARGS.dim_hidden, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(ARGS.siren_hidden_layers):\n",
    "            self.net.append(SineLayer(ARGS.dim_hidden, ARGS.dim_hidden, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        self.final_linear = nn.Linear(ARGS.dim_hidden, out_features)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.final_linear.weight.uniform_(-np.sqrt(6 / ARGS.dim_hidden) / hidden_omega_0, \n",
    "                                          np.sqrt(6 / ARGS.dim_hidden) / hidden_omega_0)\n",
    "\n",
    "        if final_activation == \"sigmoid\":\n",
    "            self.final_activation = nn.Sigmoid()\n",
    "        elif final_activation == \"relu\":\n",
    "            self.final_activation = nn.ReLU()\n",
    "        elif final_activation == None:\n",
    "            self.final_activation = None\n",
    "        else: \n",
    "            raise(Exception(\"Choose correct final activation in Siren model.\"))\n",
    "\n",
    "            \n",
    "    def forward(self, x, gamma, beta):\n",
    "        for i, sine_layer in enumerate(self.net): \n",
    "            if gamma.shape[1:] == torch.Size([256]):\n",
    "                x = sine_layer(x, gamma, beta)\n",
    "            \n",
    "            elif gamma.shape[1:] == torch.Size([4, 256]):    \n",
    "                x = sine_layer(x, gamma[:, i, :], beta[:, i, :])\n",
    "            \n",
    "            else: \n",
    "                raise(Exception(\"Shape of Gamma and Beta not correct\")) \n",
    "        \n",
    "        x = self.final_linear(x)\n",
    "        \n",
    "        if self.final_activation: \n",
    "            x = self.final_activation(x)\n",
    "            \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported PI-Gan model.\n"
     ]
    }
   ],
   "source": [
    "print(\"Imported PI-Gan model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
