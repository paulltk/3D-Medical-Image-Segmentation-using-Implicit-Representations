{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq_pi_gan_functions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"code","metadata":{"id":"j-7r_aoSl0uk"},"source":["import torch\n","import torch.nn.functional as F\n","\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n","\n","import os\n","import time\n","import argparse\n","import math \n","import skimage\n","import pickle\n","import ast\n","import random\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.path as mplPath\n","import pylab as pl\n","\n","from datetime import datetime\n","from pathlib import Path\n","from collections import Counter\n","from collections import defaultdict\n","from threading import Timer\n","from PIL import Image\n","\n","from py_files.new_dataset import *\n","\n","from py_files.cnn_model import *\n","from py_files.pigan_model import *\n","\n","from kornia.augmentation.augmentation3d import *\n","from kornia.geometry.transform import *\n","\n","import numbers\n","from collections import defaultdict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uxcgLSNcl0us"},"source":["#### ARGS class for .ipynb files"]},{"cell_type":"code","metadata":{"id":"mDac2IlAl0ut"},"source":["class init_ARGS(object): \n","    def __init__(self): \n","        self.device = \"GPU\"\n","        self.print_models = False\n","        self.name = \"\"\n","        self.pretrained = None\n","        self.pretrained_best_dataset = \"train\"\n","        self.pretrained_best_loss = \"mask\"\n","        self.pretrained_models = None\n","        self.pretrained_lr_reset = None\n","        self.dataset = \"new\"\n","        self.seed = 34\n","        self.rotate = True\n","        self.translate = True\n","        self.translate_max_pixels = 20\n","        self.flip = True\n","        self.crop = True\n","        self.stretch = True\n","        self.stretch_factor = 1.2\n","        self.norm_min_max = [0, 1]\n","        self.pcmra_epochs = 5000\n","        self.mask_epochs = 5000\n","        self.batch_size = 24\n","        self.eval_every = 50\n","        self.shuffle = True\n","        self.n_coords_sample = 5000\n","        self.min_lr = 1e-5\n","        self.cnn_setup = -1\n","        self.pcmra_train_cnn = True\n","        self.mask_train_cnn = True\n","        self.mapping_setup = -1\n","        self.dim_hidden = 256\n","        self.siren_hidden_layers = 3\n","        self.first_omega_0 = 30.\n","        self.hidden_omega_0 = 30.\n","        self.pcmra_first_omega_0 = 30.\n","        self.pcmra_hidden_omega_0 = 30.\n","        self.cnn_lr = 1e-4\n","        self.cnn_wd = 0\n","        self.mapping_lr = 1e-4\n","        self.pcmra_mapping_lr = 1e-4\n","        self.siren_lr = 1e-4\n","        self.siren_wd = 0\n","        self.pcmra_siren_lr = 1e-4\n","        self.pcmra_siren_wd = 0\n","        self.patience = 200\n","\n","\n","        print(\"WARNING: ARGS class initialized.\")\n","\n","    def set_args(self, dictionary):\n","        for k, v in dictionary.items():\n","            setattr(self, k, v)\n","          \n","        \n","def load_args(run, print_changed=True):\n","    run_path = os.path.join(\"saved_runs\", run, \"ARGS.txt\")\n","\n","    with  open(run_path, \"r\") as f:\n","        contents = f.read()\n","        args_dict = ast.literal_eval(contents)\n","    \n","    ARGS = init_ARGS()\n","    \n","    old_args = vars(ARGS)\n","    \n","    if print_changed:\n","        for k, v in args_dict.items(): \n","            if k in old_args.keys(): \n","                if old_args[k] != v: \n","                    print(f\"Changed param \\t{k}: {v}.\") \n","            else:\n","                print(f\"New param \\t{k}: {v}.\")\n","            \n","    ARGS.set_args(args_dict)\n","    \n","    return ARGS"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oyMHV1OLl0uw"},"source":["#### Set torch device"]},{"cell_type":"code","metadata":{"id":"7JGwOjGHl0ux"},"source":["def set_device():\n","    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    \n","    print('----------------------------------')\n","    print('Using device for training:', DEVICE)\n","    print('----------------------------------')\n","\n","    return DEVICE "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YPWjof-ql0uz"},"source":["####  Model saving functions "]},{"cell_type":"code","metadata":{"id":"H14tlZ1Fl0u0"},"source":["def get_folder(ARGS): \n","    now = datetime.now()\n","    dt = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n","    path = f\"saved_runs/pi-gan {dt} {ARGS.name}\"\n","    \n","    Path(f\"{path}\").mkdir(parents=True, exist_ok=True)   \n","\n","    return path\n","    \n","\n","def plot_graph(path, x, ys_and_labels, axes=(\"Epochs\", \"BCELoss\"), fig_name=\"loss_plot\"):\n","    fig, ax = plt.subplots()\n","    fig.patch.set_facecolor('white')\n","    \n","    for y, label in ys_and_labels: \n","        ax.plot(x[1:], y[1:], label=label)\n","\n","    plt.xlabel(axes[0])\n","    plt.ylabel(axes[1])\n","    legend = ax.legend(loc='upper right')\n","    \n","    plt.savefig(f\"{path}/{fig_name}.png\")\n","    plt.close()\n","\n","    \n","def save_loss(path, loss, models, optims, name=\"loss\", save_models=True):\n","    np.save(f\"{path}/{name}.npy\", loss)\n","    \n","    eps, t_loss, v_loss = loss[:, 0], loss[:, 1], loss[:, 3]\n","    \n","    print(f\"{name.ljust(15)} Train: {str(round(t_loss[-1], 6)).ljust(8, '0')}, \\t Eval: {str(round(v_loss[-1], 6)).ljust(8, '0')}\")\n","    \n","    if save_models:\n","        if t_loss[-1] == t_loss.min(): \n","            print(f\"New best train loss, saving model.\")\n","            if save_models:\n","                for model in models.keys():\n","                    torch.save(models[model].state_dict(), f\"{path}/{model}_{name}_train.pt\")\n","                    torch.save(optims[model].state_dict(), f\"{path}/{model}_optim_{name}_train.pt\")\n","    \n","        if v_loss[-1] == v_loss.min(): \n","            print(f\"New best eval  loss, saving model.\")\n","            if save_models:\n","                for model in models.keys():\n","                    torch.save(models[model].state_dict(), f\"{path}/{model}_{name}_val.pt\")\n","                    torch.save(optims[model].state_dict(), f\"{path}/{model}_optim_{name}_val.pt\")\n","        \n","    plot_graph(path, eps, [(t_loss, \"Train loss\"), (v_loss, \"Eval loss\")], \n","               axes=(\"Epochs\", \"Loss\"), fig_name=f\"{name}_plot\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZ6iD24Zl0u3"},"source":["#### Initialize dataloaders"]},{"cell_type":"code","metadata":{"id":"LQLaspe_l0u6"},"source":["def initialize_dataloaders(ARGS):\n","    \n","    if ARGS.device.lower() == \"cpu\": \n","        DEVICE = torch.device(\"cpu\")\n","        \n","        print('----------------------------------')\n","        print('Using device for training:', DEVICE)\n","        print('----------------------------------')\n","    \n","    else: \n","        DEVICE = set_device()\n","    \n","    assert(ARGS.dataset in [\"full\", \"small\", \"new\"])\n","    \n","    root = os.path.abspath('..')\n","    root = os.path.join(root, \"Dataset\")\n","\n","    if ARGS.dataset == \"small\":\n","        root = os.path.join(root, \"scaled_normalized\")\n","    \n","    elif ARGS.dataset == \"full\":\n","        root = os.path.join(root, \"original_normalized\")\n","    \n","    else: \n","        root = os.path.join(root, \"new_original\")        \n","        \n","    subjects = [file.split(\"__\")[:2] for file in  sorted(os.listdir(root))]\n","    subjects = np.array(sorted([list(subj) for subj in list(set(map(tuple, subjects)))]))\n","    \n","    idx = list(range(subjects.shape[0]))\n","    split1, split2 = int(len(idx) * 0.6), int(len(idx) * 0.8)\n","    \n","    random.seed(ARGS.seed)\n","\n","    random.shuffle(idx) # shuffles indices\n","    train_idx, val_idx, test_idx = idx[:split1], idx[split1:split2], idx[split2:] # incides per data subset\n","\n","    train_subjects, val_subjects, test_subjects =  subjects[train_idx], subjects[val_idx], subjects[test_idx]\n","\n","    train_ds = SirenDataset(root, train_subjects, DEVICE)\n","    train_dl = DataLoader(train_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=ARGS.shuffle)\n","    print(\"Train subjects:\", train_ds.__len__())\n","    \n","    val_ds =  SirenDataset(root, val_subjects, DEVICE)\n","    val_dl = DataLoader(val_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=False)\n","    print(\"Val subjects:\", val_ds.__len__())\n","    \n","    test_ds =  SirenDataset(root, test_subjects, DEVICE)\n","    test_dl = DataLoader(test_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=False)\n","    print(\"Test subjects:\", test_ds.__len__())\n","\n","    return train_dl, val_dl, test_dl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b00Z5tGRl0u8"},"source":["#### Image transformations"]},{"cell_type":"code","metadata":{"id":"shH8kaIll0u9"},"source":["##### TRANSLATE FUNCTIONS #####\n","\n","def get_random_shift(ARGS):\n","        max_t = (4, ARGS.translate_max_pixels, ARGS.translate_max_pixels)\n","        \n","        shifts = (random.randint(-max_t[0], max_t[0]), \n","                  random.randint(-max_t[1], max_t[1]), \n","                  random.randint(-max_t[2], max_t[2]))\n","        return shifts\n","     \n","def translate_image(image, shifts):\n","    \n","    image = torch.roll(image, shifts=shifts, dims=(0, 1, 2))\n","\n","    for axis, shift in enumerate(shifts):\n","        idx = [[None, None], [None, None], [None, None]]\n","\n","        if shift > 0: \n","            idx[axis][1] = shift\n","        elif shift < 0: \n","            idx[axis][0] = shift\n","        else:\n","            continue\n","\n","        image[idx[0][0]:idx[0][1], idx[1][0]:idx[1][1], idx[2][0]:idx[2][1]] = 0\n","\n","    return image\n","\n","def translate_batch(batch, ARGS): \n","    idx, subj, proj, pcmras, masks, loss_covers = batch\n","    \n","    new_pcmras = new_masks = new_loss_covers = torch.empty((0)).to(pcmras.device)\n","    \n","    for pcmra, mask, loss_cover in zip(pcmras, masks, loss_covers): \n","        pcmra, mask, loss_cover = pcmra.squeeze(), mask.squeeze(), loss_cover.squeeze()\n","        \n","        shifts = get_random_shift(ARGS)\n","        pcmra = translate_image(pcmra, shifts).unsqueeze(0).unsqueeze(0)\n","        mask = translate_image(mask, shifts).unsqueeze(0).unsqueeze(0)\n","        loss_cover = translate_image(loss_cover, shifts).unsqueeze(0).unsqueeze(0)\n","\n","        new_pcmras = torch.cat((new_pcmras, pcmra), 0)\n","        new_masks = torch.cat((new_masks, mask), 0)\n","        new_loss_covers = torch.cat((new_loss_covers, loss_cover), 0)\n","    \n","    return idx, subj, proj, new_pcmras, new_masks, new_loss_covers\n","    \n","##### FLIP FUNCTION #####\n","\n","def flip_batch(batch): \n","    d_flip, h_flip, v_flip = RandomDepthicalFlip3D(), RandomHorizontalFlip3D(), RandomVerticalFlip3D()\n","    \n","    idx, subj, proj, pcmras, masks, loss_covers = batch\n","    pcmra_masks = torch.cat((pcmras, masks, loss_covers), 1)\n","    \n","    pcmra_masks = d_flip(pcmra_masks)\n","    pcmra_masks = h_flip(pcmra_masks)\n","    pcmra_masks = v_flip(pcmra_masks)\n","    \n","    pcmras, masks, loss_covers = pcmra_masks.split(1, dim=1)\n","\n","    return idx, subj, proj, pcmras, masks, loss_covers\n","    \n","##### ROTATION FUNCTION #####\n","\n","def rotate_batch(batch):\n","    rotate = RandomRotation3D((10., 15., 15.), p=1.0)\n","    \n","    idx, subj, proj, pcmras, masks, loss_covers = batch\n","    pcmra_masks = torch.cat((pcmras, masks, loss_covers), 1)\n","    \n","    pcmra_masks = rotate(pcmra_masks)\n","    pcmras, masks, loss_covers = pcmra_masks.split(1, dim=1)\n","    \n","    return idx, subj, proj, pcmras, masks, loss_covers\n","\n","##### CROP FUNCTIONS #####\n","\n","def crop_batch(batch, stretch=True, stretch_factor=1.2):\n","    idx, subj, proj, pcmras, masks, loss_covers = batch\n","    \n","    orig_shape = pcmras.shape[2:]\n","    \n","    crop_sample = RandomCrop3D(orig_shape, p=1.)\n","    \n","    rand = random.uniform\n","    inc = stretch_factor\n","    if stretch:\n","        resize = [rand(1., inc), rand(1., inc), rand(1., inc)]\n","    else: \n","        resize = [rand(1., inc)] * 3\n","    \n","    size = tuple([int(i * j) for i, j in zip(orig_shape, resize)])\n","    \n","    pcmras = F.interpolate(pcmras, size=size, mode=\"trilinear\")\n","    masks = F.interpolate(masks, size=size, mode=\"trilinear\")\n","    loss_covers = F.interpolate(loss_covers, size=size, mode=\"trilinear\")\n","    \n","    pcmra_masks = torch.cat((pcmras, masks, loss_covers), 1)\n","    pcmra_masks = crop_sample(pcmra_masks)\n","\n","    pcmras, masks, loss_covers = pcmra_masks.split(1, dim=1)\n","\n","    return idx, subj, proj, pcmras, masks, loss_covers\n","\n","\n","##### complete transformation #####\n","\n","def transform_batch(batch, ARGS):\n","        \n","    if ARGS.flip: \n","        batch = flip_batch(batch)\n","    if ARGS.translate: \n","        batch = translate_batch(batch, ARGS)\n","    if ARGS.crop: \n","        batch = crop_batch(batch, ARGS.stretch, ARGS.stretch_factor)\n","    if ARGS.rotate: \n","        batch = rotate_batch(batch)\n","    \n","    idx, subj, proj, pcmras, masks, loss_covers = batch\n","    \n","    masks = torch.round(masks)\n","    loss_covers = torch.floor(torch.round(loss_covers*10) / 10)\n","    \n","    return idx, subj, proj, pcmras, masks, loss_covers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B5q7EsvSl0u_"},"source":["#### Create siren arrays (OLD VERSION)"]},{"cell_type":"code","metadata":{"id":"Dw0h_vOZl0vA"},"source":["# def get_siren_batch(batch): \n","#     idx, subj, proj, pcmras, masks, loss_covers = batch\n","\n","#     length = prod(pcmras.shape[2:])\n","    \n","#     coords = get_coords(*pcmras.shape[2:]).to(pcmras.device).unsqueeze(0)\n","# #     print(\"c\", coords.shape)\n","#     coords = coords.repeat(pcmras.shape[0], 1, 1)\n","    \n","#     pcmra_array = pcmras.view(pcmras.shape[0], length, 1)\n","#     mask_array = masks.view(pcmras.shape[0], length, 1)\n","#     loss_cover_array = loss_covers.view(loss_covers.shape[0], length, 1)\n","    \n","#     return idx, subj, proj, pcmras, coords, pcmra_array, mask_array, loss_cover_array\n","\n","def prod(val) :  \n","    res = 1 \n","    for ele in val:  \n","        res *= ele  \n","    return res \n","\n","    \n","def get_coords(*sidelengths):\n","    tensors = []\n","\n","    for sidelen in sidelengths:\n","        tensors.append(torch.linspace(-1, 1, steps=sidelen))\n","\n","    tensors = tuple(tensors)\n","    coords = torch.stack(torch.meshgrid(*tensors), dim=-1)\n","\n","    return coords.reshape(-1, len(sidelengths))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qf-yPtdxpB0_"},"source":["Create SIREN arrays"]},{"cell_type":"code","metadata":{"id":"5slTtGq7pD1J"},"source":["class GaussianSmoothing(nn.Module):\n","    \"\"\"\n","    Apply gaussian smoothing on a\n","    1d, 2d or 3d tensor. Filtering is performed seperately for each channel\n","    in the input using a depthwise convolution.\n","    Arguments:\n","        channels (int, sequence): Number of channels of the input tensors. Output will\n","            have this number of channels as well.\n","        kernel_size (int, sequence): Size of the gaussian kernel.\n","        sigma (float, sequence): Standard deviation of the gaussian kernel.\n","        dim (int, optional): The number of dimensions of the data.\n","            Default value is 2 (spatial).\n","    \"\"\"\n","    def __init__(self, channels, kernel_size, sigma, dim=2):\n","        super(GaussianSmoothing, self).__init__()\n","        if isinstance(kernel_size, numbers.Number):\n","            kernel_size = [kernel_size] * dim\n","            self.kernel_radius = kernel_size // 2\n","        else:\n","            self.kernel_radius = kernel_size[0] // 2\n","\n","        if isinstance(sigma, numbers.Number):\n","            sigma = [sigma] * dim\n","\n","\n","        # The gaussian kernel is the product of the\n","        # gaussian function of each dimension.\n","        kernel = 1\n","        meshgrids = torch.meshgrid(\n","            [\n","                torch.arange(size, dtype=torch.float32)\n","                for size in kernel_size\n","            ]\n","        )\n","        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n","            mean = (size - 1) / 2\n","            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n","                      torch.exp(-((mgrid - mean) / (2 * std)) ** 2)\n","\n","        # Make sure sum of values in gaussian kernel equals 1.\n","        kernel = kernel / torch.sum(kernel)\n","\n","        # Reshape to depthwise convolutional weight\n","        kernel = kernel.view(1, 1, *kernel.size())\n","        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n","\n","        self.register_buffer('weight', kernel)\n","        self.groups = channels\n","\n","        if dim == 1:\n","            self.conv = F.conv1d\n","        elif dim == 2:\n","            self.conv = F.conv2d\n","        elif dim == 3:\n","            self.conv = F.conv3d\n","        else:\n","            raise RuntimeError(\n","                'Only 1, 2 and 3 dimensions are supported. Received {}.'.format(dim)\n","            )\n","\n","    def forward(self, input):\n","        \"\"\"\n","        Apply gaussian filter to input.\n","        Arguments:\n","            input (torch.Tensor): Input to apply gaussian filter on.\n","        Returns:\n","            filtered (torch.Tensor): Filtered output.\n","        \"\"\"\n","        return self.conv(input, weight=self.weight, groups=self.groups, padding=self.kernel_radius)\n","    \n","    \n","def gradient3d(data, normalize=False, s=2):\n","    data_padded = torch.nn.functional.pad(data, (1,1,1,1,1,1,0,0,0,0))\n","\n","    grad_x = (data_padded[:,:, s:,   1:-1, 1:-1] - data_padded[:,:, 0:-s, 1:-1, 1:-1]) / s\n","    grad_y = (data_padded[:,:, 1:-1, s:,   1:-1] - data_padded[:,:, 1:-1, 0:-s, 1:-1]) / s\n","    grad_z = (data_padded[:,:, 1:-1, 1:-1, s:  ] - data_padded[:,:, 1:-1, 1:-1 ,0:-s]) / s\n","    \n","    grad = torch.cat([grad_x,grad_y,grad_z], dim=1)\n","    grad_magn = torch.sqrt(grad_x**2 + grad_y**2 + grad_z**2)\n","    \n","    if normalize:\n","        eps=1e-8\n","        grad = grad/(grad_magn + eps)\n","    \n","    return grad, grad_magn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lY9Bu8DKH0W7"},"source":["def initialize_blurring_layer(sigma, DEVICE):\n","    # Initialize the blurring layer\n","    size = math.ceil(3*sigma)\n","    return GaussianSmoothing(1, [size,size,size], sigma, dim=3).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbxMBcZZpNMG"},"source":["def get_surface_and_norm(batch): \n","    masks_blurred = blur_layer(batch[-2])     \n","\n","    grad, grad_magn = gradient3d(masks_blurred, normalize=True, s=2)\n","\n","    surface = (grad_magn >= 0.5*torch.max(grad_magn)).type(torch.float32)\n","    norm = grad * surface\n","    \n","    return surface, norm\n","\n","def reshape_arrays(*arrays): \n","    return [array.view(array.shape[0], array.shape[1], -1).permute(0, 2, 1) for array in arrays]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFOxhLcapO0G"},"source":["def get_siren_batch(batch, blur_layer, ARGS): \n","    \n","    n = ARGS.n_coords_sample\n","    sdf_split = ARGS.sdf_split\n","\n","    idx, subj, proj, pcmras, masks, loss_covers = batch\n","    subjects = []\n"," \n","    # initialize a coords matrix\n","    coords = get_coords(*pcmras.shape[2:]).to(pcmras.device)\n","\n","    # reshape all matrixes \n","    pcmra_array, mask_array, loss_cover_array = reshape_arrays(pcmras, masks, loss_covers)\n","    coords_array = coords.unsqueeze(0).repeat(pcmras.shape[0], 1, 1)\n","    if ARGS.sdf: \n","        # get the surface and norm of the mask\n","        surface_n, random_n = int(n*sdf_split), n - int(n*sdf_split)\n","        surfaces, norms = get_surface_and_norm(batch)        \n","        surface_array, norm_array = reshape_arrays(surfaces, norms)\n","        \n","    elif not ARGS.sdf: \n","        surface_array = norm_array = torch.tensor([]).repeat(pcmras.shape[0], 1)\n","\n","    if n != -1:\n","        # select n coords and their corresponding values\n","        for pcmra, mask, loss_cover, surface, norm in \\\n","            zip(pcmra_array, mask_array, loss_cover_array, surface_array, norm_array):\n","\n","            if ARGS.sdf:\n","                # select n * sfd_split points that lie on the surface\n","                surface_idx = (surface != 0).nonzero()[:, 0].flatten().cpu().numpy()\n","                surface_idx = np.random.choice(surface_idx, surface_n)\n","\n","                # select n random coords that have a non zero loss_cover\n","                random_idx = (loss_cover != 0).nonzero()[:, 0].cpu().numpy()\n","                random_idx = np.random.choice(random_idx, random_n)\n","\n","                idx = np.concatenate((surface_idx, random_idx))\n","        \n","                subject = [coords[idx, :].unsqueeze(0), pcmra[idx, :].unsqueeze(0), mask[idx, :].unsqueeze(0),\n","                        surface[idx, :].unsqueeze(0), norm[idx, :].unsqueeze(0)]\n","\n","            elif not ARGS.sdf: \n","                # select n random coords that have a non zero loss_cover\n","                idx = (loss_cover != 0).nonzero()[:, 0].cpu().numpy()\n","                idx = np.random.choice(idx, n)\n","                \n","                subject = [coords[idx, :].unsqueeze(0), pcmra[idx, :].unsqueeze(0), mask[idx, :].unsqueeze(0),\n","                        torch.tensor([]).unsqueeze(0), torch.tensor([]).unsqueeze(0)]\n","\n","            subjects.append(subject)\n","\n","        coords_array = torch.cat([subj[0] for subj in subjects], 0)\n","        pcmra_array = torch.cat([subj[1] for subj in subjects], 0)\n","        mask_array = torch.cat([subj[2] for subj in subjects], 0)\n","        surface_array = torch.cat([subj[3] for subj in subjects], 0)\n","        norm_array = torch.cat([subj[4] for subj in subjects], 0)\n","    \n","    return idx, subj, proj, pcmras, coords_array, pcmra_array, mask_array, surface_array, norm_array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcX-NC2M1LO_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7t9Pkypbl0vB"},"source":["#### Initialize models"]},{"cell_type":"code","metadata":{"id":"i0yOhAcml0vB"},"source":["def cnn_model_optim_scheduler(ARGS, DEVICE): \n","    model = load_cnn(ARGS).to(DEVICE)\n","    optim = torch.optim.Adam(lr=ARGS.cnn_lr, params=model.parameters(), weight_decay=ARGS.cnn_wd)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=ARGS.patience, factor=.5, verbose=True, min_lr=ARGS.min_lr)\n","    \n","    return model, optim, scheduler\n","\n","\n","def mapping_model_optim_scheduler(ARGS, lr, DEVICE):\n","    model= load_mapping(ARGS).to(DEVICE)\n","    optim = torch.optim.Adam(lr=lr, params=model.parameters())\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=ARGS.patience, factor=.5, verbose=True, min_lr=ARGS.min_lr)\n","\n","    return model, optim, scheduler\n","    \n","\n","def siren_model_optim_scheduler(ARGS, first_omega_0, hidden_omega_0, lr, wd, final_activation, DEVICE):\n","    model = Siren(ARGS, in_features=3, out_features=1,first_omega_0=first_omega_0, \n","                            hidden_omega_0=hidden_omega_0, final_activation=final_activation).to(DEVICE)\n","    optim = torch.optim.Adam(lr=lr, params=model.parameters(), weight_decay=wd)    \n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=ARGS.patience, factor=.5, verbose=True, min_lr=ARGS.min_lr)\n","    \n","    return model, optim, scheduler\n","\n","\n","def load_models_and_optims(ARGS):\n","    \n","    if ARGS.device.lower() == \"cpu\": \n","        DEVICE = torch.device(\"cpu\")\n","        \n","        print('----------------------------------')\n","        print('Using device for training:', DEVICE)\n","        print('----------------------------------')\n","\n","    else: \n","        DEVICE = set_device()\n","        \n","    models, optims, schedulers = {}, {}, {}\n","    \n","    models[\"cnn\"], optims[\"cnn\"], schedulers[\"cnn\"] = cnn_model_optim_scheduler(ARGS, DEVICE)\n","    \n","    models[\"mapping\"], optims[\"mapping\"], \\\n","        schedulers[\"mapping\"] = mapping_model_optim_scheduler(ARGS, ARGS.mapping_lr, DEVICE)\n","    \n","    \n","    models[\"siren\"], optims[\"siren\"], schedulers[\"siren\"] = \\\n","        siren_model_optim_scheduler(ARGS, ARGS.first_omega_0, ARGS.hidden_omega_0, \n","                                    ARGS.siren_lr, ARGS.siren_wd, \"sigmoid\", DEVICE)\n","    \n","    models[\"pcmra_mapping\"], optims[\"pcmra_mapping\"], \\\n","        schedulers[\"pcmra_mapping\"] = mapping_model_optim_scheduler(ARGS, ARGS.pcmra_mapping_lr, DEVICE)\n","   \n","    models[\"pcmra_siren\"], optims[\"pcmra_siren\"], schedulers[\"pcmra_siren\"] = \\\n","        siren_model_optim_scheduler(ARGS, ARGS.pcmra_first_omega_0, ARGS.pcmra_hidden_omega_0, \n","                                    ARGS.pcmra_siren_lr, ARGS.pcmra_siren_wd, None, DEVICE)\n","\n","    for model, struct in models.items(): \n","        print(model.upper())\n","        if ARGS.print_models:\n","            print(struct)\n","\n","    return models, optims, schedulers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z61eeZOOl0vD"},"source":["#####  Random coords subsample"]},{"cell_type":"code","metadata":{"id":"d8bf9jFal0vD"},"source":["def choose_random_coords(*arrays, n=1000): \n","    batch_size, max_int, _ = arrays[0].shape\n","\n","    batch_n = np.repeat(np.expand_dims(list(range(batch_size)), axis=1), n, axis=1)\n","    rand_ints = np.random.randint(0, max_int, size=(batch_size, n))\n","\n","    if not n == -1:\n","        arrays = [array[batch_n, rand_ints, :].detach().clone() for array in arrays]\n","        \n","    return arrays"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hlgHy7jOl0vE"},"source":["#### Dice loss"]},{"cell_type":"code","metadata":{"id":"DHHnuX0Ll0vE"},"source":["def calc_dice_loss(pred, target):\n","    \n","    smooth = 0.\n","\n","    pred = torch.round(pred)\n","\n","    pflat = pred.flatten()\n","    tflat = target.flatten()\n","    intersection = (pflat * tflat).sum()\n","\n","    A_sum = torch.sum(pflat * pflat)\n","    B_sum = torch.sum(tflat * tflat)\n","    \n","    return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JY4-XbaOl0vF"},"source":["#### Train and validation epoch functions"]},{"cell_type":"code","metadata":{"id":"Lbxoh4w4l0vF"},"source":["def train_model(dataloader, models, optims, schedulers, criterion, blur_layer, ARGS, output=\"pcmra\"): \n","    losses = [] \n","    \n","    for batch in dataloader:\n","                    \n","        batch = transform_batch(batch, ARGS)            \n","        _, _, _, pcmra, coords_array, pcmra_array, mask_array, surface_array, norm_array = get_siren_batch(batch, blur_layer, ARGS)\n","        \n","        latent_rep = models[\"cnn\"](pcmra) # get latent representation\n","        \n","        if output == \"pcmra\": \n","            siren_in, labels = coords_array, pcmra_array\n","            \n","            if ARGS.pcmra_train_cnn:\n","                gamma, beta = models[\"pcmra_mapping\"](latent_rep)\n","                model_keys = [\"cnn\", \"pcmra_mapping\", \"pcmra_siren\"]\n","                \n","            else:\n","                gamma, beta = models[\"pcmra_mapping\"](latent_rep.detach())\n","                model_keys = [\"pcmra_mapping\", \"pcmra_siren\"]\n","            \n","            out = models[\"pcmra_siren\"](siren_in, gamma, beta)            \n","            \n","        elif output == \"mask\": \n","            siren_in, labels = coords_array, mask_array\n","\n","            if ARGS.mask_train_cnn:\n","                gamma, beta = models[\"mapping\"](latent_rep)\n","                model_keys = [\"cnn\", \"mapping\", \"siren\"]\n","                \n","            else:\n","                gamma, beta = models[\"mapping\"](latent_rep.detach())\n","                model_keys = [\"mapping\", \"siren\"]\n","            \n","            out = models[\"siren\"](siren_in, gamma, beta)\n","            \n","        loss = criterion(out, labels)         \n","        losses.append(loss.item())\n","        loss.backward()\n","        \n","        for key in model_keys: \n","            optims[key].step()\n","            optims[key].zero_grad()\n","    \n","    mean, std = round(np.mean(losses), 6), round(np.std(losses), 6)\n","\n","    for key in model_keys: \n","        schedulers[key].step(mean)\n","    \n","    return mean, std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IEeJ0Xvl0vG"},"source":["def val_model(dataloader, models, criterion, ARGS, output=\"pcmra\"):\n","    with torch.no_grad():\n","        losses = []\n","        d_losses = []\n","        \n","        for batch in dataloader:\n","                    \n","            _, _, _, pcmra, coords_array, pcmra_array, mask_array, surface_array, norm_array = get_siren_batch(batch, ARGS)\n","    \n","            labels = [pcmra_array if output==\"pcmra\" else mask_array][0]\n","            \n","            out = get_complete_image(models, pcmra, coords_array, ARGS, output=output)\n","            \n","            for s_out, s_labels in zip(out, labels):\n","            \n","                loss = criterion(s_out, s_labels)  \n","                losses.append(loss.item())\n","            \n","                if output==\"mask\":\n","                    d_loss = calc_dice_loss(s_out, s_labels) \n","                else:\n","                    d_loss = torch.tensor([0])\n","\n","                d_losses.append(d_loss.item())\n","\n","        loss_mean, loss_std = round(np.mean(losses), 6), round(np.std(losses), 6)\n","        d_loss_mean, d_loss_std = round(np.mean(d_losses), 6), round(np.std(d_losses), 6)\n","    \n","    return loss_mean, loss_std, d_loss_mean, d_loss_std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wu0pe9hVl0vH"},"source":["def get_complete_image(models, pcmra, coords, ARGS, val_n=10000, output=\"mask\"): \n","    for model in models.values(): \n","        model.eval()  # evaluation mode    \n","    \n","    n_slices = math.ceil(coords.shape[1] / val_n) # number of batches\n","    \n","    latent_rep = models[\"cnn\"](pcmra)                \n","    \n","    for i in range(n_slices):\n","        coords_in = coords[:, (i*val_n) : ((i+1)*val_n), :]\n","        \n","        if output == \"mask\":\n","            gamma, beta = models[\"mapping\"](latent_rep)\n","            siren_out = models[\"siren\"](coords_in, gamma, beta)\n","        \n","        elif output == \"pcmra\": \n","            gamma, beta = models[\"pcmra_mapping\"](latent_rep)    \n","            siren_out = models[\"pcmra_siren\"](coords_in, gamma, beta)\n","        \n","        if i == 0: \n","            image = siren_out.detach()\n","        else:\n","            image = torch.cat((image, siren_out.detach()), 1)\n","    \n","    for model in models.values(): \n","        model.train()  # train mode\n","    \n","    return image "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j8Xjj-w5l0vH"},"source":["#### Load pretrained models"]},{"cell_type":"code","metadata":{"id":"WUMX3iUkl0vI"},"source":["def load_pretrained_models(folder, best_dataset, best_loss, models, optims, DEVICE, pretrained_models=None): \n","    path = f\"saved_runs/{folder}/\"\n","\n","    for key in models.keys():\n","        if pretrained_models == None or key in pretrained_models:\n","            if os.path.exists(f\"{path}/{key}_{best_loss}_loss_{best_dataset}.pt\"):\n","                print(f\"Loading params from {key}\")\n","                models[key].load_state_dict(torch.load(f\"{path}/{key}_{best_loss}_loss_{best_dataset}.pt\", \n","                                            map_location=torch.device(DEVICE)))\n","                optims[key].load_state_dict(torch.load(f\"{path}/{key}_optim_{best_loss}_loss_{best_dataset}.pt\", \n","                                            map_location=torch.device(DEVICE)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3vICh-gcl0vI"},"source":["#### Load CNN and Mapping setup"]},{"cell_type":"code","metadata":{"id":"Inq7rp_il0vJ"},"source":["def load_cnn(ARGS): \n","    if ARGS.cnn_setup == -1: \n","        cnn = LargeCNN1()\n","    elif ARGS.cnn_setup == -2: \n","        cnn = LargeCNN()\n","    elif ARGS.cnn_setup == -3: \n","        cnn = LargeCNN3()\n","    elif ARGS.cnn_setup == -4: \n","        cnn = LargeCNN4()\n","    elif ARGS.cnn_setup == -5: \n","        cnn = LargeCNN5()\n","    elif ARGS.cnn_setup == -6: \n","        cnn = LargeCNN6()\n","\n","        \n","    elif ARGS.cnn_setup == 0: \n","        cnn = Encoder()\n","    elif ARGS.cnn_setup == 1: \n","        cnn = CNN1()\n","    elif ARGS.cnn_setup == 2: \n","        cnn = CNN2()\n","    elif ARGS.cnn_setup == 3: \n","        cnn = Encoder_1()\n","    elif ARGS.cnn_setup == 4: \n","        cnn = Encoder_2()\n","    elif ARGS.cnn_setup == 5: \n","        cnn = CNN3()     \n","    elif ARGS.cnn_setup == 6: \n","        cnn = CNN4()\n","    elif ARGS.cnn_setup == 7: \n","        cnn = CNN5()\n","    elif ARGS.cnn_setup == 8: \n","        cnn = CNN6()\n","    elif ARGS.cnn_setup == 9: \n","        cnn = CNN7()\n","    elif ARGS.cnn_setup == 10: \n","        cnn = CNN8()\n","    elif ARGS.cnn_setup == 11: \n","        cnn = CNN9()\n","    elif ARGS.cnn_setup == 12: \n","        cnn = CNN10()\n","    elif ARGS.cnn_setup == 13: \n","        cnn = CNN11()\n","    elif ARGS.cnn_setup == 14: \n","        cnn = CNN12()\n","    elif ARGS.cnn_setup == 15: \n","        cnn = CNN13()\n","    elif ARGS.cnn_setup == 16: \n","        cnn = CNN14()\n","    elif ARGS.cnn_setup == 17: \n","        cnn = CNN15()\n","    elif ARGS.cnn_setup == 18: \n","        cnn = CNN16()\n","    else: \n","        raise(Exception(\"Choose existing CNN setup\"))\n","        \n","    return cnn\n","\n","def load_mapping(ARGS): \n","    \n","    if ARGS.mapping_setup == -1 or ARGS.mapping_setup == 7: \n","        mapping = LargeMapping1(ARGS)\n","    elif ARGS.mapping_setup == -2: \n","        mapping = LargeMapping2(ARGS)\n","    elif ARGS.mapping_setup == -5: \n","        mapping = LargeMapping5(ARGS)\n","    \n","    \n","    elif ARGS.mapping_setup == 1: \n","        mapping = Mapping1()\n","    elif ARGS.mapping_setup == 2: \n","        mapping = Mapping2()\n","    elif ARGS.mapping_setup == 3: \n","        mapping = Mapping3()\n","    elif ARGS.mapping_setup == 4: \n","        mapping = Mapping4()\n","    elif ARGS.mapping_setup == 0: \n","        mapping = Encoder_Mapping()\n","    elif ARGS.mapping_setup == 5: \n","        mapping = Encoder_Mapping_1()\n","    elif ARGS.mapping_setup == 6: \n","        mapping = Encoder_Mapping_2()\n","    elif ARGS.mapping_setup == 8: \n","        mapping = Encoder_Mapping_4()\n","    else: \n","        raise(Exception(\"Choose existing mapping setup\"))\n","        \n","    return mapping"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kbc9sND9l0vJ"},"source":["#### Function to scroll through output"]},{"cell_type":"code","metadata":{"id":"IpChdam5l0vK"},"source":["class Show_images(object):\n","    \"\"\"\n","    Scroll through slices. Takes an unspecified number of subfigures per figure.\n","    suptitles: either a str or a list. Represents the \n","    main title of a figure. \n","    images_titles: a list with tuples, each tuple an np.array and a \n","    title for the array subfigure. \n","    \"\"\"\n","    def __init__(self, suptitles, *images_titles):\n","        # if string if given, make list with that title for \n","        # each slice.\n","        if type(suptitles) == str: \n","            self.suptitles = []\n","            for i in range(images_titles[0][0].shape[2]): \n","                self.suptitles.append(suptitles)\n","        else: \n","            self.suptitles = suptitles\n","                    \n","        self.fig, self.ax = plt.subplots(1,len(images_titles))\n","\n","        # split tuples with (image, title) into lists\n","        self.images = [x[0] for x in images_titles]\n","        self.titles = [x[1] for x in images_titles]\n","\n","        # get the number of slices that are to be shown\n","        rows, cols, self.slices = self.images[0].shape        \n","        self.ind = 0\n","\n","        self.fig.suptitle(self.suptitles[self.ind]) # set title \n","\n","        self.plots = []\n","        \n","        # start at slice 10 if more than 20 slices, \n","        # otherwise start at middle slice.\n","        if self.images[0].shape[2] > 20: \n","            self.ind = 10\n","        else:\n","            self.ind = self.images[0].shape[2] // 2\n","        \n","        # make sure ax is an np array\n","        if type(self.ax) == np.ndarray:\n","            pass\n","        else: \n","            self.ax = np.array([self.ax])\n","        \n","        # create title for each subfigure in slice\n","        for (sub_ax, image, title) in zip(self.ax, self.images, self.titles): \n","            sub_ax.set_title(title)\n","            plot = sub_ax.imshow(image[:, :, self.ind], vmin=0, vmax=1)\n","            self.plots.append(plot)\n","\n","            \n","        # link figure to mouse scroll movement\n","        self.plot_show = self.fig.canvas.mpl_connect('scroll_event', self.onscroll)\n","        \n","\n","    def onscroll(self, event):\n","        \"\"\"\n","        Shows next or previous slice with mouse scroll.\n","        \"\"\"\n","        if event.button == 'up':\n","            self.ind = (self.ind - 1) % self.slices\n","        else:\n","            self.ind = (self.ind + 1) % self.slices\n","        \n","        self.update()\n","        \n","\n","    def update(self):\n","        \"\"\"\n","        Updates the figure.\n","        \"\"\"\n","        self.fig.suptitle(self.suptitles[self.ind])\n","        \n","        for plot, image in zip(self.plots, self.images):\n","            plot.set_data(image[:, :, self.ind])\n","        \n","        self.ax[0].set_ylabel('Slice Number: %s' % self.ind)\n","        self.plots[0].axes.figure.canvas.draw()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ym8FCWZ4l0vK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7T-ak1gnl0vL"},"source":["print(\"Loaded all helper functions.\")"],"execution_count":null,"outputs":[]}]}