{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import math \n",
    "import skimage\n",
    "import pickle\n",
    "import ast\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mplPath\n",
    "import pylab as pl\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from threading import Timer\n",
    "from PIL import Image\n",
    "\n",
    "from py_files.new_dataset import *\n",
    "\n",
    "from py_files.cnn_model import *\n",
    "from py_files.pigan_model import *\n",
    "\n",
    "from kornia.augmentation.augmentation3d import *\n",
    "from kornia.geometry.transform import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARGS class for .ipynb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class init_ARGS(object): \n",
    "    def __init__(self): \n",
    "        self.device = \"GPU\"\n",
    "        self.print_models = False\n",
    "        self.name = \"\"\n",
    "        self.pretrained = None\n",
    "        self.pretrained_best_dataset = \"train\"\n",
    "        self.pretrained_best_loss = \"mask\"\n",
    "        self.pretrained_models = None\n",
    "        self.pretrained_lr_reset = None\n",
    "        self.dataset = \"new\"\n",
    "        self.seed = 34\n",
    "        self.rotate = True\n",
    "        self.translate = True\n",
    "        self.translate_max_pixels = 20\n",
    "        self.flip = True\n",
    "        self.crop = True\n",
    "        self.stretch = True\n",
    "        self.stretch_factor = 1.2\n",
    "        self.norm_min_max = [0, 1]\n",
    "        self.pcmra_epochs = 5000\n",
    "        self.mask_epochs = 5000\n",
    "        self.batch_size = 24\n",
    "        self.eval_every = 50\n",
    "        self.shuffle = True\n",
    "        self.n_coords_sample = 5000\n",
    "        self.min_lr = 1e-5\n",
    "        self.cnn_setup = -1\n",
    "        self.pcmra_train_cnn = True\n",
    "        self.mask_train_cnn = True\n",
    "        self.mapping_setup = -1\n",
    "        self.dim_hidden = 256\n",
    "        self.siren_hidden_layers = 3\n",
    "        self.first_omega_0 = 30.\n",
    "        self.hidden_omega_0 = 30.\n",
    "        self.pcmra_first_omega_0 = 30.\n",
    "        self.pcmra_hidden_omega_0 = 30.\n",
    "        self.cnn_lr = 1e-4\n",
    "        self.cnn_wd = 0\n",
    "        self.mapping_lr = 1e-4\n",
    "        self.pcmra_mapping_lr = 1e-4\n",
    "        self.siren_lr = 1e-4\n",
    "        self.siren_wd = 0\n",
    "        self.pcmra_siren_lr = 1e-4\n",
    "        self.pcmra_siren_wd = 0\n",
    "        self.patience = 200\n",
    "\n",
    "\n",
    "        print(\"WARNING: ARGS class initialized.\")\n",
    "\n",
    "    def set_args(self, dictionary):\n",
    "        for k, v in dictionary.items():\n",
    "            setattr(self, k, v)\n",
    "          \n",
    "        \n",
    "def load_args(run, print_changed=True):\n",
    "    run_path = os.path.join(\"saved_runs\", run, \"ARGS.txt\")\n",
    "\n",
    "    with  open(run_path, \"r\") as f:\n",
    "        contents = f.read()\n",
    "        args_dict = ast.literal_eval(contents)\n",
    "    \n",
    "    ARGS = init_ARGS()\n",
    "    \n",
    "    old_args = vars(ARGS)\n",
    "    \n",
    "    if print_changed:\n",
    "        for k, v in args_dict.items(): \n",
    "            if k in old_args.keys(): \n",
    "                if old_args[k] != v: \n",
    "                    print(f\"Changed param \\t{k}: {v}.\") \n",
    "            else:\n",
    "                print(f\"New param \\t{k}: {v}.\")\n",
    "            \n",
    "    ARGS.set_args(args_dict)\n",
    "    \n",
    "    return ARGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set torch device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print('----------------------------------')\n",
    "    print('Using device for training:', DEVICE)\n",
    "    print('----------------------------------')\n",
    "\n",
    "    return DEVICE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model saving functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder(ARGS): \n",
    "    now = datetime.now()\n",
    "    dt = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    path = f\"saved_runs/pi-gan {dt} {ARGS.name}\"\n",
    "    \n",
    "    Path(f\"{path}\").mkdir(parents=True, exist_ok=True)   \n",
    "\n",
    "    return path\n",
    "    \n",
    "\n",
    "def plot_graph(path, x, ys_and_labels, axes=(\"Epochs\", \"BCELoss\"), fig_name=\"loss_plot\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    for y, label in ys_and_labels: \n",
    "        ax.plot(x[1:], y[1:], label=label)\n",
    "\n",
    "    plt.xlabel(axes[0])\n",
    "    plt.ylabel(axes[1])\n",
    "    legend = ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.savefig(f\"{path}/{fig_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def save_loss(path, loss, models, optims, name=\"loss\", save_models=True):\n",
    "    np.save(f\"{path}/{name}.npy\", loss)\n",
    "    \n",
    "    eps, t_loss, v_loss = loss[:, 0], loss[:, 1], loss[:, 3]\n",
    "    \n",
    "    print(f\"{name.ljust(15)} Train: {str(round(t_loss[-1], 6)).ljust(8, '0')}, \\t Eval: {str(round(v_loss[-1], 6)).ljust(8, '0')}\")\n",
    "    \n",
    "    if save_models:\n",
    "        if t_loss[-1] == t_loss.min(): \n",
    "            print(f\"New best train loss, saving model.\")\n",
    "            if save_models:\n",
    "                for model in models.keys():\n",
    "                    torch.save(models[model].state_dict(), f\"{path}/{model}_{name}_train.pt\")\n",
    "                    torch.save(optims[model].state_dict(), f\"{path}/{model}_optim_{name}_train.pt\")\n",
    "    \n",
    "        if v_loss[-1] == v_loss.min(): \n",
    "            print(f\"New best eval  loss, saving model.\")\n",
    "            if save_models:\n",
    "                for model in models.keys():\n",
    "                    torch.save(models[model].state_dict(), f\"{path}/{model}_{name}_val.pt\")\n",
    "                    torch.save(optims[model].state_dict(), f\"{path}/{model}_optim_{name}_val.pt\")\n",
    "        \n",
    "    plot_graph(path, eps, [(t_loss, \"Train loss\"), (v_loss, \"Eval loss\")], \n",
    "               axes=(\"Epochs\", \"Loss\"), fig_name=f\"{name}_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dataloaders(ARGS):\n",
    "    \n",
    "    if ARGS.device.lower() == \"cpu\": \n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Using device for training:', DEVICE)\n",
    "        print('----------------------------------')\n",
    "    \n",
    "    else: \n",
    "        DEVICE = set_device()\n",
    "    \n",
    "    assert(ARGS.dataset in [\"full\", \"small\", \"new\"])\n",
    "    \n",
    "    root = os.path.abspath('..')\n",
    "    root = os.path.join(root, \"Dataset\")\n",
    "\n",
    "    if ARGS.dataset == \"small\":\n",
    "        root = os.path.join(root, \"scaled_normalized\")\n",
    "    \n",
    "    elif ARGS.dataset == \"full\":\n",
    "        root = os.path.join(root, \"original_normalized\")\n",
    "    \n",
    "    else: \n",
    "        root = os.path.join(root, \"new_original\")        \n",
    "        \n",
    "    subjects = [file.split(\"__\")[:2] for file in  sorted(os.listdir(root))]\n",
    "    subjects = np.array(sorted([list(subj) for subj in list(set(map(tuple, subjects)))]))\n",
    "    \n",
    "    idx = list(range(subjects.shape[0]))\n",
    "    split1, split2 = int(len(idx) * 0.6), int(len(idx) * 0.8)\n",
    "    \n",
    "    random.seed(ARGS.seed)\n",
    "\n",
    "    random.shuffle(idx) # shuffles indices\n",
    "    train_idx, val_idx, test_idx = idx[:split1], idx[split1:split2], idx[split2:] # incides per data subset\n",
    "\n",
    "    train_subjects, val_subjects, test_subjects =  subjects[train_idx], subjects[val_idx], subjects[test_idx]\n",
    "\n",
    "    train_ds = SirenDataset(root, train_subjects, DEVICE)\n",
    "    train_dl = DataLoader(train_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=ARGS.shuffle)\n",
    "    print(\"Train subjects:\", train_ds.__len__())\n",
    "    \n",
    "    val_ds =  SirenDataset(root, val_subjects, DEVICE)\n",
    "    val_dl = DataLoader(val_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=False)\n",
    "    print(\"Val subjects:\", val_ds.__len__())\n",
    "    \n",
    "    test_ds =  SirenDataset(root, test_subjects, DEVICE)\n",
    "    test_dl = DataLoader(test_ds, batch_size=ARGS.batch_size, num_workers=0, shuffle=False)\n",
    "    print(\"Test subjects:\", test_ds.__len__())\n",
    "\n",
    "    return train_dl, val_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRANSLATE FUNCTIONS #####\n",
    "\n",
    "def get_random_shift(ARGS):\n",
    "        max_t = (4, ARGS.translate_max_pixels, ARGS.translate_max_pixels)\n",
    "        \n",
    "        shifts = (random.randint(-max_t[0], max_t[0]), \n",
    "                  random.randint(-max_t[1], max_t[1]), \n",
    "                  random.randint(-max_t[2], max_t[2]))\n",
    "        return shifts\n",
    "     \n",
    "def translate_image(image, shifts):\n",
    "    \n",
    "    image = torch.roll(image, shifts=shifts, dims=(0, 1, 2))\n",
    "\n",
    "    for axis, shift in enumerate(shifts):\n",
    "        idx = [[None, None], [None, None], [None, None]]\n",
    "\n",
    "        if shift > 0: \n",
    "            idx[axis][1] = shift\n",
    "        elif shift < 0: \n",
    "            idx[axis][0] = shift\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        image[idx[0][0]:idx[0][1], idx[1][0]:idx[1][1], idx[2][0]:idx[2][1]] = 0\n",
    "\n",
    "    return image\n",
    "\n",
    "def translate_batch(batch, ARGS): \n",
    "    idx, subj, proj, pcmras, masks, loss_covers = batch\n",
    "    \n",
    "    new_pcmras = new_masks = new_loss_covers = torch.empty((0)).to(pcmras.device)\n",
    "    \n",
    "    for pcmra, mask, loss_cover in zip(pcmras, masks, loss_covers): \n",
    "        pcmra, mask, loss_cover = pcmra.squeeze(), mask.squeeze(), loss_cover.squeeze()\n",
    "        \n",
    "        shifts = get_random_shift(ARGS)\n",
    "        pcmra = translate_image(pcmra, shifts).unsqueeze(0).unsqueeze(0)\n",
    "        mask = translate_image(mask, shifts).unsqueeze(0).unsqueeze(0)\n",
    "        loss_cover = translate_image(loss_cover, shifts).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        new_pcmras = torch.cat((new_pcmras, pcmra), 0)\n",
    "        new_masks = torch.cat((new_masks, mask), 0)\n",
    "        new_loss_covers = torch.cat((new_loss_covers, loss_cover), 0)\n",
    "    \n",
    "    return idx, subj, proj, new_pcmras, new_masks, new_loss_covers\n",
    "    \n",
    "##### FLIP FUNCTION #####\n",
    "\n",
    "def flip_batch(batch): \n",
    "    d_flip, h_flip, v_flip = RandomDepthicalFlip3D(), RandomHorizontalFlip3D(), RandomVerticalFlip3D()\n",
    "    \n",
    "    idx, subj, proj, pcmras, masks, loss_covers = batch\n",
    "    pcmra_masks = torch.cat((pcmras, masks, loss_covers), 1)\n",
    "    \n",
    "    pcmra_masks = d_flip(pcmra_masks)\n",
    "    pcmra_masks = h_flip(pcmra_masks)\n",
    "    pcmra_masks = v_flip(pcmra_masks)\n",
    "    \n",
    "    pcmras, masks, loss_covers = pcmra_masks.split(1, dim=1)\n",
    "\n",
    "    return idx, subj, proj, pcmras, masks, loss_covers\n",
    "    \n",
    "##### ROTATION FUNCTION #####\n",
    "\n",
    "def rotate_batch(batch):\n",
    "    rotate = RandomRotation3D((10., 15., 15.), p=1.0)\n",
    "    \n",
    "    idx, subj, proj, pcmras, masks, loss_covers = batch\n",
    "    pcmra_masks = torch.cat((pcmras, masks, loss_covers), 1)\n",
    "    \n",
    "    pcmra_masks = rotate(pcmra_masks)\n",
    "    pcmras, masks, loss_covers = pcmra_masks.split(1, dim=1)\n",
    "    \n",
    "    return idx, subj, proj, pcmras, masks, loss_covers\n",
    "\n",
    "##### CROP FUNCTIONS #####\n",
    "\n",
    "def crop_batch(batch, stretch=True, stretch_factor=1.2):\n",
    "    idx, subj, proj, pcmras, masks, loss_covers = batch\n",
    "    \n",
    "    orig_shape = pcmras.shape[2:]\n",
    "    \n",
    "    crop_sample = RandomCrop3D(orig_shape, p=1.)\n",
    "    \n",
    "    rand = random.uniform\n",
    "    inc = stretch_factor\n",
    "    if stretch:\n",
    "        resize = [rand(1., inc), rand(1., inc), rand(1., inc)]\n",
    "    else: \n",
    "        resize = [rand(1., inc)] * 3\n",
    "    \n",
    "    size = tuple([int(i * j) for i, j in zip(orig_shape, resize)])\n",
    "    \n",
    "    pcmras = F.interpolate(pcmras, size=size, mode=\"trilinear\")\n",
    "    masks = F.interpolate(masks, size=size, mode=\"trilinear\")\n",
    "    loss_covers = F.interpolate(loss_covers, size=size, mode=\"trilinear\")\n",
    "    \n",
    "    pcmra_masks = torch.cat((pcmras, masks, loss_covers), 1)\n",
    "    pcmra_masks = crop_sample(pcmra_masks)\n",
    "\n",
    "    pcmras, masks, loss_covers = pcmra_masks.split(1, dim=1)\n",
    "\n",
    "    return idx, subj, proj, pcmras, masks, loss_covers\n",
    "\n",
    "\n",
    "##### complete transformation #####\n",
    "\n",
    "def transform_batch(batch, ARGS):\n",
    "        \n",
    "    if ARGS.flip: \n",
    "        batch = flip_batch(batch)\n",
    "    if ARGS.translate: \n",
    "        batch = translate_batch(batch, ARGS)\n",
    "    if ARGS.crop: \n",
    "        batch = crop_batch(batch, ARGS.stretch, ARGS.stretch_factor)\n",
    "    if ARGS.rotate: \n",
    "        batch = rotate_batch(batch)\n",
    "    \n",
    "    idx, subj, proj, pcmras, masks, loss_covers = batch\n",
    "    \n",
    "    masks = torch.round(masks)\n",
    "    loss_covers = torch.floor(torch.round(loss_covers*10) / 10)\n",
    "    \n",
    "    return idx, subj, proj, pcmras, masks, loss_covers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create siren arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siren_batch(batch): \n",
    "    idx, subj, proj, pcmras, masks, loss_covers = batch\n",
    "\n",
    "    length = prod(pcmras.shape[2:])\n",
    "    \n",
    "    coords = get_coords(*pcmras.shape[2:]).to(pcmras.device).unsqueeze(0)\n",
    "#     print(\"c\", coords.shape)\n",
    "    coords = coords.repeat(pcmras.shape[0], 1, 1)\n",
    "    \n",
    "    pcmra_array = pcmras.view(pcmras.shape[0], length, 1)\n",
    "    mask_array = masks.view(pcmras.shape[0], length, 1)\n",
    "    loss_cover_array = loss_covers.view(loss_covers.shape[0], length, 1)\n",
    "    \n",
    "    return idx, subj, proj, pcmras, coords, pcmra_array, mask_array, loss_cover_array\n",
    "\n",
    "def prod(val) :  \n",
    "    res = 1 \n",
    "    for ele in val:  \n",
    "        res *= ele  \n",
    "    return res \n",
    "\n",
    "    \n",
    "def get_coords(*sidelengths):\n",
    "    tensors = []\n",
    "\n",
    "    for sidelen in sidelengths:\n",
    "        tensors.append(torch.linspace(-1, 1, steps=sidelen))\n",
    "\n",
    "    tensors = tuple(tensors)\n",
    "    coords = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "\n",
    "    return coords.reshape(-1, len(sidelengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_optim_scheduler(ARGS, DEVICE): \n",
    "    model = load_cnn(ARGS).to(DEVICE)\n",
    "    optim = torch.optim.Adam(lr=ARGS.cnn_lr, params=model.parameters(), weight_decay=ARGS.cnn_wd)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=ARGS.patience, factor=.5, verbose=True, min_lr=ARGS.min_lr)\n",
    "    \n",
    "    return model, optim, scheduler\n",
    "\n",
    "\n",
    "def mapping_model_optim_scheduler(ARGS, lr, DEVICE):\n",
    "    model= load_mapping(ARGS).to(DEVICE)\n",
    "    optim = torch.optim.Adam(lr=lr, params=model.parameters())\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=ARGS.patience, factor=.5, verbose=True, min_lr=ARGS.min_lr)\n",
    "\n",
    "    return model, optim, scheduler\n",
    "    \n",
    "\n",
    "def siren_model_optim_scheduler(ARGS, first_omega_0, hidden_omega_0, lr, wd, final_activation, DEVICE):\n",
    "    model = Siren(ARGS, in_features=3, out_features=1,first_omega_0=first_omega_0, \n",
    "                            hidden_omega_0=hidden_omega_0, final_activation=final_activation).to(DEVICE)\n",
    "    optim = torch.optim.Adam(lr=lr, params=model.parameters(), weight_decay=wd)    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=ARGS.patience, factor=.5, verbose=True, min_lr=ARGS.min_lr)\n",
    "    \n",
    "    return model, optim, scheduler\n",
    "\n",
    "\n",
    "def load_models_and_optims(ARGS):\n",
    "    \n",
    "    if ARGS.device.lower() == \"cpu\": \n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Using device for training:', DEVICE)\n",
    "        print('----------------------------------')\n",
    "\n",
    "    else: \n",
    "        DEVICE = set_device()\n",
    "        \n",
    "    models, optims, schedulers = {}, {}, {}\n",
    "    \n",
    "    models[\"cnn\"], optims[\"cnn\"], schedulers[\"cnn\"] = cnn_model_optim_scheduler(ARGS, DEVICE)\n",
    "    \n",
    "    models[\"mapping\"], optims[\"mapping\"], \\\n",
    "        schedulers[\"mapping\"] = mapping_model_optim_scheduler(ARGS, ARGS.mapping_lr, DEVICE)\n",
    "    \n",
    "    \n",
    "    models[\"siren\"], optims[\"siren\"], schedulers[\"siren\"] = \\\n",
    "        siren_model_optim_scheduler(ARGS, ARGS.first_omega_0, ARGS.hidden_omega_0, \n",
    "                                    ARGS.siren_lr, ARGS.siren_wd, \"sigmoid\", DEVICE)\n",
    "    \n",
    "    models[\"pcmra_mapping\"], optims[\"pcmra_mapping\"], \\\n",
    "        schedulers[\"pcmra_mapping\"] = mapping_model_optim_scheduler(ARGS, ARGS.pcmra_mapping_lr, DEVICE)\n",
    "   \n",
    "    models[\"pcmra_siren\"], optims[\"pcmra_siren\"], schedulers[\"pcmra_siren\"] = \\\n",
    "        siren_model_optim_scheduler(ARGS, ARGS.pcmra_first_omega_0, ARGS.pcmra_hidden_omega_0, \n",
    "                                    ARGS.pcmra_siren_lr, ARGS.pcmra_siren_wd, None, DEVICE)\n",
    "\n",
    "    for model, struct in models.items(): \n",
    "        print(model.upper())\n",
    "        if ARGS.print_models:\n",
    "            print(struct)\n",
    "\n",
    "    return models, optims, schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Random coords subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_coords(*arrays, n=1000): \n",
    "    batch_size, max_int, _ = arrays[0].shape\n",
    "\n",
    "    batch_n = np.repeat(np.expand_dims(list(range(batch_size)), axis=1), n, axis=1)\n",
    "    rand_ints = np.random.randint(0, max_int, size=(batch_size, n))\n",
    "\n",
    "    if not n == -1:\n",
    "        arrays = [array[batch_n, rand_ints, :].detach().clone() for array in arrays]\n",
    "        \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice_loss(pred, target):\n",
    "    \n",
    "    smooth = 0.\n",
    "\n",
    "    pred = torch.round(pred)\n",
    "\n",
    "    pflat = pred.flatten()\n",
    "    tflat = target.flatten()\n",
    "    intersection = (pflat * tflat).sum()\n",
    "\n",
    "    A_sum = torch.sum(pflat * pflat)\n",
    "    B_sum = torch.sum(tflat * tflat)\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and validation epoch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloader, models, optims, schedulers, criterion, ARGS, output=\"pcmra\"): \n",
    "    losses = [] \n",
    "    \n",
    "    for batch in dataloader:\n",
    "                    \n",
    "        batch = transform_batch(batch, ARGS)            \n",
    "        _, _, _, pcmra, coords, pcmra_array, mask_array, loss_cover_array = get_siren_batch(batch)\n",
    "        \n",
    "        latent_rep = models[\"cnn\"](pcmra) # get latent representation\n",
    "        \n",
    "        if output == \"pcmra\": \n",
    "            siren_in, labels, loss_cover = choose_random_coords(coords, pcmra_array, \n",
    "                                                                loss_cover_array, n=ARGS.n_coords_sample)\n",
    "            \n",
    "            if ARGS.pcmra_train_cnn:\n",
    "                gamma, beta = models[\"pcmra_mapping\"](latent_rep)\n",
    "                model_keys = [\"cnn\", \"pcmra_mapping\", \"pcmra_siren\"]\n",
    "                \n",
    "            else:\n",
    "                gamma, beta = models[\"pcmra_mapping\"](latent_rep.detach())\n",
    "                model_keys = [\"pcmra_mapping\", \"pcmra_siren\"]\n",
    "            \n",
    "            out = models[\"pcmra_siren\"](siren_in, gamma, beta)            \n",
    "            \n",
    "        elif output == \"mask\": \n",
    "            siren_in, labels, loss_cover = choose_random_coords(coords, mask_array, \n",
    "                                                                loss_cover_array, n=ARGS.n_coords_sample)\n",
    "            \n",
    "            if ARGS.mask_train_cnn:\n",
    "                gamma, beta = models[\"mapping\"](latent_rep)\n",
    "                model_keys = [\"cnn\", \"mapping\", \"siren\"]\n",
    "                \n",
    "            else:\n",
    "                gamma, beta = models[\"mapping\"](latent_rep.detach())\n",
    "                model_keys = [\"mapping\", \"siren\"]\n",
    "            \n",
    "            out = models[\"siren\"](siren_in, gamma, beta)\n",
    "            \n",
    "        loss = criterion(out * loss_cover, labels * loss_cover)         \n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        for key in model_keys: \n",
    "            optims[key].step()\n",
    "            optims[key].zero_grad()\n",
    "    \n",
    "    mean, std = round(np.mean(losses), 6), round(np.std(losses), 6)\n",
    "\n",
    "    for key in model_keys: \n",
    "        schedulers[key].step(mean)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_model(dataloader, models, criterion, ARGS, output=\"pcmra\"):\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        d_losses = []\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "                    \n",
    "            _, _, _, pcmra, coords, pcmra_array, mask_array, loss_cover_array = get_siren_batch(batch)\n",
    "\n",
    "            i += pcmra.shape[0]\n",
    "            \n",
    "            labels = [pcmra_array if output==\"pcmra\" else mask_array][0]\n",
    "            \n",
    "            out = get_complete_image(models, pcmra, coords, ARGS, output=output)\n",
    "            \n",
    "            for s_out, s_labels in zip(out, labels):\n",
    "            \n",
    "                loss = criterion(s_out, s_labels)  \n",
    "                losses.append(loss.item())\n",
    "            \n",
    "                if output==\"mask\":\n",
    "                    d_loss = calc_dice_loss(s_out, s_labels) \n",
    "                else:\n",
    "                    d_loss = torch.tensor([0])\n",
    "\n",
    "                d_losses.append(d_loss.item())\n",
    "\n",
    "        loss_mean, loss_std = round(np.mean(losses), 6), round(np.std(losses), 6)\n",
    "        d_loss_mean, d_loss_std = round(np.mean(d_losses), 6), round(np.std(d_losses), 6)\n",
    "    \n",
    "    return loss_mean, loss_std, d_loss_mean, d_loss_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_image(models, pcmra, coords, ARGS, val_n=10000, output=\"mask\"): \n",
    "    for model in models.values(): \n",
    "        model.eval()  # evaluation mode    \n",
    "    \n",
    "    n_slices = math.ceil(coords.shape[1] / val_n) # number of batches\n",
    "    \n",
    "    latent_rep = models[\"cnn\"](pcmra)                \n",
    "    \n",
    "    for i in range(n_slices):\n",
    "        coords_in = coords[:, (i*val_n) : ((i+1)*val_n), :]\n",
    "        \n",
    "        if output == \"mask\":\n",
    "            gamma, beta = models[\"mapping\"](latent_rep)\n",
    "            siren_out = models[\"siren\"](coords_in, gamma, beta)\n",
    "        \n",
    "        elif output == \"pcmra\": \n",
    "            gamma, beta = models[\"pcmra_mapping\"](latent_rep)    \n",
    "            siren_out = models[\"pcmra_siren\"](coords_in, gamma, beta)\n",
    "        \n",
    "        if i == 0: \n",
    "            image = siren_out.detach()\n",
    "        else:\n",
    "            image = torch.cat((image, siren_out.detach()), 1)\n",
    "    \n",
    "    for model in models.values(): \n",
    "        model.train()  # train mode\n",
    "    \n",
    "    return image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_models(folder, best_dataset, best_loss, models, optims, pretrained_models=None): \n",
    "    path = f\"saved_runs/{folder}/\"\n",
    "\n",
    "    for key in models.keys():\n",
    "        if pretrained_models == None or key in pretrained_models:\n",
    "            if os.path.exists(f\"{path}/{key}_{best_loss}_loss_{best_dataset}.pt\"):\n",
    "                print(f\"Loading params from {key}\")\n",
    "                models[key].load_state_dict(torch.load(f\"{path}/{key}_{best_loss}_loss_{best_dataset}.pt\"))\n",
    "                optims[key].load_state_dict(torch.load(f\"{path}/{key}_optim_{best_loss}_loss_{best_dataset}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CNN and Mapping setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cnn(ARGS): \n",
    "    if ARGS.cnn_setup == -1: \n",
    "        cnn = LargeCNN1()\n",
    "    elif ARGS.cnn_setup == -2: \n",
    "        cnn = LargeCNN()\n",
    "    elif ARGS.cnn_setup == -3: \n",
    "        cnn = LargeCNN3()\n",
    "    elif ARGS.cnn_setup == -4: \n",
    "        cnn = LargeCNN4()\n",
    "    elif ARGS.cnn_setup == -5: \n",
    "        cnn = LargeCNN5()\n",
    "    elif ARGS.cnn_setup == -6: \n",
    "        cnn = LargeCNN6()\n",
    "\n",
    "        \n",
    "    elif ARGS.cnn_setup == 0: \n",
    "        cnn = Encoder()\n",
    "    elif ARGS.cnn_setup == 1: \n",
    "        cnn = CNN1()\n",
    "    elif ARGS.cnn_setup == 2: \n",
    "        cnn = CNN2()\n",
    "    elif ARGS.cnn_setup == 3: \n",
    "        cnn = Encoder_1()\n",
    "    elif ARGS.cnn_setup == 4: \n",
    "        cnn = Encoder_2()\n",
    "    elif ARGS.cnn_setup == 5: \n",
    "        cnn = CNN3()     \n",
    "    elif ARGS.cnn_setup == 6: \n",
    "        cnn = CNN4()\n",
    "    elif ARGS.cnn_setup == 7: \n",
    "        cnn = CNN5()\n",
    "    elif ARGS.cnn_setup == 8: \n",
    "        cnn = CNN6()\n",
    "    elif ARGS.cnn_setup == 9: \n",
    "        cnn = CNN7()\n",
    "    elif ARGS.cnn_setup == 10: \n",
    "        cnn = CNN8()\n",
    "    elif ARGS.cnn_setup == 11: \n",
    "        cnn = CNN9()\n",
    "    elif ARGS.cnn_setup == 12: \n",
    "        cnn = CNN10()\n",
    "    elif ARGS.cnn_setup == 13: \n",
    "        cnn = CNN11()\n",
    "    elif ARGS.cnn_setup == 14: \n",
    "        cnn = CNN12()\n",
    "    elif ARGS.cnn_setup == 15: \n",
    "        cnn = CNN13()\n",
    "    elif ARGS.cnn_setup == 16: \n",
    "        cnn = CNN14()\n",
    "    elif ARGS.cnn_setup == 17: \n",
    "        cnn = CNN15()\n",
    "    elif ARGS.cnn_setup == 18: \n",
    "        cnn = CNN16()\n",
    "    else: \n",
    "        raise(Exception(\"Choose existing CNN setup\"))\n",
    "        \n",
    "    return cnn\n",
    "\n",
    "def load_mapping(ARGS): \n",
    "    \n",
    "    if ARGS.mapping_setup == -1 or ARGS.mapping_setup == 7: \n",
    "        mapping = LargeMapping1(ARGS)\n",
    "    elif ARGS.mapping_setup == -2: \n",
    "        mapping = LargeMapping2(ARGS)\n",
    "    elif ARGS.mapping_setup == -5: \n",
    "        mapping = LargeMapping5(ARGS)\n",
    "    \n",
    "    \n",
    "    elif ARGS.mapping_setup == 1: \n",
    "        mapping = Mapping1()\n",
    "    elif ARGS.mapping_setup == 2: \n",
    "        mapping = Mapping2()\n",
    "    elif ARGS.mapping_setup == 3: \n",
    "        mapping = Mapping3()\n",
    "    elif ARGS.mapping_setup == 4: \n",
    "        mapping = Mapping4()\n",
    "    elif ARGS.mapping_setup == 0: \n",
    "        mapping = Encoder_Mapping()\n",
    "    elif ARGS.mapping_setup == 5: \n",
    "        mapping = Encoder_Mapping_1()\n",
    "    elif ARGS.mapping_setup == 6: \n",
    "        mapping = Encoder_Mapping_2()\n",
    "    elif ARGS.mapping_setup == 8: \n",
    "        mapping = Encoder_Mapping_4()\n",
    "    else: \n",
    "        raise(Exception(\"Choose existing mapping setup\"))\n",
    "        \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to scroll through output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Show_images(object):\n",
    "    \"\"\"\n",
    "    Scroll through slices. Takes an unspecified number of subfigures per figure.\n",
    "    suptitles: either a str or a list. Represents the \n",
    "    main title of a figure. \n",
    "    images_titles: a list with tuples, each tuple an np.array and a \n",
    "    title for the array subfigure. \n",
    "    \"\"\"\n",
    "    def __init__(self, suptitles, *images_titles):\n",
    "        # if string if given, make list with that title for \n",
    "        # each slice.\n",
    "        if type(suptitles) == str: \n",
    "            self.suptitles = []\n",
    "            for i in range(images_titles[0][0].shape[2]): \n",
    "                self.suptitles.append(suptitles)\n",
    "        else: \n",
    "            self.suptitles = suptitles\n",
    "                    \n",
    "        self.fig, self.ax = plt.subplots(1,len(images_titles))\n",
    "\n",
    "        # split tuples with (image, title) into lists\n",
    "        self.images = [x[0] for x in images_titles]\n",
    "        self.titles = [x[1] for x in images_titles]\n",
    "\n",
    "        # get the number of slices that are to be shown\n",
    "        rows, cols, self.slices = self.images[0].shape        \n",
    "        self.ind = 0\n",
    "\n",
    "        self.fig.suptitle(self.suptitles[self.ind]) # set title \n",
    "\n",
    "        self.plots = []\n",
    "        \n",
    "        # start at slice 10 if more than 20 slices, \n",
    "        # otherwise start at middle slice.\n",
    "        if self.images[0].shape[2] > 20: \n",
    "            self.ind = 10\n",
    "        else:\n",
    "            self.ind = self.images[0].shape[2] // 2\n",
    "        \n",
    "        # make sure ax is an np array\n",
    "        if type(self.ax) == np.ndarray:\n",
    "            pass\n",
    "        else: \n",
    "            self.ax = np.array([self.ax])\n",
    "        \n",
    "        # create title for each subfigure in slice\n",
    "        for (sub_ax, image, title) in zip(self.ax, self.images, self.titles): \n",
    "            sub_ax.set_title(title)\n",
    "            plot = sub_ax.imshow(image[:, :, self.ind], vmin=0, vmax=1)\n",
    "            self.plots.append(plot)\n",
    "\n",
    "            \n",
    "        # link figure to mouse scroll movement\n",
    "        self.plot_show = self.fig.canvas.mpl_connect('scroll_event', self.onscroll)\n",
    "        \n",
    "\n",
    "    def onscroll(self, event):\n",
    "        \"\"\"\n",
    "        Shows next or previous slice with mouse scroll.\n",
    "        \"\"\"\n",
    "        if event.button == 'up':\n",
    "            self.ind = (self.ind - 1) % self.slices\n",
    "        else:\n",
    "            self.ind = (self.ind + 1) % self.slices\n",
    "        \n",
    "        self.update()\n",
    "        \n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates the figure.\n",
    "        \"\"\"\n",
    "        self.fig.suptitle(self.suptitles[self.ind])\n",
    "        \n",
    "        for plot, image in zip(self.plots, self.images):\n",
    "            plot.set_data(image[:, :, self.ind])\n",
    "        \n",
    "        self.ax[0].set_ylabel('Slice Number: %s' % self.ind)\n",
    "        self.plots[0].axes.figure.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loaded all helper functions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
