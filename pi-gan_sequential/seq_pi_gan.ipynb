{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/ptenkaate/scratch/Master-Thesis/convert_ipynb_to_py_files.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import math \n",
    "import skimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from py_files.new_dataset import *\n",
    "\n",
    "from py_files.cnn_model import *\n",
    "from py_files.pigan_model import *\n",
    "\n",
    "from py_files.seq_pi_gan_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():  \n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    ##### path to wich the model should be saved #####\n",
    "    path = get_folder(ARGS)\n",
    "    \n",
    "    ##### save ARGS #####\n",
    "    with open(f\"{path}/ARGS.txt\", \"w\") as f:\n",
    "        print(vars(ARGS), file=f)\n",
    "        \n",
    "    ##### data preparation #####\n",
    "    train_dl, val_dl, test_dl = initialize_dataloaders(ARGS)\n",
    "    print(\"train batch:\", next(iter(train_dl))[1][:5])\n",
    "    print(\"eval batch:\", next(iter(val_dl))[1][:5])\n",
    "    print(\"test batch:\", next(iter(test_dl))[1][:5])\n",
    "            \n",
    "    ##### initialize models and optimizers #####\n",
    "    models, optims, schedulers = load_models_and_optims(ARGS)\n",
    "    \n",
    "    \n",
    "    ##### load pretrained model #####\n",
    "    if ARGS.pretrained: \n",
    "        print(f\"Loading pretrained model from '{ARGS.pretrained}'.\")\n",
    "        load_pretrained_models(ARGS.pretrained, ARGS.pretrained_best_dataset, ARGS.pretrained_best_loss,\n",
    "                    models, optims, pretrained_models = ARGS.pretrained_models)\n",
    "    \n",
    "        if ARGS.pretrained_lr_reset:\n",
    "            orig_lr = {\"cnn\": ARGS.pretrained_lr_reset, \"mapping\": ARGS.pretrained_lr_reset, \n",
    "                       \"siren\": ARGS.pretrained_lr_reset, \"pcmra_mapping\": ARGS.pretrained_lr_reset, \n",
    "                       \"pcmra_siren\": ARGS.pretrained_lr_reset}\n",
    "            for name, optim in optims.items():\n",
    "                for param_group in optim.param_groups: \n",
    "                    if param_group[\"lr\"] != orig_lr[name]: \n",
    "                        param_group[\"lr\"] = ARGS.pretrained_lr_reset\n",
    "                print(f\"{name} lr: {optim.param_groups[0]['lr']}\")\n",
    "\n",
    "    ##### loss function #####\n",
    "    criterions = [nn.BCELoss(), nn.MSELoss()]\n",
    "        \n",
    "    ##### epoch, train loss mean, train loss std, val loss mean, val loss std #####\n",
    "    mask_losses, pcmra_losses, dice_losses = np.empty((0, 5)), np.empty((0, 5)), np.empty((0, 5))\n",
    "    \n",
    "    for ep in range(ARGS.pcmra_epochs):\n",
    "    \n",
    "        t = time.time() \n",
    "\n",
    "        for model in models.values():\n",
    "            model.train()\n",
    "\n",
    "        loss, _ = train_model(train_dl, models, optims, schedulers, criterions[1], ARGS, output=\"pcmra\")\n",
    "        \n",
    "        \n",
    "        if ep % ARGS.eval_every == 0: \n",
    "\n",
    "            print(f\"Epoch {ep} took {round(time.time() - t, 2)} seconds.\")\n",
    "            \n",
    "            t_pcmra_mean, t_pcmra_std, _, _ = \\\n",
    "                val_model(train_dl, models, criterions[1], ARGS, output=\"pcmra\")\n",
    "            \n",
    "            v_pcmra_mean, v_pcmra_std, _, _ = \\\n",
    "                val_model(val_dl, models, criterions[1], ARGS, output=\"pcmra\")\n",
    "\n",
    "            pcmra_losses = np.append(pcmra_losses, [[ep ,t_pcmra_mean, t_pcmra_std, \n",
    "                                         v_pcmra_mean, v_pcmra_std]], axis=0)\n",
    "            \n",
    "            save_loss(path, pcmra_losses, models, optims, name=\"pcmra_loss\", \n",
    "                      save_models=True)\n",
    "        \n",
    "    \n",
    "    for ep in range(ARGS.mask_epochs):\n",
    "    \n",
    "        t = time.time() \n",
    "\n",
    "        for model in models.values():\n",
    "            model.train()\n",
    "\n",
    "        loss, _ = train_model(train_dl, models, optims, schedulers, criterions[0], ARGS, output=\"mask\")\n",
    "        \n",
    "        \n",
    "        if ep % ARGS.eval_every == 0: \n",
    "\n",
    "            print(f\"Epoch {ep} took {round(time.time() - t, 2)} seconds.\")\n",
    "            \n",
    "            t_mask_mean, t_mask_std, t_dice_mean, t_dice_std = \\\n",
    "                val_model(train_dl, models, criterions[0], ARGS, output=\"mask\")\n",
    "            \n",
    "            v_mask_mean, v_mask_std, v_dice_mean, v_dice_std = \\\n",
    "                val_model(val_dl, models, criterions[0], ARGS, output=\"mask\")\n",
    "\n",
    "            mask_losses = np.append(mask_losses, [[ep ,t_mask_mean, t_mask_std, \n",
    "                                         v_mask_mean, v_mask_std]], axis=0)\n",
    "            \n",
    "            dice_losses = np.append(dice_losses, [[ep ,t_dice_mean, t_dice_std, \n",
    "                                         v_dice_mean, v_dice_std]], axis=0)\n",
    "            \n",
    "            save_loss(path, mask_losses, models, optims, name=\"mask_loss\", \n",
    "                      save_models=True)\n",
    "            \n",
    "            save_loss(path, dice_losses, models, optims, name=\"dice_loss\", \n",
    "                      save_models=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cnn_setup, mapping_setup in [(-1, -1)]:\n",
    "\n",
    "    ARGS = init_ARGS()\n",
    "    \n",
    "    ARGS.cnn_setup = cnn_setup\n",
    "    ARGS.mapping_setup = mapping_setup\n",
    "    \n",
    "    ARGS.pcmra_epochs = 0\n",
    "    \n",
    "    ARGS.patience = 100 \n",
    "    \n",
    "    ARGS.first_omega_0 = 10\n",
    "    \n",
    "    ARGS.pretrained = \"pi-gan 2021-06-07 09:48:16 \"\n",
    "    ARGS.pretrained_lr_reset = 1e-5\n",
    "\n",
    "    print(vars(ARGS))\n",
    "\n",
    "    train()  \n",
    "\n",
    "    torch.cuda.empty_cache()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cnn_setup, mapping_setup in [(-1, -1)]:\n",
    "\n",
    "#     ARGS = init_ARGS()\n",
    "    \n",
    "#     ARGS.dim_hidden = 512\n",
    "        \n",
    "#     ARGS.cnn_setup = cnn_setup\n",
    "#     ARGS.mapping_setup = mapping_setup\n",
    "    \n",
    "#     ARGS.pcmra_epochs = 0\n",
    "    \n",
    "#     ARGS.min_lr = 5e-6\n",
    "        \n",
    "#     print(vars(ARGS))\n",
    "\n",
    "#     train()  \n",
    "\n",
    "#     torch.cuda.empty_cache()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    PARSER = argparse.ArgumentParser()\n",
    "\n",
    "    \n",
    "    # Arguments for training\n",
    "    PARSER.add_argument('--device', type=str, default=\"GPU\", \n",
    "                        help='Device that should be used.')\n",
    "\n",
    "    PARSER.add_argument('--print_models', type=str2bool, nargs=\"?\", const=True, default=False, \n",
    "                        help='Print the models after initialization or not.')\n",
    "\n",
    "    PARSER.add_argument('--name', type=str, default=\"\", \n",
    "                        help='Name of the folder where the output should be saved.')\n",
    "    \n",
    "    \n",
    "\n",
    "    # pretrained params \n",
    "    \n",
    "    PARSER.add_argument('--pretrained', type=str, default=None, \n",
    "                        help='Folder name of pretrained model that should be loaded.')\n",
    "    \n",
    "    PARSER.add_argument('--pretrained_best_dataset', type=str, default=\"train\", \n",
    "                        help='Pretrained model with lowest [train, val] loss.')\n",
    "    \n",
    "    PARSER.add_argument('--pretrained_best_loss', type=str, default=\"mask\", \n",
    "                        help='Pretrained model with lowest [train, val] loss.')\n",
    "    \n",
    "    PARSER.add_argument('--pretrained_models', type=str, default=None, \n",
    "                        help='Choose which pretrained models to load. None = all models')\n",
    "    \n",
    "    PARSER.add_argument('--pretrained_lr_reset', type=str, default=None, \n",
    "                        help='Reset the lr to a value.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # data\n",
    "    PARSER.add_argument('--dataset', type=str, default=\"new\", \n",
    "                        help='The dataset which we train on.')\n",
    "    \n",
    "    PARSER.add_argument('--seed', type=int, default=34, \n",
    "                        help='Seed for initializig dataloader')\n",
    "    \n",
    "    PARSER.add_argument('--rotate', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Rotations of the same image')\n",
    "    \n",
    "    PARSER.add_argument('--translate', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Translations of the same image')\n",
    "    \n",
    "    PARSER.add_argument('--translate_max_pixels', type=int, default=20, \n",
    "                        help='Translation max in height and width.')\n",
    "    \n",
    "    PARSER.add_argument('--flip', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Flips the train image')\n",
    "    \n",
    "    PARSER.add_argument('--crop', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Crops the train image')\n",
    "\n",
    "    PARSER.add_argument('--stretch', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Stretches the train image')\n",
    "\n",
    "    PARSER.add_argument('--stretch_factor', type=float, default=1.2, \n",
    "                        help='Stretch maximum of the train image')\n",
    "\n",
    "    PARSER.add_argument('--norm_min_max', type=list, default=[0, 1], \n",
    "                        help='List with min and max for normalizing input.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # train variables\n",
    "    PARSER.add_argument('--pcmra_epochs', type=int, default=5000, \n",
    "                        help='Number of epochs for pcmra training.')\n",
    "\n",
    "    PARSER.add_argument('--mask_epochs', type=int, default=5000, \n",
    "                        help='Number of epochs for mask training.')\n",
    "    \n",
    "    PARSER.add_argument('--batch_size', type=int, default=24, \n",
    "                        help='Number of epochs.')\n",
    "        \n",
    "    PARSER.add_argument('--eval_every', type=int, default=50, \n",
    "                        help='Set the # epochs after which evaluation should be done.')\n",
    "    \n",
    "    PARSER.add_argument('--shuffle', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Shuffle the train dataloader?')\n",
    "    \n",
    "    PARSER.add_argument('--n_coords_sample', type=int, default=5000, \n",
    "                        help='Number of coordinates that should be sampled for each subject.')\n",
    "    \n",
    "    PARSER.add_argument('--min_lr', type=float, default=1e-5, \n",
    "                        help='Minimum lr, input for lr scheduler.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # CNN\n",
    "    PARSER.add_argument('--cnn_setup', type=int, default=-1, \n",
    "                        help='Setup of the CNN.')\n",
    "    \n",
    "    PARSER.add_argument('--pcmra_train_cnn', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Whether to also train the cnn during pcmra reconstruction.')\n",
    "\n",
    "    PARSER.add_argument('--mask_train_cnn', type=str2bool, nargs=\"?\", const=True, default=True, \n",
    "                        help='Whether to also train the cnn during mask segmentation.')\n",
    "\n",
    "\n",
    "    \n",
    "    # Mapping\n",
    "    PARSER.add_argument('--mapping_setup', type=int, default=-1, \n",
    "                        help='Setup of the Mapping network.')\n",
    "\n",
    "    \n",
    "    \n",
    "    # SIREN\n",
    "    PARSER.add_argument('--dim_hidden', type=int, default=256, \n",
    "                        help='Dimension of hidden SIREN layers.')\n",
    "    \n",
    "    PARSER.add_argument('--siren_hidden_layers', type=int, default=3, \n",
    "                        help='Number of hidden SIREN layers.')\n",
    "    \n",
    "    \n",
    "    PARSER.add_argument('--first_omega_0', type=float, default=30., \n",
    "                        help='Omega_0 of first layer.')\n",
    "    \n",
    "    PARSER.add_argument('--hidden_omega_0', type=float, default=30., \n",
    "                        help='Omega_0 of hidden layer.')\n",
    "    \n",
    "    \n",
    "    PARSER.add_argument('--pcmra_first_omega_0', type=float, default=30., \n",
    "                        help='Omega_0 of first layer of PCMRA siren.')\n",
    "    \n",
    "    PARSER.add_argument('--pcmra_hidden_omega_0', type=float, default=30., \n",
    "                        help='Omega_0 of hidden layer of PCMRA siren.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # optimizers\n",
    "    PARSER.add_argument('--cnn_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of cnn optim.')\n",
    "\n",
    "    PARSER.add_argument('--cnn_wd', type=float, default=0, \n",
    "                        help='Weight decay of cnn optim.')\n",
    "\n",
    "    \n",
    "    PARSER.add_argument('--mapping_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of siren optim.')\n",
    "    \n",
    "    PARSER.add_argument('--pcmra_mapping_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of siren optim.')\n",
    "    \n",
    "\n",
    "    PARSER.add_argument('--siren_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of siren optim.')\n",
    "\n",
    "    PARSER.add_argument('--siren_wd', type=float, default=0, \n",
    "                        help='Weight decay of siren optim.')\n",
    "    \n",
    "    \n",
    "    PARSER.add_argument('--pcmra_siren_lr', type=float, default=1e-4, \n",
    "                        help='Learning rate of PCMRA siren optim.')    \n",
    "    \n",
    "    PARSER.add_argument('--pcmra_siren_wd', type=float, default=0, \n",
    "                        help='Weight decay of PCMRA siren optim.')\n",
    "    \n",
    "    PARSER.add_argument('--patience', type=int, default=200, \n",
    "                        help='Patience of the LR scheduler.')\n",
    "    \n",
    "    \n",
    "    ARGS = PARSER.parse_args()\n",
    "    \n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
