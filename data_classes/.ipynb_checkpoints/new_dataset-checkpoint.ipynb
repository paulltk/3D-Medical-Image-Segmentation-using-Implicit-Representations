{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import torch \n",
    "import glob\n",
    "import sys\n",
    "import time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mplPath\n",
    "\n",
    "import pylab as pl\n",
    "\n",
    "from threading import Timer\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SirenDataset(Dataset): \n",
    "    def __init__(self, root, subjects, DEVICE, dataset=\"train\", max_t=(8, 8, 4)): \n",
    "        self.root = root\n",
    "        self.dataset = dataset\n",
    "        self.max_t = max_t\n",
    "        self.DEVICE = DEVICE\n",
    "        \n",
    "        if self.dataset == \"train\":\n",
    "            self.all_images = [image.split(\"__\")[:3] for image in os.listdir(root) \n",
    "                               if list(image.split(\"__\")[:2]) in subjects.tolist() \n",
    "                               and image.split(\"__\")[3] == \"pcmra.npy\"]\n",
    "        else:\n",
    "            self.all_images = [image.split(\"__\")[:3] for image in os.listdir(root) \n",
    "                               if list(image.split(\"__\")[:2]) in subjects.tolist() \n",
    "                               and (len(image.split(\"__\")[2].split(\"_\")) == 1 \n",
    "                                    or image.split(\"__\")[2].split(\"_\")[1] == \"rot 0 (-, -)\")\n",
    "                               and image.split(\"__\")[3] == \"pcmra.npy\"]\n",
    "            \n",
    "        self.pcmras = torch.tensor([np.load(os.path.join(self.root, f\"{subj}__{proj}__{rot}__pcmra.npy\")) \n",
    "                           for subj, proj, rot in self.all_images]).float().to(DEVICE)\n",
    "\n",
    "        self.masks = torch.tensor([np.load(os.path.join(self.root, f\"{subj}__{proj}__{rot}__mask.npy\")) \n",
    "                           for subj, proj, rot in self.all_images]).float().to(DEVICE)\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        subj, proj, rot = self.all_images[idx]\n",
    "        pcmra = self.pcmras[idx]\n",
    "        mask = self.masks[idx]\n",
    "            \n",
    "        if self.dataset == \"train\":\n",
    "            shifts = self.get_random_shift()\n",
    "            \n",
    "            pcmra = self.translate_image(pcmra, shifts)\n",
    "            mask = self.translate_image(mask, shifts)\n",
    "                \n",
    "\n",
    "        length = self.prod(pcmra.shape)\n",
    "\n",
    "        coords = self.get_coords(*pcmra.shape).to(self.DEVICE)        \n",
    "        pcmra_array = pcmra.view(length, 1)\n",
    "        mask_array = mask.view(length, 1)\n",
    "        \n",
    "        pcmra = pcmra.permute(2, 0, 1).unsqueeze(0)\n",
    "        \n",
    "        return idx, subj, proj, pcmra, coords, pcmra_array, mask_array\n",
    "    \n",
    "    \n",
    "    def get_random_shift(self):\n",
    "        \n",
    "        max_t = self.max_t\n",
    "        \n",
    "        shifts = (random.randint(-max_t[0], max_t[0]), \n",
    "                  random.randint(-max_t[1], max_t[1]), \n",
    "                  random.randint(-max_t[2], max_t[2]))\n",
    "        \n",
    "        return shifts\n",
    "    \n",
    "    \n",
    "    def translate_image(self, image, shifts):\n",
    "\n",
    "        image = torch.roll(image, shifts=shifts, dims=(0, 1, 2))\n",
    "\n",
    "        for axis, shift in enumerate(shifts):\n",
    "            idx = [[None, None], [None, None], [None, None]]\n",
    "\n",
    "            if shift > 0: \n",
    "                idx[axis][1] = shift\n",
    "            elif shift < 0: \n",
    "                idx[axis][0] = shift\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            image[idx[0][0]:idx[0][1], idx[1][0]:idx[1][1], idx[2][0]:idx[2][1]] = 0\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def prod(self, val) :  \n",
    "        res = 1 \n",
    "        for ele in val:  \n",
    "            res *= ele  \n",
    "        return res \n",
    "\n",
    "    \n",
    "    def get_coords(self, *sidelengths):\n",
    "        tensors = []\n",
    "\n",
    "        for sidelen in sidelengths:\n",
    "            tensors.append(torch.linspace(-1, 1, steps=sidelen))\n",
    "\n",
    "        tensors = tuple(tensors)\n",
    "        coords = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "        \n",
    "        return coords.reshape(-1, len(sidelengths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bitc17f53f707db4b89be7c32a22adf91a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
